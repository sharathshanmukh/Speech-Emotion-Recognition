# Speech-Emotion-Recognition
Detecting emotions is one of the most important marketing strategy in today’s world. You could personalize different things for an individual specifically to suit their interest. For this reason, we decided to do a project where we could detect a person’s emotions just by their voice which will let us manage many AI related applications. Some examples could be including call centers to play music when one is angry on the call. Another could be a smart car slowing down when one is angry or fearful. As a result this type of application has much potential in the world that would benefit companies and also even safety to consumers.
Data Used: We got audio datasets with around 2000 audio files which were in the wav format from the following website: http://neuron.arts.ryerson.ca/ravdess/?f=3.
 The next step involves organizing the audio files. Each audio file has a unique identifier at the 6th position of the file name which can be used to determine the emotion the audio file consists. We have 4 different emotions in our dataset. 
1.	Calm 
2.	Happy 
3.	Sad 
4.	Angry






And finally deployed on AWS.
