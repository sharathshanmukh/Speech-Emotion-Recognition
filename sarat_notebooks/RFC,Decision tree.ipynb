{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "noticed-federal",
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as  tf\n",
    "from tensorflow import keras\n",
    "import os\n",
    "import librosa\n",
    "import librosa.display\n",
    "import numpy as np\n",
    "import IPython.display as ipd\n",
    "import pandas as pd\n",
    "from sklearn.utils import shuffle\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "from tensorflow.keras.layers import Conv1D,Dropout,MaxPooling1D,Activation,Flatten,Dense\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn.metrics import classification_report,confusion_matrix\n",
    "from sklearn.ensemble import RandomForestClassifier\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "hybrid-treasure",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'C:\\\\Users\\\\Sharath\\\\Desktop\\\\stuff\\\\projects\\\\proj\\\\data'"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test_path=os.path.join(os.getcwd(),\"data\")\n",
    "test_path"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "intense-jewel",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import itertools\n",
    "cmap=plt.cm.Blues\n",
    "title='Confusion matrix'\n",
    "# classes = Le.classes_\n",
    "normalize=False\n",
    "figname = 'model3.jpg'\n",
    "\n",
    "def plot_confusion_matrix(cm, classes, figname, normalize=False, title='Confusion matrix',cmap=plt.cm.Blues):\n",
    "    if normalize:\n",
    "        cm = cm.astype(\"float\") / cm.sum(axis=1)[:, np.newaxis]\n",
    "        print('Normalized confusion matrix')\n",
    "    else:\n",
    "        print(\"Confusion matrix, without normalization\")\n",
    "    plt.figure(figsize=(8,8))\n",
    "    plt.imshow(cm, interpolation=\"nearest\", cmap=cmap)\n",
    "    plt.title(title)\n",
    " #plt.colorbar()\n",
    "    tick_marks = np.arange(len(classes))\n",
    "    plt.xticks(tick_marks, classes, rotation=90)\n",
    "    plt.yticks(tick_marks, classes)\n",
    "    fmt = \".2f\" if normalize else \"d\"\n",
    "    thresh = cm.max() / 2.\n",
    "    for i, j in itertools.product(range(cm.shape[0]), range(cm.shape[1])):\n",
    "        plt.text(j, i, format(cm[i, j], fmt),\n",
    "        horizontalalignment=\"center\",\n",
    "        color=\"white\" if cm[i, j] > thresh else \"black\")\n",
    "        plt.ylabel(\"True label\")\n",
    "        plt.xlabel(\"Predicted label\")\n",
    "        plt.tight_layout()\n",
    "#         plt.savefig(figname)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "handmade-briefs",
   "metadata": {},
   "source": [
    "This function takes Actor directory as input and returns a numpy array of only 4 emotions [Audio_path,gender,emotion]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "greater-south",
   "metadata": {},
   "outputs": [],
   "source": [
    "def prep_labels(Actor_dir):\n",
    "    emotion=[]\n",
    "    gender=[]\n",
    "    audios=[]\n",
    "    emotion_d={1:'neutral', 2:'calm', 3:'happy', 4:'sad', 5:'angry', 6:'fear', 7:'disgust', 8:'surprise'}\n",
    "    gender_d={0:'female',1:'male'}\n",
    "    for actor in os.listdir(Actor_dir):\n",
    "        file_p=(os.path.join(Actor_dir,actor))\n",
    "        for recording in os.listdir(file_p):\n",
    "            if recording[6:-16]in [\"02\",\"03\",\"04\",\"05\"]:\n",
    "                emotion.append(int(recording[6:-16]))\n",
    "                gender.append(int(recording[18:-4])%2)\n",
    "                audios.append(os.path.join(file_p,recording))\n",
    "    gender=[gender_d[i] for i in gender]\n",
    "    emotion=[emotion_d[i] for i in emotion]\n",
    "    return np.c_[audios,gender,emotion]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "modern-assumption",
   "metadata": {},
   "source": [
    "This function takes a numpy array of paths and returns a pandas dataframe of Mfcc features and labels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "neural-roads",
   "metadata": {},
   "outputs": [],
   "source": [
    "def features(Path,sample_rate=22050*2,offset=0.5,n_mfcc=13,duration=2.5):\n",
    "    df = pd.DataFrame(columns=['features'])\n",
    "    count=0\n",
    "    for f in list(Path):\n",
    "        X, sample_rate = librosa.load(f, res_type='kaiser_fast',duration=duration,sr=sample_rate,offset=offset)\n",
    "        mfccs = np.mean(librosa.feature.mfcc(y=X,sr=sample_rate,n_mfcc=n_mfcc).T,axis=0)\n",
    "        features = mfccs\n",
    "        df.loc[count] = [features]\n",
    "        count=count+1\n",
    "        d=pd.DataFrame(df['features'].values.tolist())\n",
    "    return d"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "continuous-audit",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_final=features(prep_labels(test_path)[:,0],n_mfcc=40)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "literary-nirvana",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_final[\"emotion\"]=prep_labels(test_path)[:,2]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "lesbian-pipeline",
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>0</th>\n",
       "      <th>1</th>\n",
       "      <th>2</th>\n",
       "      <th>3</th>\n",
       "      <th>4</th>\n",
       "      <th>5</th>\n",
       "      <th>6</th>\n",
       "      <th>7</th>\n",
       "      <th>8</th>\n",
       "      <th>9</th>\n",
       "      <th>...</th>\n",
       "      <th>31</th>\n",
       "      <th>32</th>\n",
       "      <th>33</th>\n",
       "      <th>34</th>\n",
       "      <th>35</th>\n",
       "      <th>36</th>\n",
       "      <th>37</th>\n",
       "      <th>38</th>\n",
       "      <th>39</th>\n",
       "      <th>emotion</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>-691.554016</td>\n",
       "      <td>103.488388</td>\n",
       "      <td>6.234205</td>\n",
       "      <td>18.971476</td>\n",
       "      <td>8.451644</td>\n",
       "      <td>18.539339</td>\n",
       "      <td>-6.382955</td>\n",
       "      <td>6.202209</td>\n",
       "      <td>-10.171426</td>\n",
       "      <td>-0.678910</td>\n",
       "      <td>...</td>\n",
       "      <td>-5.225513</td>\n",
       "      <td>-0.647115</td>\n",
       "      <td>-0.530049</td>\n",
       "      <td>-2.785005</td>\n",
       "      <td>0.125315</td>\n",
       "      <td>-1.336625</td>\n",
       "      <td>-2.389767</td>\n",
       "      <td>-0.677985</td>\n",
       "      <td>-2.257579</td>\n",
       "      <td>calm</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>-669.990479</td>\n",
       "      <td>111.411613</td>\n",
       "      <td>10.758529</td>\n",
       "      <td>15.129254</td>\n",
       "      <td>8.621660</td>\n",
       "      <td>20.590872</td>\n",
       "      <td>-5.424139</td>\n",
       "      <td>4.473267</td>\n",
       "      <td>-9.863037</td>\n",
       "      <td>-1.271303</td>\n",
       "      <td>...</td>\n",
       "      <td>-4.514940</td>\n",
       "      <td>-1.264935</td>\n",
       "      <td>-1.201889</td>\n",
       "      <td>-2.088279</td>\n",
       "      <td>-0.541381</td>\n",
       "      <td>-2.506760</td>\n",
       "      <td>-3.407242</td>\n",
       "      <td>-2.235733</td>\n",
       "      <td>-3.555218</td>\n",
       "      <td>calm</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>-660.321472</td>\n",
       "      <td>111.567696</td>\n",
       "      <td>4.625660</td>\n",
       "      <td>19.650215</td>\n",
       "      <td>6.706089</td>\n",
       "      <td>18.305843</td>\n",
       "      <td>-6.093471</td>\n",
       "      <td>10.697109</td>\n",
       "      <td>-10.637363</td>\n",
       "      <td>0.421806</td>\n",
       "      <td>...</td>\n",
       "      <td>-5.643905</td>\n",
       "      <td>-0.768427</td>\n",
       "      <td>-0.937701</td>\n",
       "      <td>-3.438322</td>\n",
       "      <td>-0.336898</td>\n",
       "      <td>-2.816852</td>\n",
       "      <td>-2.498607</td>\n",
       "      <td>-1.849675</td>\n",
       "      <td>-2.227733</td>\n",
       "      <td>calm</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>-663.058350</td>\n",
       "      <td>111.353386</td>\n",
       "      <td>6.952808</td>\n",
       "      <td>16.100903</td>\n",
       "      <td>8.186879</td>\n",
       "      <td>18.408474</td>\n",
       "      <td>-6.693346</td>\n",
       "      <td>9.646807</td>\n",
       "      <td>-11.229571</td>\n",
       "      <td>-1.220288</td>\n",
       "      <td>...</td>\n",
       "      <td>-4.297531</td>\n",
       "      <td>-1.210608</td>\n",
       "      <td>-1.576615</td>\n",
       "      <td>-3.309341</td>\n",
       "      <td>-0.375529</td>\n",
       "      <td>-2.907807</td>\n",
       "      <td>-3.097103</td>\n",
       "      <td>-0.968241</td>\n",
       "      <td>-2.492663</td>\n",
       "      <td>calm</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>-680.847107</td>\n",
       "      <td>121.460922</td>\n",
       "      <td>10.062194</td>\n",
       "      <td>21.828939</td>\n",
       "      <td>7.593652</td>\n",
       "      <td>24.082800</td>\n",
       "      <td>-7.907874</td>\n",
       "      <td>8.599798</td>\n",
       "      <td>-12.025018</td>\n",
       "      <td>4.583032</td>\n",
       "      <td>...</td>\n",
       "      <td>-3.877761</td>\n",
       "      <td>0.625304</td>\n",
       "      <td>-2.025431</td>\n",
       "      <td>-2.090710</td>\n",
       "      <td>-0.976551</td>\n",
       "      <td>-2.383626</td>\n",
       "      <td>-3.999593</td>\n",
       "      <td>-3.170493</td>\n",
       "      <td>-2.492446</td>\n",
       "      <td>calm</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>763</th>\n",
       "      <td>-444.119110</td>\n",
       "      <td>73.669128</td>\n",
       "      <td>-28.460447</td>\n",
       "      <td>5.365310</td>\n",
       "      <td>-13.476593</td>\n",
       "      <td>-2.534122</td>\n",
       "      <td>-30.909962</td>\n",
       "      <td>-3.104536</td>\n",
       "      <td>-14.926821</td>\n",
       "      <td>-13.822457</td>\n",
       "      <td>...</td>\n",
       "      <td>3.538071</td>\n",
       "      <td>7.758658</td>\n",
       "      <td>10.049922</td>\n",
       "      <td>6.853305</td>\n",
       "      <td>7.994804</td>\n",
       "      <td>10.021395</td>\n",
       "      <td>4.083268</td>\n",
       "      <td>3.643723</td>\n",
       "      <td>0.631288</td>\n",
       "      <td>angry</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>764</th>\n",
       "      <td>-378.511078</td>\n",
       "      <td>64.218536</td>\n",
       "      <td>-32.865643</td>\n",
       "      <td>11.794813</td>\n",
       "      <td>-10.838286</td>\n",
       "      <td>-13.677436</td>\n",
       "      <td>-26.487675</td>\n",
       "      <td>1.482656</td>\n",
       "      <td>-14.414303</td>\n",
       "      <td>-12.062708</td>\n",
       "      <td>...</td>\n",
       "      <td>6.069856</td>\n",
       "      <td>4.045506</td>\n",
       "      <td>2.930989</td>\n",
       "      <td>-0.176050</td>\n",
       "      <td>-0.430975</td>\n",
       "      <td>0.593558</td>\n",
       "      <td>-0.287489</td>\n",
       "      <td>2.036106</td>\n",
       "      <td>0.191679</td>\n",
       "      <td>angry</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>765</th>\n",
       "      <td>-415.127319</td>\n",
       "      <td>68.543427</td>\n",
       "      <td>-34.881615</td>\n",
       "      <td>10.059309</td>\n",
       "      <td>-12.314293</td>\n",
       "      <td>-7.163306</td>\n",
       "      <td>-27.360477</td>\n",
       "      <td>2.133626</td>\n",
       "      <td>-14.272416</td>\n",
       "      <td>-12.633283</td>\n",
       "      <td>...</td>\n",
       "      <td>9.127749</td>\n",
       "      <td>5.921012</td>\n",
       "      <td>1.140636</td>\n",
       "      <td>1.266077</td>\n",
       "      <td>-0.284112</td>\n",
       "      <td>3.392887</td>\n",
       "      <td>1.678638</td>\n",
       "      <td>0.742106</td>\n",
       "      <td>-0.852997</td>\n",
       "      <td>angry</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>766</th>\n",
       "      <td>-440.400391</td>\n",
       "      <td>73.256340</td>\n",
       "      <td>-24.545799</td>\n",
       "      <td>10.807652</td>\n",
       "      <td>-14.200200</td>\n",
       "      <td>-3.927950</td>\n",
       "      <td>-24.290613</td>\n",
       "      <td>-3.342228</td>\n",
       "      <td>-17.595304</td>\n",
       "      <td>-11.925268</td>\n",
       "      <td>...</td>\n",
       "      <td>3.089315</td>\n",
       "      <td>6.614276</td>\n",
       "      <td>10.623822</td>\n",
       "      <td>9.390310</td>\n",
       "      <td>10.567907</td>\n",
       "      <td>9.109989</td>\n",
       "      <td>3.990542</td>\n",
       "      <td>1.412750</td>\n",
       "      <td>-1.220157</td>\n",
       "      <td>angry</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>767</th>\n",
       "      <td>-486.741333</td>\n",
       "      <td>42.567852</td>\n",
       "      <td>-26.040928</td>\n",
       "      <td>12.394094</td>\n",
       "      <td>-16.908117</td>\n",
       "      <td>-6.012173</td>\n",
       "      <td>-18.903172</td>\n",
       "      <td>0.631802</td>\n",
       "      <td>-16.163420</td>\n",
       "      <td>-7.842727</td>\n",
       "      <td>...</td>\n",
       "      <td>8.720415</td>\n",
       "      <td>5.919779</td>\n",
       "      <td>5.353457</td>\n",
       "      <td>1.388490</td>\n",
       "      <td>1.488488</td>\n",
       "      <td>1.632382</td>\n",
       "      <td>-0.146163</td>\n",
       "      <td>1.004053</td>\n",
       "      <td>-0.419241</td>\n",
       "      <td>angry</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>768 rows × 41 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "              0           1          2          3          4          5  \\\n",
       "0   -691.554016  103.488388   6.234205  18.971476   8.451644  18.539339   \n",
       "1   -669.990479  111.411613  10.758529  15.129254   8.621660  20.590872   \n",
       "2   -660.321472  111.567696   4.625660  19.650215   6.706089  18.305843   \n",
       "3   -663.058350  111.353386   6.952808  16.100903   8.186879  18.408474   \n",
       "4   -680.847107  121.460922  10.062194  21.828939   7.593652  24.082800   \n",
       "..          ...         ...        ...        ...        ...        ...   \n",
       "763 -444.119110   73.669128 -28.460447   5.365310 -13.476593  -2.534122   \n",
       "764 -378.511078   64.218536 -32.865643  11.794813 -10.838286 -13.677436   \n",
       "765 -415.127319   68.543427 -34.881615  10.059309 -12.314293  -7.163306   \n",
       "766 -440.400391   73.256340 -24.545799  10.807652 -14.200200  -3.927950   \n",
       "767 -486.741333   42.567852 -26.040928  12.394094 -16.908117  -6.012173   \n",
       "\n",
       "             6          7          8          9  ...        31        32  \\\n",
       "0    -6.382955   6.202209 -10.171426  -0.678910  ... -5.225513 -0.647115   \n",
       "1    -5.424139   4.473267  -9.863037  -1.271303  ... -4.514940 -1.264935   \n",
       "2    -6.093471  10.697109 -10.637363   0.421806  ... -5.643905 -0.768427   \n",
       "3    -6.693346   9.646807 -11.229571  -1.220288  ... -4.297531 -1.210608   \n",
       "4    -7.907874   8.599798 -12.025018   4.583032  ... -3.877761  0.625304   \n",
       "..         ...        ...        ...        ...  ...       ...       ...   \n",
       "763 -30.909962  -3.104536 -14.926821 -13.822457  ...  3.538071  7.758658   \n",
       "764 -26.487675   1.482656 -14.414303 -12.062708  ...  6.069856  4.045506   \n",
       "765 -27.360477   2.133626 -14.272416 -12.633283  ...  9.127749  5.921012   \n",
       "766 -24.290613  -3.342228 -17.595304 -11.925268  ...  3.089315  6.614276   \n",
       "767 -18.903172   0.631802 -16.163420  -7.842727  ...  8.720415  5.919779   \n",
       "\n",
       "            33        34         35         36        37        38        39  \\\n",
       "0    -0.530049 -2.785005   0.125315  -1.336625 -2.389767 -0.677985 -2.257579   \n",
       "1    -1.201889 -2.088279  -0.541381  -2.506760 -3.407242 -2.235733 -3.555218   \n",
       "2    -0.937701 -3.438322  -0.336898  -2.816852 -2.498607 -1.849675 -2.227733   \n",
       "3    -1.576615 -3.309341  -0.375529  -2.907807 -3.097103 -0.968241 -2.492663   \n",
       "4    -2.025431 -2.090710  -0.976551  -2.383626 -3.999593 -3.170493 -2.492446   \n",
       "..         ...       ...        ...        ...       ...       ...       ...   \n",
       "763  10.049922  6.853305   7.994804  10.021395  4.083268  3.643723  0.631288   \n",
       "764   2.930989 -0.176050  -0.430975   0.593558 -0.287489  2.036106  0.191679   \n",
       "765   1.140636  1.266077  -0.284112   3.392887  1.678638  0.742106 -0.852997   \n",
       "766  10.623822  9.390310  10.567907   9.109989  3.990542  1.412750 -1.220157   \n",
       "767   5.353457  1.388490   1.488488   1.632382 -0.146163  1.004053 -0.419241   \n",
       "\n",
       "     emotion  \n",
       "0       calm  \n",
       "1       calm  \n",
       "2       calm  \n",
       "3       calm  \n",
       "4       calm  \n",
       "..       ...  \n",
       "763    angry  \n",
       "764    angry  \n",
       "765    angry  \n",
       "766    angry  \n",
       "767    angry  \n",
       "\n",
       "[768 rows x 41 columns]"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_final"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "nuclear-prophet",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>0</th>\n",
       "      <th>1</th>\n",
       "      <th>2</th>\n",
       "      <th>3</th>\n",
       "      <th>4</th>\n",
       "      <th>5</th>\n",
       "      <th>6</th>\n",
       "      <th>7</th>\n",
       "      <th>8</th>\n",
       "      <th>9</th>\n",
       "      <th>...</th>\n",
       "      <th>31</th>\n",
       "      <th>32</th>\n",
       "      <th>33</th>\n",
       "      <th>34</th>\n",
       "      <th>35</th>\n",
       "      <th>36</th>\n",
       "      <th>37</th>\n",
       "      <th>38</th>\n",
       "      <th>39</th>\n",
       "      <th>emotion</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>-691.554016</td>\n",
       "      <td>103.488388</td>\n",
       "      <td>6.234205</td>\n",
       "      <td>18.971476</td>\n",
       "      <td>8.451644</td>\n",
       "      <td>18.539339</td>\n",
       "      <td>-6.382955</td>\n",
       "      <td>6.202209</td>\n",
       "      <td>-10.171426</td>\n",
       "      <td>-0.678910</td>\n",
       "      <td>...</td>\n",
       "      <td>-5.225513</td>\n",
       "      <td>-0.647115</td>\n",
       "      <td>-0.530049</td>\n",
       "      <td>-2.785005</td>\n",
       "      <td>0.125315</td>\n",
       "      <td>-1.336625</td>\n",
       "      <td>-2.389767</td>\n",
       "      <td>-0.677985</td>\n",
       "      <td>-2.257579</td>\n",
       "      <td>calm</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>-669.990479</td>\n",
       "      <td>111.411613</td>\n",
       "      <td>10.758529</td>\n",
       "      <td>15.129254</td>\n",
       "      <td>8.621660</td>\n",
       "      <td>20.590872</td>\n",
       "      <td>-5.424139</td>\n",
       "      <td>4.473267</td>\n",
       "      <td>-9.863037</td>\n",
       "      <td>-1.271303</td>\n",
       "      <td>...</td>\n",
       "      <td>-4.514940</td>\n",
       "      <td>-1.264935</td>\n",
       "      <td>-1.201889</td>\n",
       "      <td>-2.088279</td>\n",
       "      <td>-0.541381</td>\n",
       "      <td>-2.506760</td>\n",
       "      <td>-3.407242</td>\n",
       "      <td>-2.235733</td>\n",
       "      <td>-3.555218</td>\n",
       "      <td>calm</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>-660.321472</td>\n",
       "      <td>111.567696</td>\n",
       "      <td>4.625660</td>\n",
       "      <td>19.650215</td>\n",
       "      <td>6.706089</td>\n",
       "      <td>18.305843</td>\n",
       "      <td>-6.093471</td>\n",
       "      <td>10.697109</td>\n",
       "      <td>-10.637363</td>\n",
       "      <td>0.421806</td>\n",
       "      <td>...</td>\n",
       "      <td>-5.643905</td>\n",
       "      <td>-0.768427</td>\n",
       "      <td>-0.937701</td>\n",
       "      <td>-3.438322</td>\n",
       "      <td>-0.336898</td>\n",
       "      <td>-2.816852</td>\n",
       "      <td>-2.498607</td>\n",
       "      <td>-1.849675</td>\n",
       "      <td>-2.227733</td>\n",
       "      <td>calm</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>-663.058350</td>\n",
       "      <td>111.353386</td>\n",
       "      <td>6.952808</td>\n",
       "      <td>16.100903</td>\n",
       "      <td>8.186879</td>\n",
       "      <td>18.408474</td>\n",
       "      <td>-6.693346</td>\n",
       "      <td>9.646807</td>\n",
       "      <td>-11.229571</td>\n",
       "      <td>-1.220288</td>\n",
       "      <td>...</td>\n",
       "      <td>-4.297531</td>\n",
       "      <td>-1.210608</td>\n",
       "      <td>-1.576615</td>\n",
       "      <td>-3.309341</td>\n",
       "      <td>-0.375529</td>\n",
       "      <td>-2.907807</td>\n",
       "      <td>-3.097103</td>\n",
       "      <td>-0.968241</td>\n",
       "      <td>-2.492663</td>\n",
       "      <td>calm</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>-680.847107</td>\n",
       "      <td>121.460922</td>\n",
       "      <td>10.062194</td>\n",
       "      <td>21.828939</td>\n",
       "      <td>7.593652</td>\n",
       "      <td>24.082800</td>\n",
       "      <td>-7.907874</td>\n",
       "      <td>8.599798</td>\n",
       "      <td>-12.025018</td>\n",
       "      <td>4.583032</td>\n",
       "      <td>...</td>\n",
       "      <td>-3.877761</td>\n",
       "      <td>0.625304</td>\n",
       "      <td>-2.025431</td>\n",
       "      <td>-2.090710</td>\n",
       "      <td>-0.976551</td>\n",
       "      <td>-2.383626</td>\n",
       "      <td>-3.999593</td>\n",
       "      <td>-3.170493</td>\n",
       "      <td>-2.492446</td>\n",
       "      <td>calm</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>763</th>\n",
       "      <td>-444.119110</td>\n",
       "      <td>73.669128</td>\n",
       "      <td>-28.460447</td>\n",
       "      <td>5.365310</td>\n",
       "      <td>-13.476593</td>\n",
       "      <td>-2.534122</td>\n",
       "      <td>-30.909962</td>\n",
       "      <td>-3.104536</td>\n",
       "      <td>-14.926821</td>\n",
       "      <td>-13.822457</td>\n",
       "      <td>...</td>\n",
       "      <td>3.538071</td>\n",
       "      <td>7.758658</td>\n",
       "      <td>10.049922</td>\n",
       "      <td>6.853305</td>\n",
       "      <td>7.994804</td>\n",
       "      <td>10.021395</td>\n",
       "      <td>4.083268</td>\n",
       "      <td>3.643723</td>\n",
       "      <td>0.631288</td>\n",
       "      <td>angry</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>764</th>\n",
       "      <td>-378.511078</td>\n",
       "      <td>64.218536</td>\n",
       "      <td>-32.865643</td>\n",
       "      <td>11.794813</td>\n",
       "      <td>-10.838286</td>\n",
       "      <td>-13.677436</td>\n",
       "      <td>-26.487675</td>\n",
       "      <td>1.482656</td>\n",
       "      <td>-14.414303</td>\n",
       "      <td>-12.062708</td>\n",
       "      <td>...</td>\n",
       "      <td>6.069856</td>\n",
       "      <td>4.045506</td>\n",
       "      <td>2.930989</td>\n",
       "      <td>-0.176050</td>\n",
       "      <td>-0.430975</td>\n",
       "      <td>0.593558</td>\n",
       "      <td>-0.287489</td>\n",
       "      <td>2.036106</td>\n",
       "      <td>0.191679</td>\n",
       "      <td>angry</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>765</th>\n",
       "      <td>-415.127319</td>\n",
       "      <td>68.543427</td>\n",
       "      <td>-34.881615</td>\n",
       "      <td>10.059309</td>\n",
       "      <td>-12.314293</td>\n",
       "      <td>-7.163306</td>\n",
       "      <td>-27.360477</td>\n",
       "      <td>2.133626</td>\n",
       "      <td>-14.272416</td>\n",
       "      <td>-12.633283</td>\n",
       "      <td>...</td>\n",
       "      <td>9.127749</td>\n",
       "      <td>5.921012</td>\n",
       "      <td>1.140636</td>\n",
       "      <td>1.266077</td>\n",
       "      <td>-0.284112</td>\n",
       "      <td>3.392887</td>\n",
       "      <td>1.678638</td>\n",
       "      <td>0.742106</td>\n",
       "      <td>-0.852997</td>\n",
       "      <td>angry</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>766</th>\n",
       "      <td>-440.400391</td>\n",
       "      <td>73.256340</td>\n",
       "      <td>-24.545799</td>\n",
       "      <td>10.807652</td>\n",
       "      <td>-14.200200</td>\n",
       "      <td>-3.927950</td>\n",
       "      <td>-24.290613</td>\n",
       "      <td>-3.342228</td>\n",
       "      <td>-17.595304</td>\n",
       "      <td>-11.925268</td>\n",
       "      <td>...</td>\n",
       "      <td>3.089315</td>\n",
       "      <td>6.614276</td>\n",
       "      <td>10.623822</td>\n",
       "      <td>9.390310</td>\n",
       "      <td>10.567907</td>\n",
       "      <td>9.109989</td>\n",
       "      <td>3.990542</td>\n",
       "      <td>1.412750</td>\n",
       "      <td>-1.220157</td>\n",
       "      <td>angry</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>767</th>\n",
       "      <td>-486.741333</td>\n",
       "      <td>42.567852</td>\n",
       "      <td>-26.040928</td>\n",
       "      <td>12.394094</td>\n",
       "      <td>-16.908117</td>\n",
       "      <td>-6.012173</td>\n",
       "      <td>-18.903172</td>\n",
       "      <td>0.631802</td>\n",
       "      <td>-16.163420</td>\n",
       "      <td>-7.842727</td>\n",
       "      <td>...</td>\n",
       "      <td>8.720415</td>\n",
       "      <td>5.919779</td>\n",
       "      <td>5.353457</td>\n",
       "      <td>1.388490</td>\n",
       "      <td>1.488488</td>\n",
       "      <td>1.632382</td>\n",
       "      <td>-0.146163</td>\n",
       "      <td>1.004053</td>\n",
       "      <td>-0.419241</td>\n",
       "      <td>angry</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>768 rows × 41 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "              0           1          2          3          4          5  \\\n",
       "0   -691.554016  103.488388   6.234205  18.971476   8.451644  18.539339   \n",
       "1   -669.990479  111.411613  10.758529  15.129254   8.621660  20.590872   \n",
       "2   -660.321472  111.567696   4.625660  19.650215   6.706089  18.305843   \n",
       "3   -663.058350  111.353386   6.952808  16.100903   8.186879  18.408474   \n",
       "4   -680.847107  121.460922  10.062194  21.828939   7.593652  24.082800   \n",
       "..          ...         ...        ...        ...        ...        ...   \n",
       "763 -444.119110   73.669128 -28.460447   5.365310 -13.476593  -2.534122   \n",
       "764 -378.511078   64.218536 -32.865643  11.794813 -10.838286 -13.677436   \n",
       "765 -415.127319   68.543427 -34.881615  10.059309 -12.314293  -7.163306   \n",
       "766 -440.400391   73.256340 -24.545799  10.807652 -14.200200  -3.927950   \n",
       "767 -486.741333   42.567852 -26.040928  12.394094 -16.908117  -6.012173   \n",
       "\n",
       "             6          7          8          9  ...        31        32  \\\n",
       "0    -6.382955   6.202209 -10.171426  -0.678910  ... -5.225513 -0.647115   \n",
       "1    -5.424139   4.473267  -9.863037  -1.271303  ... -4.514940 -1.264935   \n",
       "2    -6.093471  10.697109 -10.637363   0.421806  ... -5.643905 -0.768427   \n",
       "3    -6.693346   9.646807 -11.229571  -1.220288  ... -4.297531 -1.210608   \n",
       "4    -7.907874   8.599798 -12.025018   4.583032  ... -3.877761  0.625304   \n",
       "..         ...        ...        ...        ...  ...       ...       ...   \n",
       "763 -30.909962  -3.104536 -14.926821 -13.822457  ...  3.538071  7.758658   \n",
       "764 -26.487675   1.482656 -14.414303 -12.062708  ...  6.069856  4.045506   \n",
       "765 -27.360477   2.133626 -14.272416 -12.633283  ...  9.127749  5.921012   \n",
       "766 -24.290613  -3.342228 -17.595304 -11.925268  ...  3.089315  6.614276   \n",
       "767 -18.903172   0.631802 -16.163420  -7.842727  ...  8.720415  5.919779   \n",
       "\n",
       "            33        34         35         36        37        38        39  \\\n",
       "0    -0.530049 -2.785005   0.125315  -1.336625 -2.389767 -0.677985 -2.257579   \n",
       "1    -1.201889 -2.088279  -0.541381  -2.506760 -3.407242 -2.235733 -3.555218   \n",
       "2    -0.937701 -3.438322  -0.336898  -2.816852 -2.498607 -1.849675 -2.227733   \n",
       "3    -1.576615 -3.309341  -0.375529  -2.907807 -3.097103 -0.968241 -2.492663   \n",
       "4    -2.025431 -2.090710  -0.976551  -2.383626 -3.999593 -3.170493 -2.492446   \n",
       "..         ...       ...        ...        ...       ...       ...       ...   \n",
       "763  10.049922  6.853305   7.994804  10.021395  4.083268  3.643723  0.631288   \n",
       "764   2.930989 -0.176050  -0.430975   0.593558 -0.287489  2.036106  0.191679   \n",
       "765   1.140636  1.266077  -0.284112   3.392887  1.678638  0.742106 -0.852997   \n",
       "766  10.623822  9.390310  10.567907   9.109989  3.990542  1.412750 -1.220157   \n",
       "767   5.353457  1.388490   1.488488   1.632382 -0.146163  1.004053 -0.419241   \n",
       "\n",
       "     emotion  \n",
       "0       calm  \n",
       "1       calm  \n",
       "2       calm  \n",
       "3       calm  \n",
       "4       calm  \n",
       "..       ...  \n",
       "763    angry  \n",
       "764    angry  \n",
       "765    angry  \n",
       "766    angry  \n",
       "767    angry  \n",
       "\n",
       "[768 rows x 41 columns]"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_final"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "functional-median",
   "metadata": {},
   "outputs": [],
   "source": [
    " X_train, X_test, y_train, y_test = train_test_split(df_final.iloc[:,:-1],df_final.iloc[:,-1], test_size=0.33, random_state=42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "consistent-process",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array(['angry', 'calm', 'happy', 'sad'], dtype=object)"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "Le=LabelEncoder()\n",
    "Le.fit(df_final[\"emotion\"])\n",
    "Le.classes_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "composed-reply",
   "metadata": {},
   "outputs": [],
   "source": [
    "y_train=Le.transform(y_train)\n",
    "y_test=Le.transform(y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "congressional-bench",
   "metadata": {},
   "outputs": [],
   "source": [
    "dtc = DecisionTreeClassifier()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "differential-practice",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "DecisionTreeClassifier()"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dtc.fit(X_train, y_train)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "living-massachusetts",
   "metadata": {},
   "outputs": [],
   "source": [
    "predictions = dtc.predict(X_test)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "affected-water",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Confusion matrix, without normalization\n"
     ]
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 576x576 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "cm = confusion_matrix( y_test,predictions)\n",
    "plot_confusion_matrix(cm, classes = Le.classes_, title='Confusion Matrix', normalize=False, figname = 'Confusion_matrix_concrete2.jpg')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "comic-winning",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "       angry       0.58      0.79      0.67        56\n",
      "        calm       0.65      0.60      0.63        68\n",
      "       happy       0.65      0.52      0.58        67\n",
      "         sad       0.56      0.54      0.55        63\n",
      "\n",
      "    accuracy                           0.61       254\n",
      "   macro avg       0.61      0.61      0.60       254\n",
      "weighted avg       0.61      0.61      0.60       254\n",
      "\n"
     ]
    }
   ],
   "source": [
    "print(classification_report(y_test,predictions,target_names=Le.classes_))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "comfortable-catering",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "RandomForestClassifier(max_depth=10, max_features='log2', max_leaf_nodes=100,\n",
       "                       min_samples_leaf=3, min_samples_split=20,\n",
       "                       n_estimators=22000, random_state=5)"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "rfc = RandomForestClassifier(criterion=\"gini\", max_depth=10, max_features=\"log2\", \n",
    "                                 max_leaf_nodes = 100, min_samples_leaf = 3, min_samples_split = 20, \n",
    "                                 n_estimators= 22000, random_state= 5)\n",
    "rfc.fit(X_train, y_train)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "quiet-medication",
   "metadata": {},
   "outputs": [],
   "source": [
    "predictions = rfc.predict(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "sought-bottom",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "       angry       0.71      0.95      0.81        56\n",
      "        calm       0.67      0.84      0.75        68\n",
      "       happy       0.65      0.45      0.53        67\n",
      "         sad       0.60      0.46      0.52        63\n",
      "\n",
      "    accuracy                           0.67       254\n",
      "   macro avg       0.66      0.67      0.65       254\n",
      "weighted avg       0.66      0.67      0.65       254\n",
      "\n"
     ]
    }
   ],
   "source": [
    "print(classification_report(y_test,predictions,target_names=Le.classes_))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "central-gateway",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Confusion matrix, without normalization\n"
     ]
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 576x576 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "cm = confusion_matrix( y_test,predictions)\n",
    "plot_confusion_matrix(cm, classes = Le.classes_, title='Confusion Matrix', normalize=False, figname = 'Confusion_matrix_concrete2.jpg')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "scenic-overview",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pickle\n",
    "pickle.dump(rfc, open('rfc.pkl','wb'))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "vocational-audio",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['dtc.pkl']"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "joblib_file = \"dtc.pkl\"  \n",
    "\n",
    "joblib.dump(dtc, joblib_file)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "mental-seattle",
   "metadata": {},
   "outputs": [],
   "source": [
    "from tensorflow.keras.layers import Dense, Embedding\n",
    "from tensorflow.keras.layers import Input, Flatten, Dropout, Activation\n",
    "from tensorflow.keras.layers import Conv1D, MaxPooling1D\n",
    "from tensorflow.keras.models import Model\n",
    "from tensorflow.keras.callbacks import ModelCheckpoint"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "finished-refund",
   "metadata": {},
   "outputs": [],
   "source": [
    "model = keras.models.Sequential()\n",
    "model.add(Conv1D(128, 5,padding='same',\n",
    "                 input_shape=(40,1)))\n",
    "model.add(Activation('relu'))\n",
    "model.add(Dropout(0.1))\n",
    "model.add(MaxPooling1D(pool_size=(8)))\n",
    "model.add(Conv1D(128, 5,padding='same',))\n",
    "model.add(Activation('relu'))\n",
    "model.add(Dropout(0.1))\n",
    "model.add(Flatten())\n",
    "model.add(Dense(4))\n",
    "model.add(Activation('softmax'))\n",
    "opt = keras.optimizers.RMSprop(lr=0.00005, rho=0.9, epsilon=None, decay=0.0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "cardiac-security",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential_2\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "conv1d_2 (Conv1D)            (None, 40, 128)           768       \n",
      "_________________________________________________________________\n",
      "activation_3 (Activation)    (None, 40, 128)           0         \n",
      "_________________________________________________________________\n",
      "dropout_2 (Dropout)          (None, 40, 128)           0         \n",
      "_________________________________________________________________\n",
      "max_pooling1d_1 (MaxPooling1 (None, 5, 128)            0         \n",
      "_________________________________________________________________\n",
      "conv1d_3 (Conv1D)            (None, 5, 128)            82048     \n",
      "_________________________________________________________________\n",
      "activation_4 (Activation)    (None, 5, 128)            0         \n",
      "_________________________________________________________________\n",
      "dropout_3 (Dropout)          (None, 5, 128)            0         \n",
      "_________________________________________________________________\n",
      "flatten_1 (Flatten)          (None, 640)               0         \n",
      "_________________________________________________________________\n",
      "dense_1 (Dense)              (None, 4)                 2564      \n",
      "_________________________________________________________________\n",
      "activation_5 (Activation)    (None, 4)                 0         \n",
      "=================================================================\n",
      "Total params: 85,380\n",
      "Trainable params: 85,380\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "model.summary()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "quarterly-adaptation",
   "metadata": {},
   "outputs": [],
   "source": [
    "%load_ext tensorboard"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "collectible-annex",
   "metadata": {},
   "outputs": [],
   "source": [
    "model.compile(loss='sparse_categorical_crossentropy',\n",
    "              optimizer=opt,\n",
    "              metrics=['accuracy'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "id": "front-aging",
   "metadata": {},
   "outputs": [],
   "source": [
    "import datetime\n",
    "log_dir = \"model_board_1\" \n",
    "tensorboard_callback = tf.keras.callbacks.TensorBoard(log_dir=log_dir, histogram_freq=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "id": "thirty-sally",
   "metadata": {},
   "outputs": [],
   "source": [
    "x_traincnn = np.expand_dims(X_train, axis=2)\n",
    "x_testcnn = np.expand_dims(X_test, axis=2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "id": "naked-story",
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/1000\n",
      "33/33 [==============================] - 0s 11ms/step - loss: 0.0100 - accuracy: 1.0000 - val_loss: 1.1738 - val_accuracy: 0.7835\n",
      "Epoch 2/1000\n",
      "33/33 [==============================] - 0s 5ms/step - loss: 0.0084 - accuracy: 0.9981 - val_loss: 1.1938 - val_accuracy: 0.7835\n",
      "Epoch 3/1000\n",
      "33/33 [==============================] - 0s 5ms/step - loss: 0.0097 - accuracy: 0.9981 - val_loss: 1.0462 - val_accuracy: 0.7992\n",
      "Epoch 4/1000\n",
      "33/33 [==============================] - 0s 6ms/step - loss: 0.0133 - accuracy: 0.9961 - val_loss: 1.1103 - val_accuracy: 0.7874\n",
      "Epoch 5/1000\n",
      "33/33 [==============================] - 0s 7ms/step - loss: 0.0135 - accuracy: 0.9961 - val_loss: 1.1209 - val_accuracy: 0.7992\n",
      "Epoch 6/1000\n",
      "33/33 [==============================] - 0s 5ms/step - loss: 0.0266 - accuracy: 0.9922 - val_loss: 1.2316 - val_accuracy: 0.7677\n",
      "Epoch 7/1000\n",
      "33/33 [==============================] - 0s 7ms/step - loss: 0.0097 - accuracy: 0.9961 - val_loss: 1.0872 - val_accuracy: 0.7992\n",
      "Epoch 8/1000\n",
      "33/33 [==============================] - 0s 7ms/step - loss: 0.0193 - accuracy: 0.9922 - val_loss: 1.1782 - val_accuracy: 0.8031\n",
      "Epoch 9/1000\n",
      "33/33 [==============================] - 0s 5ms/step - loss: 0.0131 - accuracy: 0.9961 - val_loss: 1.1037 - val_accuracy: 0.7874\n",
      "Epoch 10/1000\n",
      "33/33 [==============================] - 0s 6ms/step - loss: 0.0114 - accuracy: 0.9981 - val_loss: 1.1458 - val_accuracy: 0.7874\n",
      "Epoch 11/1000\n",
      "33/33 [==============================] - 0s 6ms/step - loss: 0.0116 - accuracy: 0.9981 - val_loss: 1.0573 - val_accuracy: 0.7717\n",
      "Epoch 12/1000\n",
      "33/33 [==============================] - 0s 5ms/step - loss: 0.0216 - accuracy: 0.9922 - val_loss: 1.0786 - val_accuracy: 0.7953\n",
      "Epoch 13/1000\n",
      "33/33 [==============================] - 0s 5ms/step - loss: 0.0146 - accuracy: 0.9981 - val_loss: 1.0602 - val_accuracy: 0.7835\n",
      "Epoch 14/1000\n",
      "33/33 [==============================] - 0s 5ms/step - loss: 0.0091 - accuracy: 1.0000 - val_loss: 1.2469 - val_accuracy: 0.7795\n",
      "Epoch 15/1000\n",
      "33/33 [==============================] - 0s 5ms/step - loss: 0.0100 - accuracy: 1.0000 - val_loss: 1.0486 - val_accuracy: 0.7913\n",
      "Epoch 16/1000\n",
      "33/33 [==============================] - 0s 5ms/step - loss: 0.0105 - accuracy: 0.9981 - val_loss: 1.2831 - val_accuracy: 0.7874\n",
      "Epoch 17/1000\n",
      "33/33 [==============================] - 0s 6ms/step - loss: 0.0146 - accuracy: 0.9942 - val_loss: 1.0922 - val_accuracy: 0.7953\n",
      "Epoch 18/1000\n",
      "33/33 [==============================] - 0s 6ms/step - loss: 0.0202 - accuracy: 0.9922 - val_loss: 1.1148 - val_accuracy: 0.7874\n",
      "Epoch 19/1000\n",
      "33/33 [==============================] - 0s 6ms/step - loss: 0.0073 - accuracy: 0.9981 - val_loss: 1.1476 - val_accuracy: 0.7795\n",
      "Epoch 20/1000\n",
      "33/33 [==============================] - 0s 5ms/step - loss: 0.0094 - accuracy: 1.0000 - val_loss: 1.0910 - val_accuracy: 0.7835\n",
      "Epoch 21/1000\n",
      "33/33 [==============================] - 0s 5ms/step - loss: 0.0102 - accuracy: 1.0000 - val_loss: 1.1417 - val_accuracy: 0.7913\n",
      "Epoch 22/1000\n",
      "33/33 [==============================] - 0s 6ms/step - loss: 0.0100 - accuracy: 1.0000 - val_loss: 1.0488 - val_accuracy: 0.7756\n",
      "Epoch 23/1000\n",
      "33/33 [==============================] - 0s 5ms/step - loss: 0.0147 - accuracy: 0.9961 - val_loss: 1.0196 - val_accuracy: 0.8071\n",
      "Epoch 24/1000\n",
      "33/33 [==============================] - 0s 6ms/step - loss: 0.0112 - accuracy: 0.9981 - val_loss: 1.1104 - val_accuracy: 0.7874\n",
      "Epoch 25/1000\n",
      "33/33 [==============================] - 0s 5ms/step - loss: 0.0135 - accuracy: 0.9961 - val_loss: 1.0124 - val_accuracy: 0.7953\n",
      "Epoch 26/1000\n",
      "33/33 [==============================] - 0s 6ms/step - loss: 0.0129 - accuracy: 0.9961 - val_loss: 1.1007 - val_accuracy: 0.7835\n",
      "Epoch 27/1000\n",
      "33/33 [==============================] - 0s 6ms/step - loss: 0.0172 - accuracy: 0.9981 - val_loss: 1.0471 - val_accuracy: 0.7874\n",
      "Epoch 28/1000\n",
      "33/33 [==============================] - 0s 6ms/step - loss: 0.0150 - accuracy: 0.9981 - val_loss: 1.0434 - val_accuracy: 0.7717\n",
      "Epoch 29/1000\n",
      "33/33 [==============================] - 0s 6ms/step - loss: 0.0157 - accuracy: 0.9942 - val_loss: 1.0553 - val_accuracy: 0.8071\n",
      "Epoch 30/1000\n",
      "33/33 [==============================] - 0s 5ms/step - loss: 0.0114 - accuracy: 0.9981 - val_loss: 1.1541 - val_accuracy: 0.7953\n",
      "Epoch 31/1000\n",
      "33/33 [==============================] - 0s 6ms/step - loss: 0.0098 - accuracy: 1.0000 - val_loss: 1.0941 - val_accuracy: 0.7874\n",
      "Epoch 32/1000\n",
      "33/33 [==============================] - 0s 5ms/step - loss: 0.0093 - accuracy: 0.9981 - val_loss: 1.0360 - val_accuracy: 0.7913\n",
      "Epoch 33/1000\n",
      "33/33 [==============================] - 0s 6ms/step - loss: 0.0134 - accuracy: 0.9981 - val_loss: 1.0460 - val_accuracy: 0.7913\n",
      "Epoch 34/1000\n",
      "33/33 [==============================] - 0s 5ms/step - loss: 0.0131 - accuracy: 0.9981 - val_loss: 1.2272 - val_accuracy: 0.7874\n",
      "Epoch 35/1000\n",
      "33/33 [==============================] - 0s 6ms/step - loss: 0.0080 - accuracy: 0.9981 - val_loss: 1.1690 - val_accuracy: 0.7677\n",
      "Epoch 36/1000\n",
      "33/33 [==============================] - 0s 6ms/step - loss: 0.0131 - accuracy: 0.9981 - val_loss: 1.1616 - val_accuracy: 0.7913\n",
      "Epoch 37/1000\n",
      "33/33 [==============================] - 0s 6ms/step - loss: 0.0120 - accuracy: 0.9961 - val_loss: 1.1139 - val_accuracy: 0.7913\n",
      "Epoch 38/1000\n",
      "33/33 [==============================] - 0s 6ms/step - loss: 0.0155 - accuracy: 0.9942 - val_loss: 1.2219 - val_accuracy: 0.7835\n",
      "Epoch 39/1000\n",
      "33/33 [==============================] - 0s 6ms/step - loss: 0.0105 - accuracy: 0.9961 - val_loss: 1.1510 - val_accuracy: 0.7756\n",
      "Epoch 40/1000\n",
      "33/33 [==============================] - 0s 5ms/step - loss: 0.0097 - accuracy: 0.9981 - val_loss: 1.2301 - val_accuracy: 0.7717\n",
      "Epoch 41/1000\n",
      "33/33 [==============================] - 0s 5ms/step - loss: 0.0118 - accuracy: 0.9981 - val_loss: 1.1326 - val_accuracy: 0.8031\n",
      "Epoch 42/1000\n",
      "33/33 [==============================] - 0s 6ms/step - loss: 0.0163 - accuracy: 0.9942 - val_loss: 1.1091 - val_accuracy: 0.7795\n",
      "Epoch 43/1000\n",
      "33/33 [==============================] - 0s 6ms/step - loss: 0.0151 - accuracy: 0.9961 - val_loss: 1.1539 - val_accuracy: 0.7953\n",
      "Epoch 44/1000\n",
      "33/33 [==============================] - 0s 5ms/step - loss: 0.0111 - accuracy: 0.9961 - val_loss: 1.1940 - val_accuracy: 0.7677\n",
      "Epoch 45/1000\n",
      "33/33 [==============================] - 0s 6ms/step - loss: 0.0112 - accuracy: 0.9981 - val_loss: 1.1795 - val_accuracy: 0.7756\n",
      "Epoch 46/1000\n",
      "33/33 [==============================] - 0s 6ms/step - loss: 0.0208 - accuracy: 0.9922 - val_loss: 1.1580 - val_accuracy: 0.7717\n",
      "Epoch 47/1000\n",
      "33/33 [==============================] - 0s 6ms/step - loss: 0.0242 - accuracy: 0.9903 - val_loss: 1.1270 - val_accuracy: 0.7913\n",
      "Epoch 48/1000\n",
      "33/33 [==============================] - 0s 5ms/step - loss: 0.0132 - accuracy: 0.9961 - val_loss: 1.0840 - val_accuracy: 0.8071\n",
      "Epoch 49/1000\n",
      "33/33 [==============================] - 0s 6ms/step - loss: 0.0102 - accuracy: 0.9961 - val_loss: 1.1210 - val_accuracy: 0.8110\n",
      "Epoch 50/1000\n",
      "33/33 [==============================] - 0s 6ms/step - loss: 0.0096 - accuracy: 0.9961 - val_loss: 1.0623 - val_accuracy: 0.7874\n",
      "Epoch 51/1000\n",
      "33/33 [==============================] - 0s 5ms/step - loss: 0.0096 - accuracy: 0.9981 - val_loss: 1.0973 - val_accuracy: 0.7835\n",
      "Epoch 52/1000\n",
      "33/33 [==============================] - 0s 5ms/step - loss: 0.0142 - accuracy: 0.9961 - val_loss: 1.1048 - val_accuracy: 0.7913\n",
      "Epoch 53/1000\n",
      "33/33 [==============================] - 0s 5ms/step - loss: 0.0082 - accuracy: 0.9981 - val_loss: 1.1531 - val_accuracy: 0.7874\n",
      "Epoch 54/1000\n",
      "33/33 [==============================] - 0s 7ms/step - loss: 0.0132 - accuracy: 0.9961 - val_loss: 1.1335 - val_accuracy: 0.7835\n",
      "Epoch 55/1000\n",
      "33/33 [==============================] - 0s 6ms/step - loss: 0.0190 - accuracy: 0.9942 - val_loss: 1.1176 - val_accuracy: 0.7638\n",
      "Epoch 56/1000\n",
      "33/33 [==============================] - 0s 6ms/step - loss: 0.0095 - accuracy: 0.9961 - val_loss: 1.1757 - val_accuracy: 0.7835\n",
      "Epoch 57/1000\n",
      "33/33 [==============================] - 0s 5ms/step - loss: 0.0084 - accuracy: 0.9981 - val_loss: 1.2079 - val_accuracy: 0.7756\n",
      "Epoch 58/1000\n",
      "33/33 [==============================] - 0s 6ms/step - loss: 0.0088 - accuracy: 1.0000 - val_loss: 1.1466 - val_accuracy: 0.7913\n",
      "Epoch 59/1000\n",
      "33/33 [==============================] - 0s 6ms/step - loss: 0.0144 - accuracy: 0.9942 - val_loss: 1.1626 - val_accuracy: 0.7992\n",
      "Epoch 60/1000\n",
      "33/33 [==============================] - 0s 6ms/step - loss: 0.0209 - accuracy: 0.9942 - val_loss: 1.1649 - val_accuracy: 0.7913\n",
      "Epoch 61/1000\n",
      "33/33 [==============================] - 0s 6ms/step - loss: 0.0089 - accuracy: 1.0000 - val_loss: 1.1536 - val_accuracy: 0.7992\n",
      "Epoch 62/1000\n",
      "33/33 [==============================] - 0s 6ms/step - loss: 0.0092 - accuracy: 1.0000 - val_loss: 1.0894 - val_accuracy: 0.7835\n",
      "Epoch 63/1000\n",
      "33/33 [==============================] - 0s 5ms/step - loss: 0.0161 - accuracy: 0.9981 - val_loss: 1.1004 - val_accuracy: 0.8031\n",
      "Epoch 64/1000\n",
      "33/33 [==============================] - 0s 5ms/step - loss: 0.0185 - accuracy: 0.9981 - val_loss: 1.1158 - val_accuracy: 0.7756\n",
      "Epoch 65/1000\n",
      "33/33 [==============================] - 0s 6ms/step - loss: 0.0176 - accuracy: 0.9942 - val_loss: 1.0535 - val_accuracy: 0.7835\n",
      "Epoch 66/1000\n",
      "33/33 [==============================] - 0s 6ms/step - loss: 0.0088 - accuracy: 1.0000 - val_loss: 1.1161 - val_accuracy: 0.7953\n",
      "Epoch 67/1000\n",
      "33/33 [==============================] - 0s 6ms/step - loss: 0.0172 - accuracy: 0.9961 - val_loss: 1.1232 - val_accuracy: 0.7913\n",
      "Epoch 68/1000\n",
      "33/33 [==============================] - ETA: 0s - loss: 0.0091 - accuracy: 1.00 - 0s 5ms/step - loss: 0.0086 - accuracy: 1.0000 - val_loss: 1.1056 - val_accuracy: 0.7795\n",
      "Epoch 69/1000\n",
      "33/33 [==============================] - 0s 5ms/step - loss: 0.0132 - accuracy: 0.9961 - val_loss: 1.1600 - val_accuracy: 0.7795\n",
      "Epoch 70/1000\n",
      "33/33 [==============================] - 0s 6ms/step - loss: 0.0098 - accuracy: 0.9981 - val_loss: 1.0670 - val_accuracy: 0.8071\n",
      "Epoch 71/1000\n",
      "33/33 [==============================] - 0s 5ms/step - loss: 0.0116 - accuracy: 0.9981 - val_loss: 1.0963 - val_accuracy: 0.7913\n",
      "Epoch 72/1000\n",
      "33/33 [==============================] - 0s 5ms/step - loss: 0.0116 - accuracy: 0.9981 - val_loss: 1.0487 - val_accuracy: 0.7795\n",
      "Epoch 73/1000\n",
      "33/33 [==============================] - 0s 6ms/step - loss: 0.0110 - accuracy: 0.9961 - val_loss: 1.1272 - val_accuracy: 0.7913\n",
      "Epoch 74/1000\n",
      "33/33 [==============================] - 0s 6ms/step - loss: 0.0217 - accuracy: 0.9942 - val_loss: 1.1453 - val_accuracy: 0.7835\n",
      "Epoch 75/1000\n",
      "33/33 [==============================] - 0s 5ms/step - loss: 0.0160 - accuracy: 0.9961 - val_loss: 1.1488 - val_accuracy: 0.7795\n",
      "Epoch 76/1000\n",
      "33/33 [==============================] - 0s 5ms/step - loss: 0.0126 - accuracy: 0.9942 - val_loss: 1.1904 - val_accuracy: 0.7717\n",
      "Epoch 77/1000\n",
      "33/33 [==============================] - 0s 6ms/step - loss: 0.0122 - accuracy: 0.9981 - val_loss: 1.0788 - val_accuracy: 0.7874\n",
      "Epoch 78/1000\n",
      "33/33 [==============================] - 0s 5ms/step - loss: 0.0164 - accuracy: 0.9942 - val_loss: 1.1930 - val_accuracy: 0.7756\n",
      "Epoch 79/1000\n",
      "33/33 [==============================] - 0s 5ms/step - loss: 0.0125 - accuracy: 0.9961 - val_loss: 1.0943 - val_accuracy: 0.7835\n",
      "Epoch 80/1000\n",
      "33/33 [==============================] - 0s 5ms/step - loss: 0.0098 - accuracy: 1.0000 - val_loss: 1.0632 - val_accuracy: 0.7874\n",
      "Epoch 81/1000\n",
      "33/33 [==============================] - 0s 5ms/step - loss: 0.0105 - accuracy: 0.9942 - val_loss: 1.1974 - val_accuracy: 0.7992\n",
      "Epoch 82/1000\n",
      "33/33 [==============================] - 0s 6ms/step - loss: 0.0117 - accuracy: 0.9961 - val_loss: 1.1689 - val_accuracy: 0.8031\n",
      "Epoch 83/1000\n",
      "33/33 [==============================] - 0s 5ms/step - loss: 0.0253 - accuracy: 0.9922 - val_loss: 1.2150 - val_accuracy: 0.7953\n",
      "Epoch 84/1000\n",
      "33/33 [==============================] - 0s 5ms/step - loss: 0.0067 - accuracy: 1.0000 - val_loss: 1.0993 - val_accuracy: 0.7835\n",
      "Epoch 85/1000\n",
      "33/33 [==============================] - 0s 5ms/step - loss: 0.0072 - accuracy: 1.0000 - val_loss: 1.2061 - val_accuracy: 0.7795\n",
      "Epoch 86/1000\n",
      "33/33 [==============================] - 0s 5ms/step - loss: 0.0098 - accuracy: 0.9961 - val_loss: 1.0942 - val_accuracy: 0.7992\n",
      "Epoch 87/1000\n",
      "33/33 [==============================] - 0s 5ms/step - loss: 0.0068 - accuracy: 1.0000 - val_loss: 1.1492 - val_accuracy: 0.8031\n",
      "Epoch 88/1000\n",
      "33/33 [==============================] - 0s 5ms/step - loss: 0.0117 - accuracy: 0.9961 - val_loss: 1.1545 - val_accuracy: 0.7953\n",
      "Epoch 89/1000\n",
      "33/33 [==============================] - 0s 5ms/step - loss: 0.0123 - accuracy: 0.9981 - val_loss: 1.1285 - val_accuracy: 0.7756\n",
      "Epoch 90/1000\n",
      "33/33 [==============================] - 0s 6ms/step - loss: 0.0179 - accuracy: 0.9961 - val_loss: 1.1557 - val_accuracy: 0.7953\n",
      "Epoch 91/1000\n",
      "33/33 [==============================] - 0s 6ms/step - loss: 0.0120 - accuracy: 0.9961 - val_loss: 1.1931 - val_accuracy: 0.7638\n",
      "Epoch 92/1000\n",
      "33/33 [==============================] - 0s 7ms/step - loss: 0.0092 - accuracy: 0.9961 - val_loss: 1.1317 - val_accuracy: 0.7835\n",
      "Epoch 93/1000\n",
      "33/33 [==============================] - 0s 8ms/step - loss: 0.0136 - accuracy: 0.9961 - val_loss: 1.1582 - val_accuracy: 0.7835\n",
      "Epoch 94/1000\n",
      "33/33 [==============================] - 0s 8ms/step - loss: 0.0148 - accuracy: 0.9942 - val_loss: 1.1320 - val_accuracy: 0.7795\n",
      "Epoch 95/1000\n",
      "33/33 [==============================] - 0s 8ms/step - loss: 0.0166 - accuracy: 0.9961 - val_loss: 1.0733 - val_accuracy: 0.7795\n",
      "Epoch 96/1000\n",
      "33/33 [==============================] - 0s 7ms/step - loss: 0.0132 - accuracy: 0.9961 - val_loss: 1.1732 - val_accuracy: 0.7913\n",
      "Epoch 97/1000\n",
      "33/33 [==============================] - 0s 7ms/step - loss: 0.0097 - accuracy: 0.9981 - val_loss: 1.2279 - val_accuracy: 0.7913\n",
      "Epoch 98/1000\n",
      "33/33 [==============================] - 0s 7ms/step - loss: 0.0105 - accuracy: 1.0000 - val_loss: 1.2411 - val_accuracy: 0.7913\n",
      "Epoch 99/1000\n",
      "33/33 [==============================] - 0s 7ms/step - loss: 0.0356 - accuracy: 0.9942 - val_loss: 1.0729 - val_accuracy: 0.7874\n",
      "Epoch 100/1000\n",
      "33/33 [==============================] - 0s 6ms/step - loss: 0.0074 - accuracy: 0.9981 - val_loss: 1.1415 - val_accuracy: 0.7835\n",
      "Epoch 101/1000\n",
      "33/33 [==============================] - 0s 6ms/step - loss: 0.0084 - accuracy: 0.9961 - val_loss: 1.2260 - val_accuracy: 0.7795\n",
      "Epoch 102/1000\n",
      "33/33 [==============================] - 0s 6ms/step - loss: 0.0079 - accuracy: 1.0000 - val_loss: 1.1757 - val_accuracy: 0.7717\n",
      "Epoch 103/1000\n",
      "33/33 [==============================] - 0s 6ms/step - loss: 0.0156 - accuracy: 0.9961 - val_loss: 1.0916 - val_accuracy: 0.7992\n",
      "Epoch 104/1000\n",
      "33/33 [==============================] - 0s 7ms/step - loss: 0.0168 - accuracy: 0.9981 - val_loss: 1.1484 - val_accuracy: 0.7835\n",
      "Epoch 105/1000\n",
      "33/33 [==============================] - 0s 6ms/step - loss: 0.0184 - accuracy: 0.9942 - val_loss: 1.2020 - val_accuracy: 0.7913\n",
      "Epoch 106/1000\n",
      "33/33 [==============================] - 0s 6ms/step - loss: 0.0091 - accuracy: 0.9981 - val_loss: 1.1520 - val_accuracy: 0.7874\n",
      "Epoch 107/1000\n",
      "33/33 [==============================] - 0s 6ms/step - loss: 0.0139 - accuracy: 0.9981 - val_loss: 1.1821 - val_accuracy: 0.7795\n",
      "Epoch 108/1000\n",
      "33/33 [==============================] - 0s 6ms/step - loss: 0.0074 - accuracy: 1.0000 - val_loss: 1.2039 - val_accuracy: 0.7913\n",
      "Epoch 109/1000\n",
      "33/33 [==============================] - 0s 6ms/step - loss: 0.0105 - accuracy: 0.9981 - val_loss: 1.2937 - val_accuracy: 0.7717\n",
      "Epoch 110/1000\n",
      "33/33 [==============================] - 0s 6ms/step - loss: 0.0086 - accuracy: 0.9981 - val_loss: 1.1722 - val_accuracy: 0.7717\n",
      "Epoch 111/1000\n",
      "33/33 [==============================] - 0s 6ms/step - loss: 0.0256 - accuracy: 0.9922 - val_loss: 1.1228 - val_accuracy: 0.7874\n",
      "Epoch 112/1000\n",
      "33/33 [==============================] - 0s 6ms/step - loss: 0.0109 - accuracy: 0.9981 - val_loss: 1.0891 - val_accuracy: 0.7756\n",
      "Epoch 113/1000\n",
      "33/33 [==============================] - 0s 6ms/step - loss: 0.0165 - accuracy: 0.9942 - val_loss: 1.2913 - val_accuracy: 0.7717\n",
      "Epoch 114/1000\n",
      "33/33 [==============================] - 0s 6ms/step - loss: 0.0107 - accuracy: 0.9981 - val_loss: 1.2162 - val_accuracy: 0.7756\n",
      "Epoch 115/1000\n",
      "33/33 [==============================] - 0s 6ms/step - loss: 0.0105 - accuracy: 0.9981 - val_loss: 1.1744 - val_accuracy: 0.7835\n",
      "Epoch 116/1000\n",
      "33/33 [==============================] - 0s 6ms/step - loss: 0.0093 - accuracy: 0.9981 - val_loss: 1.2618 - val_accuracy: 0.7756\n",
      "Epoch 117/1000\n",
      "33/33 [==============================] - 0s 6ms/step - loss: 0.0066 - accuracy: 1.0000 - val_loss: 1.1032 - val_accuracy: 0.7795\n",
      "Epoch 118/1000\n",
      "33/33 [==============================] - 0s 6ms/step - loss: 0.0100 - accuracy: 0.9981 - val_loss: 1.1470 - val_accuracy: 0.7874\n",
      "Epoch 119/1000\n",
      "33/33 [==============================] - 0s 6ms/step - loss: 0.0060 - accuracy: 1.0000 - val_loss: 1.1675 - val_accuracy: 0.7874\n",
      "Epoch 120/1000\n",
      "33/33 [==============================] - 0s 6ms/step - loss: 0.0217 - accuracy: 0.9903 - val_loss: 1.1333 - val_accuracy: 0.7756\n",
      "Epoch 121/1000\n",
      "33/33 [==============================] - 0s 6ms/step - loss: 0.0111 - accuracy: 0.9981 - val_loss: 1.1829 - val_accuracy: 0.7795\n",
      "Epoch 122/1000\n",
      "33/33 [==============================] - 0s 6ms/step - loss: 0.0130 - accuracy: 0.9961 - val_loss: 1.1966 - val_accuracy: 0.7913\n",
      "Epoch 123/1000\n",
      "33/33 [==============================] - 0s 6ms/step - loss: 0.0102 - accuracy: 0.9981 - val_loss: 1.2050 - val_accuracy: 0.7795\n",
      "Epoch 124/1000\n",
      "33/33 [==============================] - 0s 6ms/step - loss: 0.0099 - accuracy: 0.9981 - val_loss: 1.1826 - val_accuracy: 0.7835\n",
      "Epoch 125/1000\n",
      "33/33 [==============================] - 0s 6ms/step - loss: 0.0098 - accuracy: 0.9981 - val_loss: 1.1334 - val_accuracy: 0.7756\n",
      "Epoch 126/1000\n",
      "33/33 [==============================] - 0s 5ms/step - loss: 0.0054 - accuracy: 0.9981 - val_loss: 1.0726 - val_accuracy: 0.7913\n",
      "Epoch 127/1000\n",
      "33/33 [==============================] - 0s 5ms/step - loss: 0.0084 - accuracy: 0.9981 - val_loss: 1.2159 - val_accuracy: 0.7913\n",
      "Epoch 128/1000\n",
      "33/33 [==============================] - 0s 6ms/step - loss: 0.0088 - accuracy: 0.9981 - val_loss: 1.1646 - val_accuracy: 0.7913\n",
      "Epoch 129/1000\n",
      "33/33 [==============================] - 0s 6ms/step - loss: 0.0088 - accuracy: 0.9981 - val_loss: 1.1695 - val_accuracy: 0.7874\n",
      "Epoch 130/1000\n",
      "33/33 [==============================] - 0s 6ms/step - loss: 0.0292 - accuracy: 0.9883 - val_loss: 1.2410 - val_accuracy: 0.7677\n",
      "Epoch 131/1000\n",
      "33/33 [==============================] - 0s 6ms/step - loss: 0.0173 - accuracy: 0.9981 - val_loss: 1.2707 - val_accuracy: 0.7756\n",
      "Epoch 132/1000\n",
      "33/33 [==============================] - 0s 8ms/step - loss: 0.0089 - accuracy: 0.9981 - val_loss: 1.1363 - val_accuracy: 0.8031\n",
      "Epoch 133/1000\n",
      "33/33 [==============================] - 0s 8ms/step - loss: 0.0074 - accuracy: 0.9981 - val_loss: 1.1522 - val_accuracy: 0.8031\n",
      "Epoch 134/1000\n",
      "33/33 [==============================] - 0s 8ms/step - loss: 0.0133 - accuracy: 0.9981 - val_loss: 1.1462 - val_accuracy: 0.7913\n",
      "Epoch 135/1000\n",
      "33/33 [==============================] - 0s 7ms/step - loss: 0.0080 - accuracy: 1.0000 - val_loss: 1.2109 - val_accuracy: 0.8031\n",
      "Epoch 136/1000\n",
      "33/33 [==============================] - 0s 7ms/step - loss: 0.0135 - accuracy: 0.9981 - val_loss: 1.1411 - val_accuracy: 0.7835\n",
      "Epoch 137/1000\n",
      "33/33 [==============================] - 0s 7ms/step - loss: 0.0084 - accuracy: 1.0000 - val_loss: 1.1118 - val_accuracy: 0.7717\n",
      "Epoch 138/1000\n",
      "33/33 [==============================] - ETA: 0s - loss: 0.0061 - accuracy: 0.99 - 0s 8ms/step - loss: 0.0061 - accuracy: 0.9981 - val_loss: 1.1431 - val_accuracy: 0.7992\n",
      "Epoch 139/1000\n",
      "33/33 [==============================] - 0s 8ms/step - loss: 0.0157 - accuracy: 0.9942 - val_loss: 1.1651 - val_accuracy: 0.7638\n",
      "Epoch 140/1000\n",
      "33/33 [==============================] - 0s 7ms/step - loss: 0.0098 - accuracy: 0.9981 - val_loss: 1.1388 - val_accuracy: 0.7992\n",
      "Epoch 141/1000\n",
      "33/33 [==============================] - 0s 7ms/step - loss: 0.0121 - accuracy: 0.9961 - val_loss: 1.1561 - val_accuracy: 0.7756\n",
      "Epoch 142/1000\n",
      "33/33 [==============================] - 0s 7ms/step - loss: 0.0099 - accuracy: 0.9961 - val_loss: 1.3407 - val_accuracy: 0.7638\n",
      "Epoch 143/1000\n",
      "33/33 [==============================] - 0s 7ms/step - loss: 0.0087 - accuracy: 0.9961 - val_loss: 1.1757 - val_accuracy: 0.7992\n",
      "Epoch 144/1000\n",
      "33/33 [==============================] - 0s 7ms/step - loss: 0.0070 - accuracy: 0.9981 - val_loss: 1.1862 - val_accuracy: 0.7598\n",
      "Epoch 145/1000\n",
      "33/33 [==============================] - 0s 7ms/step - loss: 0.0073 - accuracy: 1.0000 - val_loss: 1.1874 - val_accuracy: 0.7992\n",
      "Epoch 146/1000\n",
      "33/33 [==============================] - 0s 7ms/step - loss: 0.0113 - accuracy: 0.9961 - val_loss: 1.1488 - val_accuracy: 0.7874\n",
      "Epoch 147/1000\n",
      "33/33 [==============================] - 0s 7ms/step - loss: 0.0162 - accuracy: 0.9961 - val_loss: 1.0756 - val_accuracy: 0.7874\n",
      "Epoch 148/1000\n",
      "33/33 [==============================] - 0s 7ms/step - loss: 0.0097 - accuracy: 0.9981 - val_loss: 1.1474 - val_accuracy: 0.7638\n",
      "Epoch 149/1000\n",
      "33/33 [==============================] - 0s 7ms/step - loss: 0.0058 - accuracy: 1.0000 - val_loss: 1.1571 - val_accuracy: 0.7756\n",
      "Epoch 150/1000\n",
      "33/33 [==============================] - 0s 7ms/step - loss: 0.0069 - accuracy: 0.9981 - val_loss: 1.1446 - val_accuracy: 0.7913\n",
      "Epoch 151/1000\n",
      "33/33 [==============================] - 0s 7ms/step - loss: 0.0046 - accuracy: 1.0000 - val_loss: 1.2011 - val_accuracy: 0.7874\n",
      "Epoch 152/1000\n",
      "33/33 [==============================] - 0s 7ms/step - loss: 0.0079 - accuracy: 0.9981 - val_loss: 1.2608 - val_accuracy: 0.7717\n",
      "Epoch 153/1000\n",
      "33/33 [==============================] - 0s 7ms/step - loss: 0.0155 - accuracy: 0.9961 - val_loss: 1.2462 - val_accuracy: 0.7756\n",
      "Epoch 154/1000\n",
      "33/33 [==============================] - 0s 6ms/step - loss: 0.0128 - accuracy: 0.9981 - val_loss: 1.2252 - val_accuracy: 0.7874\n",
      "Epoch 155/1000\n",
      "33/33 [==============================] - 0s 7ms/step - loss: 0.0056 - accuracy: 1.0000 - val_loss: 1.2297 - val_accuracy: 0.7717\n",
      "Epoch 156/1000\n",
      "33/33 [==============================] - 0s 7ms/step - loss: 0.0109 - accuracy: 0.9981 - val_loss: 1.1816 - val_accuracy: 0.7756\n",
      "Epoch 157/1000\n",
      "33/33 [==============================] - 0s 7ms/step - loss: 0.0134 - accuracy: 0.9981 - val_loss: 1.1758 - val_accuracy: 0.7835\n",
      "Epoch 158/1000\n",
      "33/33 [==============================] - 0s 7ms/step - loss: 0.0150 - accuracy: 0.9942 - val_loss: 1.1676 - val_accuracy: 0.7717\n",
      "Epoch 159/1000\n",
      "33/33 [==============================] - 0s 6ms/step - loss: 0.0218 - accuracy: 0.9981 - val_loss: 1.2089 - val_accuracy: 0.7795\n",
      "Epoch 160/1000\n",
      "33/33 [==============================] - 0s 6ms/step - loss: 0.0150 - accuracy: 0.9942 - val_loss: 1.1523 - val_accuracy: 0.7913\n",
      "Epoch 161/1000\n",
      "33/33 [==============================] - 0s 6ms/step - loss: 0.0096 - accuracy: 0.9961 - val_loss: 1.1748 - val_accuracy: 0.7677\n",
      "Epoch 162/1000\n",
      "33/33 [==============================] - 0s 7ms/step - loss: 0.0102 - accuracy: 0.9961 - val_loss: 1.1871 - val_accuracy: 0.7756\n",
      "Epoch 163/1000\n",
      "33/33 [==============================] - 0s 7ms/step - loss: 0.0264 - accuracy: 0.9922 - val_loss: 1.1567 - val_accuracy: 0.7874\n",
      "Epoch 164/1000\n",
      "33/33 [==============================] - 0s 6ms/step - loss: 0.0060 - accuracy: 1.0000 - val_loss: 1.3019 - val_accuracy: 0.7638\n",
      "Epoch 165/1000\n",
      "33/33 [==============================] - 0s 6ms/step - loss: 0.0149 - accuracy: 0.9942 - val_loss: 1.1374 - val_accuracy: 0.7756\n",
      "Epoch 166/1000\n",
      "33/33 [==============================] - 0s 6ms/step - loss: 0.0084 - accuracy: 0.9981 - val_loss: 1.1534 - val_accuracy: 0.7913\n",
      "Epoch 167/1000\n",
      "33/33 [==============================] - 0s 6ms/step - loss: 0.0077 - accuracy: 1.0000 - val_loss: 1.1465 - val_accuracy: 0.7756\n",
      "Epoch 168/1000\n",
      "33/33 [==============================] - 0s 6ms/step - loss: 0.0071 - accuracy: 0.9981 - val_loss: 1.2182 - val_accuracy: 0.7874\n",
      "Epoch 169/1000\n",
      "33/33 [==============================] - 0s 6ms/step - loss: 0.0094 - accuracy: 0.9981 - val_loss: 1.1603 - val_accuracy: 0.8031\n",
      "Epoch 170/1000\n",
      "33/33 [==============================] - 0s 6ms/step - loss: 0.0138 - accuracy: 0.9942 - val_loss: 1.2489 - val_accuracy: 0.7756\n",
      "Epoch 171/1000\n",
      "33/33 [==============================] - 0s 6ms/step - loss: 0.0078 - accuracy: 0.9981 - val_loss: 1.1914 - val_accuracy: 0.7835\n",
      "Epoch 172/1000\n",
      "33/33 [==============================] - 0s 6ms/step - loss: 0.0113 - accuracy: 0.9961 - val_loss: 1.1125 - val_accuracy: 0.7795\n",
      "Epoch 173/1000\n",
      "33/33 [==============================] - 0s 6ms/step - loss: 0.0049 - accuracy: 1.0000 - val_loss: 1.1701 - val_accuracy: 0.7913\n",
      "Epoch 174/1000\n",
      "33/33 [==============================] - 0s 7ms/step - loss: 0.0140 - accuracy: 0.9961 - val_loss: 1.1017 - val_accuracy: 0.7913\n",
      "Epoch 175/1000\n",
      "33/33 [==============================] - 0s 6ms/step - loss: 0.0088 - accuracy: 0.9981 - val_loss: 1.1476 - val_accuracy: 0.7717\n",
      "Epoch 176/1000\n",
      "33/33 [==============================] - 0s 6ms/step - loss: 0.0126 - accuracy: 0.9981 - val_loss: 1.1211 - val_accuracy: 0.7992\n",
      "Epoch 177/1000\n",
      "33/33 [==============================] - 0s 6ms/step - loss: 0.0102 - accuracy: 1.0000 - val_loss: 1.1652 - val_accuracy: 0.7913\n",
      "Epoch 178/1000\n",
      "33/33 [==============================] - 0s 6ms/step - loss: 0.0063 - accuracy: 1.0000 - val_loss: 1.1417 - val_accuracy: 0.7913\n",
      "Epoch 179/1000\n",
      "33/33 [==============================] - 0s 6ms/step - loss: 0.0085 - accuracy: 1.0000 - val_loss: 1.2452 - val_accuracy: 0.7795\n",
      "Epoch 180/1000\n",
      "33/33 [==============================] - 0s 6ms/step - loss: 0.0138 - accuracy: 0.9981 - val_loss: 1.1058 - val_accuracy: 0.7756\n",
      "Epoch 181/1000\n",
      "33/33 [==============================] - 0s 6ms/step - loss: 0.0096 - accuracy: 0.9961 - val_loss: 1.1719 - val_accuracy: 0.7756\n",
      "Epoch 182/1000\n",
      "33/33 [==============================] - 0s 6ms/step - loss: 0.0077 - accuracy: 0.9981 - val_loss: 1.1453 - val_accuracy: 0.8031\n",
      "Epoch 183/1000\n",
      "33/33 [==============================] - 0s 6ms/step - loss: 0.0093 - accuracy: 1.0000 - val_loss: 1.3175 - val_accuracy: 0.7677\n",
      "Epoch 184/1000\n",
      "33/33 [==============================] - 0s 6ms/step - loss: 0.0067 - accuracy: 0.9981 - val_loss: 1.1426 - val_accuracy: 0.7953\n",
      "Epoch 185/1000\n",
      "33/33 [==============================] - 0s 6ms/step - loss: 0.0058 - accuracy: 0.9981 - val_loss: 1.2238 - val_accuracy: 0.7795\n",
      "Epoch 186/1000\n",
      "33/33 [==============================] - 0s 6ms/step - loss: 0.0082 - accuracy: 1.0000 - val_loss: 1.1770 - val_accuracy: 0.7913\n",
      "Epoch 187/1000\n",
      "33/33 [==============================] - 0s 6ms/step - loss: 0.0101 - accuracy: 0.9961 - val_loss: 1.1704 - val_accuracy: 0.7835\n",
      "Epoch 188/1000\n",
      "33/33 [==============================] - 0s 6ms/step - loss: 0.0048 - accuracy: 1.0000 - val_loss: 1.2936 - val_accuracy: 0.7795\n",
      "Epoch 189/1000\n",
      "33/33 [==============================] - 0s 6ms/step - loss: 0.0076 - accuracy: 1.0000 - val_loss: 1.2869 - val_accuracy: 0.7835\n",
      "Epoch 190/1000\n",
      "33/33 [==============================] - 0s 6ms/step - loss: 0.0193 - accuracy: 0.9942 - val_loss: 1.2594 - val_accuracy: 0.7913\n",
      "Epoch 191/1000\n",
      "33/33 [==============================] - 0s 6ms/step - loss: 0.0183 - accuracy: 0.9922 - val_loss: 1.1512 - val_accuracy: 0.7756\n",
      "Epoch 192/1000\n",
      "33/33 [==============================] - 0s 6ms/step - loss: 0.0069 - accuracy: 0.9981 - val_loss: 1.3195 - val_accuracy: 0.7677\n",
      "Epoch 193/1000\n",
      "33/33 [==============================] - 0s 6ms/step - loss: 0.0080 - accuracy: 0.9981 - val_loss: 1.1751 - val_accuracy: 0.7953\n",
      "Epoch 194/1000\n",
      "33/33 [==============================] - 0s 7ms/step - loss: 0.0101 - accuracy: 0.9981 - val_loss: 1.1554 - val_accuracy: 0.7756\n",
      "Epoch 195/1000\n",
      "33/33 [==============================] - 0s 6ms/step - loss: 0.0118 - accuracy: 0.9961 - val_loss: 1.0894 - val_accuracy: 0.7953\n",
      "Epoch 196/1000\n",
      "33/33 [==============================] - 0s 6ms/step - loss: 0.0097 - accuracy: 0.9961 - val_loss: 1.2218 - val_accuracy: 0.7913\n",
      "Epoch 197/1000\n",
      "33/33 [==============================] - 0s 6ms/step - loss: 0.0046 - accuracy: 1.0000 - val_loss: 1.1754 - val_accuracy: 0.7795\n",
      "Epoch 198/1000\n",
      "33/33 [==============================] - 0s 6ms/step - loss: 0.0178 - accuracy: 0.9922 - val_loss: 1.3049 - val_accuracy: 0.7953\n",
      "Epoch 199/1000\n",
      "33/33 [==============================] - 0s 7ms/step - loss: 0.0071 - accuracy: 1.0000 - val_loss: 1.2233 - val_accuracy: 0.7835\n",
      "Epoch 200/1000\n",
      "33/33 [==============================] - ETA: 0s - loss: 0.0098 - accuracy: 0.99 - 0s 7ms/step - loss: 0.0140 - accuracy: 0.9942 - val_loss: 1.2476 - val_accuracy: 0.7913\n",
      "Epoch 201/1000\n",
      "33/33 [==============================] - 0s 7ms/step - loss: 0.0140 - accuracy: 0.9981 - val_loss: 1.1362 - val_accuracy: 0.7913\n",
      "Epoch 202/1000\n",
      "33/33 [==============================] - 0s 7ms/step - loss: 0.0088 - accuracy: 0.9981 - val_loss: 1.1398 - val_accuracy: 0.7874\n",
      "Epoch 203/1000\n",
      "33/33 [==============================] - 0s 7ms/step - loss: 0.0105 - accuracy: 0.9942 - val_loss: 1.2185 - val_accuracy: 0.7953\n",
      "Epoch 204/1000\n",
      "33/33 [==============================] - 0s 7ms/step - loss: 0.0153 - accuracy: 0.9942 - val_loss: 1.1674 - val_accuracy: 0.7874\n",
      "Epoch 205/1000\n",
      "33/33 [==============================] - 0s 7ms/step - loss: 0.0055 - accuracy: 1.0000 - val_loss: 1.1145 - val_accuracy: 0.7953\n",
      "Epoch 206/1000\n",
      "33/33 [==============================] - 0s 7ms/step - loss: 0.0074 - accuracy: 0.9981 - val_loss: 1.2382 - val_accuracy: 0.7835\n",
      "Epoch 207/1000\n",
      "33/33 [==============================] - 0s 7ms/step - loss: 0.0064 - accuracy: 0.9981 - val_loss: 1.2674 - val_accuracy: 0.7677\n",
      "Epoch 208/1000\n",
      "33/33 [==============================] - 0s 7ms/step - loss: 0.0047 - accuracy: 1.0000 - val_loss: 1.2110 - val_accuracy: 0.7717\n",
      "Epoch 209/1000\n",
      "33/33 [==============================] - 0s 7ms/step - loss: 0.0157 - accuracy: 0.9981 - val_loss: 1.2895 - val_accuracy: 0.7913\n",
      "Epoch 210/1000\n",
      "33/33 [==============================] - 0s 7ms/step - loss: 0.0093 - accuracy: 0.9981 - val_loss: 1.3245 - val_accuracy: 0.7835\n",
      "Epoch 211/1000\n",
      "33/33 [==============================] - 0s 7ms/step - loss: 0.0083 - accuracy: 0.9961 - val_loss: 1.2451 - val_accuracy: 0.7677\n",
      "Epoch 212/1000\n",
      "33/33 [==============================] - 0s 6ms/step - loss: 0.0141 - accuracy: 0.9961 - val_loss: 1.1938 - val_accuracy: 0.7795\n",
      "Epoch 213/1000\n",
      "33/33 [==============================] - 0s 7ms/step - loss: 0.0123 - accuracy: 0.9981 - val_loss: 1.1852 - val_accuracy: 0.7874\n",
      "Epoch 214/1000\n",
      "33/33 [==============================] - 0s 6ms/step - loss: 0.0089 - accuracy: 0.9981 - val_loss: 1.1852 - val_accuracy: 0.8031\n",
      "Epoch 215/1000\n",
      "33/33 [==============================] - 0s 7ms/step - loss: 0.0083 - accuracy: 1.0000 - val_loss: 1.2468 - val_accuracy: 0.7874\n",
      "Epoch 216/1000\n",
      "33/33 [==============================] - 0s 7ms/step - loss: 0.0109 - accuracy: 0.9961 - val_loss: 1.4680 - val_accuracy: 0.7756\n",
      "Epoch 217/1000\n",
      "33/33 [==============================] - 0s 6ms/step - loss: 0.0103 - accuracy: 0.9981 - val_loss: 1.2255 - val_accuracy: 0.7874\n",
      "Epoch 218/1000\n",
      "33/33 [==============================] - 0s 7ms/step - loss: 0.0076 - accuracy: 0.9981 - val_loss: 1.1824 - val_accuracy: 0.8031\n",
      "Epoch 219/1000\n",
      "33/33 [==============================] - 0s 7ms/step - loss: 0.0091 - accuracy: 1.0000 - val_loss: 1.2249 - val_accuracy: 0.7913\n",
      "Epoch 220/1000\n",
      "33/33 [==============================] - 0s 7ms/step - loss: 0.0076 - accuracy: 0.9981 - val_loss: 1.2548 - val_accuracy: 0.7874\n",
      "Epoch 221/1000\n",
      "33/33 [==============================] - 0s 6ms/step - loss: 0.0053 - accuracy: 1.0000 - val_loss: 1.1754 - val_accuracy: 0.7795\n",
      "Epoch 222/1000\n",
      "33/33 [==============================] - 0s 6ms/step - loss: 0.0116 - accuracy: 1.0000 - val_loss: 1.1615 - val_accuracy: 0.7992\n",
      "Epoch 223/1000\n",
      "33/33 [==============================] - 0s 7ms/step - loss: 0.0085 - accuracy: 0.9981 - val_loss: 1.1718 - val_accuracy: 0.7795\n",
      "Epoch 224/1000\n",
      "33/33 [==============================] - 0s 6ms/step - loss: 0.0179 - accuracy: 0.9942 - val_loss: 1.1889 - val_accuracy: 0.8031\n",
      "Epoch 225/1000\n",
      "33/33 [==============================] - 0s 7ms/step - loss: 0.0132 - accuracy: 0.9961 - val_loss: 1.1302 - val_accuracy: 0.7874\n",
      "Epoch 226/1000\n",
      "33/33 [==============================] - 0s 7ms/step - loss: 0.0054 - accuracy: 1.0000 - val_loss: 1.3038 - val_accuracy: 0.7953\n",
      "Epoch 227/1000\n",
      "33/33 [==============================] - 0s 6ms/step - loss: 0.0203 - accuracy: 0.9942 - val_loss: 1.1553 - val_accuracy: 0.7953\n",
      "Epoch 228/1000\n",
      "33/33 [==============================] - 0s 7ms/step - loss: 0.0087 - accuracy: 0.9961 - val_loss: 1.2856 - val_accuracy: 0.7874\n",
      "Epoch 229/1000\n",
      "33/33 [==============================] - 0s 6ms/step - loss: 0.0110 - accuracy: 0.9981 - val_loss: 1.1811 - val_accuracy: 0.7913\n",
      "Epoch 230/1000\n",
      "33/33 [==============================] - 0s 6ms/step - loss: 0.0060 - accuracy: 1.0000 - val_loss: 1.2582 - val_accuracy: 0.7756\n",
      "Epoch 231/1000\n",
      "33/33 [==============================] - 0s 6ms/step - loss: 0.0047 - accuracy: 1.0000 - val_loss: 1.1988 - val_accuracy: 0.7874\n",
      "Epoch 232/1000\n",
      "33/33 [==============================] - 0s 6ms/step - loss: 0.0054 - accuracy: 0.9981 - val_loss: 1.2847 - val_accuracy: 0.7717\n",
      "Epoch 233/1000\n",
      "33/33 [==============================] - 0s 6ms/step - loss: 0.0136 - accuracy: 0.9942 - val_loss: 1.2194 - val_accuracy: 0.7756\n",
      "Epoch 234/1000\n",
      "33/33 [==============================] - 0s 6ms/step - loss: 0.0120 - accuracy: 0.9981 - val_loss: 1.3139 - val_accuracy: 0.7717\n",
      "Epoch 235/1000\n",
      "33/33 [==============================] - 0s 6ms/step - loss: 0.0112 - accuracy: 0.9981 - val_loss: 1.2015 - val_accuracy: 0.8031\n",
      "Epoch 236/1000\n",
      "33/33 [==============================] - 0s 6ms/step - loss: 0.0107 - accuracy: 0.9961 - val_loss: 1.2592 - val_accuracy: 0.7756\n",
      "Epoch 237/1000\n",
      "33/33 [==============================] - 0s 6ms/step - loss: 0.0133 - accuracy: 0.9961 - val_loss: 1.2441 - val_accuracy: 0.7874\n",
      "Epoch 238/1000\n",
      "33/33 [==============================] - 0s 6ms/step - loss: 0.0088 - accuracy: 0.9981 - val_loss: 1.3655 - val_accuracy: 0.7756\n",
      "Epoch 239/1000\n",
      "33/33 [==============================] - 0s 6ms/step - loss: 0.0048 - accuracy: 1.0000 - val_loss: 1.1971 - val_accuracy: 0.7913\n",
      "Epoch 240/1000\n",
      "33/33 [==============================] - 0s 6ms/step - loss: 0.0076 - accuracy: 0.9981 - val_loss: 1.1949 - val_accuracy: 0.8071\n",
      "Epoch 241/1000\n",
      "33/33 [==============================] - 0s 6ms/step - loss: 0.0104 - accuracy: 0.9961 - val_loss: 1.1752 - val_accuracy: 0.7874\n",
      "Epoch 242/1000\n",
      "33/33 [==============================] - 0s 6ms/step - loss: 0.0088 - accuracy: 0.9981 - val_loss: 1.3114 - val_accuracy: 0.7677\n",
      "Epoch 243/1000\n",
      "33/33 [==============================] - 0s 6ms/step - loss: 0.0044 - accuracy: 1.0000 - val_loss: 1.1960 - val_accuracy: 0.7795\n",
      "Epoch 244/1000\n",
      "33/33 [==============================] - 0s 6ms/step - loss: 0.0192 - accuracy: 0.9942 - val_loss: 1.2305 - val_accuracy: 0.7874\n",
      "Epoch 245/1000\n",
      "33/33 [==============================] - 0s 6ms/step - loss: 0.0132 - accuracy: 0.9961 - val_loss: 1.1898 - val_accuracy: 0.7795\n",
      "Epoch 246/1000\n",
      "33/33 [==============================] - 0s 6ms/step - loss: 0.0075 - accuracy: 0.9981 - val_loss: 1.1472 - val_accuracy: 0.7874\n",
      "Epoch 247/1000\n",
      "33/33 [==============================] - 0s 6ms/step - loss: 0.0057 - accuracy: 1.0000 - val_loss: 1.3201 - val_accuracy: 0.7795\n",
      "Epoch 248/1000\n",
      "33/33 [==============================] - 0s 6ms/step - loss: 0.0112 - accuracy: 0.9981 - val_loss: 1.1827 - val_accuracy: 0.7913\n",
      "Epoch 249/1000\n",
      "33/33 [==============================] - 0s 6ms/step - loss: 0.0077 - accuracy: 0.9981 - val_loss: 1.1874 - val_accuracy: 0.7756\n",
      "Epoch 250/1000\n",
      "33/33 [==============================] - 0s 6ms/step - loss: 0.0071 - accuracy: 0.9981 - val_loss: 1.2623 - val_accuracy: 0.7756\n",
      "Epoch 251/1000\n",
      "33/33 [==============================] - 0s 6ms/step - loss: 0.0069 - accuracy: 1.0000 - val_loss: 1.2356 - val_accuracy: 0.7835\n",
      "Epoch 252/1000\n",
      "33/33 [==============================] - 0s 6ms/step - loss: 0.0045 - accuracy: 1.0000 - val_loss: 1.1782 - val_accuracy: 0.7992\n",
      "Epoch 253/1000\n",
      "33/33 [==============================] - 0s 6ms/step - loss: 0.0082 - accuracy: 0.9981 - val_loss: 1.2346 - val_accuracy: 0.7874\n",
      "Epoch 254/1000\n",
      "33/33 [==============================] - 0s 6ms/step - loss: 0.0075 - accuracy: 1.0000 - val_loss: 1.3528 - val_accuracy: 0.7756\n",
      "Epoch 255/1000\n",
      "33/33 [==============================] - 0s 6ms/step - loss: 0.0037 - accuracy: 1.0000 - val_loss: 1.2085 - val_accuracy: 0.8031\n",
      "Epoch 256/1000\n",
      "33/33 [==============================] - 0s 6ms/step - loss: 0.0204 - accuracy: 0.9883 - val_loss: 1.2058 - val_accuracy: 0.7953\n",
      "Epoch 257/1000\n",
      "33/33 [==============================] - 0s 6ms/step - loss: 0.0074 - accuracy: 0.9981 - val_loss: 1.2810 - val_accuracy: 0.8031\n",
      "Epoch 258/1000\n",
      "33/33 [==============================] - 0s 6ms/step - loss: 0.0033 - accuracy: 1.0000 - val_loss: 1.2168 - val_accuracy: 0.7874\n",
      "Epoch 259/1000\n",
      "33/33 [==============================] - 0s 6ms/step - loss: 0.0147 - accuracy: 0.9961 - val_loss: 1.2037 - val_accuracy: 0.7953\n",
      "Epoch 260/1000\n",
      "33/33 [==============================] - 0s 6ms/step - loss: 0.0081 - accuracy: 0.9981 - val_loss: 1.1775 - val_accuracy: 0.7795\n",
      "Epoch 261/1000\n",
      "33/33 [==============================] - 0s 7ms/step - loss: 0.0090 - accuracy: 0.9981 - val_loss: 1.2625 - val_accuracy: 0.7874\n",
      "Epoch 262/1000\n",
      "33/33 [==============================] - 0s 7ms/step - loss: 0.0128 - accuracy: 0.9942 - val_loss: 1.1752 - val_accuracy: 0.7953\n",
      "Epoch 263/1000\n",
      "33/33 [==============================] - 0s 6ms/step - loss: 0.0050 - accuracy: 1.0000 - val_loss: 1.2032 - val_accuracy: 0.7795\n",
      "Epoch 264/1000\n",
      "33/33 [==============================] - 0s 6ms/step - loss: 0.0045 - accuracy: 1.0000 - val_loss: 1.1915 - val_accuracy: 0.7953\n",
      "Epoch 265/1000\n",
      "33/33 [==============================] - 0s 6ms/step - loss: 0.0099 - accuracy: 1.0000 - val_loss: 1.1872 - val_accuracy: 0.7992\n",
      "Epoch 266/1000\n",
      "33/33 [==============================] - 0s 6ms/step - loss: 0.0044 - accuracy: 1.0000 - val_loss: 1.1864 - val_accuracy: 0.7874\n",
      "Epoch 267/1000\n",
      "33/33 [==============================] - 0s 6ms/step - loss: 0.0078 - accuracy: 0.9981 - val_loss: 1.1593 - val_accuracy: 0.7953\n",
      "Epoch 268/1000\n",
      "33/33 [==============================] - 0s 7ms/step - loss: 0.0088 - accuracy: 0.9981 - val_loss: 1.1799 - val_accuracy: 0.7874\n",
      "Epoch 269/1000\n",
      "33/33 [==============================] - 0s 7ms/step - loss: 0.0076 - accuracy: 0.9981 - val_loss: 1.2499 - val_accuracy: 0.7795\n",
      "Epoch 270/1000\n",
      "33/33 [==============================] - 0s 8ms/step - loss: 0.0085 - accuracy: 0.9981 - val_loss: 1.1723 - val_accuracy: 0.7913\n",
      "Epoch 271/1000\n",
      "33/33 [==============================] - 0s 8ms/step - loss: 0.0155 - accuracy: 0.9961 - val_loss: 1.1988 - val_accuracy: 0.7756\n",
      "Epoch 272/1000\n",
      "33/33 [==============================] - 0s 8ms/step - loss: 0.0070 - accuracy: 1.0000 - val_loss: 1.2343 - val_accuracy: 0.7835\n",
      "Epoch 273/1000\n",
      "33/33 [==============================] - 0s 7ms/step - loss: 0.0101 - accuracy: 0.9981 - val_loss: 1.1609 - val_accuracy: 0.8031\n",
      "Epoch 274/1000\n",
      "33/33 [==============================] - 0s 8ms/step - loss: 0.0095 - accuracy: 0.9961 - val_loss: 1.1349 - val_accuracy: 0.7874\n",
      "Epoch 275/1000\n",
      "33/33 [==============================] - 0s 9ms/step - loss: 0.0074 - accuracy: 0.9981 - val_loss: 1.1895 - val_accuracy: 0.7835\n",
      "Epoch 276/1000\n",
      "33/33 [==============================] - 0s 7ms/step - loss: 0.0183 - accuracy: 0.9942 - val_loss: 1.2168 - val_accuracy: 0.7913\n",
      "Epoch 277/1000\n",
      "33/33 [==============================] - 0s 7ms/step - loss: 0.0127 - accuracy: 0.9981 - val_loss: 1.2048 - val_accuracy: 0.7795\n",
      "Epoch 278/1000\n",
      "33/33 [==============================] - 0s 7ms/step - loss: 0.0065 - accuracy: 1.0000 - val_loss: 1.1934 - val_accuracy: 0.7992\n",
      "Epoch 279/1000\n",
      "33/33 [==============================] - 0s 8ms/step - loss: 0.0061 - accuracy: 1.0000 - val_loss: 1.2581 - val_accuracy: 0.7953\n",
      "Epoch 280/1000\n",
      "33/33 [==============================] - 0s 8ms/step - loss: 0.0136 - accuracy: 0.9981 - val_loss: 1.2733 - val_accuracy: 0.7992\n",
      "Epoch 281/1000\n",
      "33/33 [==============================] - 0s 9ms/step - loss: 0.0099 - accuracy: 0.9961 - val_loss: 1.2126 - val_accuracy: 0.7835\n",
      "Epoch 282/1000\n",
      "33/33 [==============================] - 0s 9ms/step - loss: 0.0081 - accuracy: 0.9981 - val_loss: 1.2436 - val_accuracy: 0.7953\n",
      "Epoch 283/1000\n",
      "33/33 [==============================] - 0s 8ms/step - loss: 0.0143 - accuracy: 0.9961 - val_loss: 1.2560 - val_accuracy: 0.7953\n",
      "Epoch 284/1000\n",
      "33/33 [==============================] - 0s 8ms/step - loss: 0.0086 - accuracy: 0.9981 - val_loss: 1.2860 - val_accuracy: 0.7953\n",
      "Epoch 285/1000\n",
      "33/33 [==============================] - 0s 7ms/step - loss: 0.0139 - accuracy: 0.9942 - val_loss: 1.2343 - val_accuracy: 0.7835\n",
      "Epoch 286/1000\n",
      "33/33 [==============================] - 0s 7ms/step - loss: 0.0150 - accuracy: 0.9961 - val_loss: 1.2787 - val_accuracy: 0.7913\n",
      "Epoch 287/1000\n",
      "33/33 [==============================] - 0s 7ms/step - loss: 0.0066 - accuracy: 0.9981 - val_loss: 1.3018 - val_accuracy: 0.7913\n",
      "Epoch 288/1000\n",
      "33/33 [==============================] - 0s 9ms/step - loss: 0.0111 - accuracy: 0.9942 - val_loss: 1.2053 - val_accuracy: 0.8031\n",
      "Epoch 289/1000\n",
      "33/33 [==============================] - 0s 9ms/step - loss: 0.0111 - accuracy: 0.9961 - val_loss: 1.3360 - val_accuracy: 0.7756\n",
      "Epoch 290/1000\n",
      "33/33 [==============================] - 0s 9ms/step - loss: 0.0148 - accuracy: 0.9942 - val_loss: 1.2056 - val_accuracy: 0.8110\n",
      "Epoch 291/1000\n",
      "33/33 [==============================] - 0s 8ms/step - loss: 0.0090 - accuracy: 0.9981 - val_loss: 1.2782 - val_accuracy: 0.7835\n",
      "Epoch 292/1000\n",
      "33/33 [==============================] - 0s 8ms/step - loss: 0.0109 - accuracy: 0.9981 - val_loss: 1.2452 - val_accuracy: 0.7835\n",
      "Epoch 293/1000\n",
      "33/33 [==============================] - 0s 8ms/step - loss: 0.0100 - accuracy: 0.9981 - val_loss: 1.2339 - val_accuracy: 0.7717\n",
      "Epoch 294/1000\n",
      "33/33 [==============================] - 0s 9ms/step - loss: 0.0119 - accuracy: 0.9942 - val_loss: 1.2144 - val_accuracy: 0.7795\n",
      "Epoch 295/1000\n",
      "33/33 [==============================] - 0s 9ms/step - loss: 0.0059 - accuracy: 1.0000 - val_loss: 1.1408 - val_accuracy: 0.7913\n",
      "Epoch 296/1000\n",
      "33/33 [==============================] - 0s 10ms/step - loss: 0.0163 - accuracy: 0.9961 - val_loss: 1.2095 - val_accuracy: 0.7913\n",
      "Epoch 297/1000\n",
      "33/33 [==============================] - 0s 9ms/step - loss: 0.0127 - accuracy: 0.9961 - val_loss: 1.1624 - val_accuracy: 0.7953\n",
      "Epoch 298/1000\n",
      "33/33 [==============================] - 0s 9ms/step - loss: 0.0055 - accuracy: 1.0000 - val_loss: 1.2192 - val_accuracy: 0.7795\n",
      "Epoch 299/1000\n",
      "33/33 [==============================] - 0s 9ms/step - loss: 0.0047 - accuracy: 0.9981 - val_loss: 1.1397 - val_accuracy: 0.7953\n",
      "Epoch 300/1000\n",
      "33/33 [==============================] - 0s 9ms/step - loss: 0.0117 - accuracy: 0.9961 - val_loss: 1.1711 - val_accuracy: 0.7953\n",
      "Epoch 301/1000\n",
      "33/33 [==============================] - 0s 9ms/step - loss: 0.0045 - accuracy: 1.0000 - val_loss: 1.1728 - val_accuracy: 0.7795\n",
      "Epoch 302/1000\n",
      "33/33 [==============================] - 0s 8ms/step - loss: 0.0077 - accuracy: 0.9981 - val_loss: 1.2617 - val_accuracy: 0.7835\n",
      "Epoch 303/1000\n",
      "33/33 [==============================] - 0s 8ms/step - loss: 0.0053 - accuracy: 1.0000 - val_loss: 1.2192 - val_accuracy: 0.7677\n",
      "Epoch 304/1000\n",
      "33/33 [==============================] - 0s 8ms/step - loss: 0.0078 - accuracy: 1.0000 - val_loss: 1.1692 - val_accuracy: 0.7756\n",
      "Epoch 305/1000\n",
      "33/33 [==============================] - 0s 7ms/step - loss: 0.0048 - accuracy: 1.0000 - val_loss: 1.1534 - val_accuracy: 0.8031\n",
      "Epoch 306/1000\n",
      "33/33 [==============================] - 0s 7ms/step - loss: 0.0077 - accuracy: 0.9961 - val_loss: 1.3047 - val_accuracy: 0.7835\n",
      "Epoch 307/1000\n",
      "33/33 [==============================] - 0s 7ms/step - loss: 0.0054 - accuracy: 1.0000 - val_loss: 1.3094 - val_accuracy: 0.7717\n",
      "Epoch 308/1000\n",
      "33/33 [==============================] - 0s 6ms/step - loss: 0.0135 - accuracy: 0.9942 - val_loss: 1.1273 - val_accuracy: 0.7835\n",
      "Epoch 309/1000\n",
      "33/33 [==============================] - 0s 7ms/step - loss: 0.0140 - accuracy: 0.9942 - val_loss: 1.1686 - val_accuracy: 0.7874\n",
      "Epoch 310/1000\n",
      "33/33 [==============================] - 0s 6ms/step - loss: 0.0041 - accuracy: 1.0000 - val_loss: 1.2867 - val_accuracy: 0.7835\n",
      "Epoch 311/1000\n",
      "33/33 [==============================] - 0s 6ms/step - loss: 0.0041 - accuracy: 1.0000 - val_loss: 1.2527 - val_accuracy: 0.7913\n",
      "Epoch 312/1000\n",
      "33/33 [==============================] - 0s 6ms/step - loss: 0.0037 - accuracy: 1.0000 - val_loss: 1.2553 - val_accuracy: 0.7795\n",
      "Epoch 313/1000\n",
      "33/33 [==============================] - 0s 6ms/step - loss: 0.0071 - accuracy: 1.0000 - val_loss: 1.2440 - val_accuracy: 0.7795\n",
      "Epoch 314/1000\n",
      "33/33 [==============================] - 0s 7ms/step - loss: 0.0155 - accuracy: 0.9942 - val_loss: 1.3113 - val_accuracy: 0.7677\n",
      "Epoch 315/1000\n",
      "33/33 [==============================] - 0s 6ms/step - loss: 0.0049 - accuracy: 1.0000 - val_loss: 1.2512 - val_accuracy: 0.7953\n",
      "Epoch 316/1000\n",
      "33/33 [==============================] - 0s 6ms/step - loss: 0.0099 - accuracy: 0.9981 - val_loss: 1.2781 - val_accuracy: 0.7795\n",
      "Epoch 317/1000\n",
      "33/33 [==============================] - 0s 7ms/step - loss: 0.0192 - accuracy: 0.9961 - val_loss: 1.1960 - val_accuracy: 0.7913\n",
      "Epoch 318/1000\n",
      "33/33 [==============================] - 0s 7ms/step - loss: 0.0072 - accuracy: 0.9981 - val_loss: 1.2578 - val_accuracy: 0.7953\n",
      "Epoch 319/1000\n",
      "33/33 [==============================] - 0s 7ms/step - loss: 0.0091 - accuracy: 0.9981 - val_loss: 1.2788 - val_accuracy: 0.7874\n",
      "Epoch 320/1000\n",
      "33/33 [==============================] - 0s 8ms/step - loss: 0.0100 - accuracy: 0.9981 - val_loss: 1.2324 - val_accuracy: 0.7874\n",
      "Epoch 321/1000\n",
      "33/33 [==============================] - 0s 8ms/step - loss: 0.0101 - accuracy: 0.9942 - val_loss: 1.1458 - val_accuracy: 0.7795\n",
      "Epoch 322/1000\n",
      "33/33 [==============================] - ETA: 0s - loss: 0.0057 - accuracy: 1.00 - 0s 7ms/step - loss: 0.0118 - accuracy: 0.9961 - val_loss: 1.1584 - val_accuracy: 0.7953\n",
      "Epoch 323/1000\n",
      "33/33 [==============================] - 0s 8ms/step - loss: 0.0091 - accuracy: 0.9961 - val_loss: 1.2037 - val_accuracy: 0.7835\n",
      "Epoch 324/1000\n",
      "33/33 [==============================] - 0s 8ms/step - loss: 0.0069 - accuracy: 0.9981 - val_loss: 1.1909 - val_accuracy: 0.7913\n",
      "Epoch 325/1000\n",
      "33/33 [==============================] - 0s 8ms/step - loss: 0.0130 - accuracy: 0.9981 - val_loss: 1.1712 - val_accuracy: 0.7913\n",
      "Epoch 326/1000\n",
      "33/33 [==============================] - 0s 9ms/step - loss: 0.0124 - accuracy: 0.9942 - val_loss: 1.2251 - val_accuracy: 0.7874\n",
      "Epoch 327/1000\n",
      "33/33 [==============================] - 0s 9ms/step - loss: 0.0063 - accuracy: 0.9981 - val_loss: 1.3726 - val_accuracy: 0.7795\n",
      "Epoch 328/1000\n",
      "33/33 [==============================] - 0s 11ms/step - loss: 0.0116 - accuracy: 0.9961 - val_loss: 1.1978 - val_accuracy: 0.7874\n",
      "Epoch 329/1000\n",
      "33/33 [==============================] - 0s 10ms/step - loss: 0.0082 - accuracy: 0.9981 - val_loss: 1.2230 - val_accuracy: 0.7835\n",
      "Epoch 330/1000\n",
      "33/33 [==============================] - 0s 9ms/step - loss: 0.0242 - accuracy: 0.9942 - val_loss: 1.1922 - val_accuracy: 0.7953\n",
      "Epoch 331/1000\n",
      "33/33 [==============================] - 0s 12ms/step - loss: 0.0146 - accuracy: 0.9942 - val_loss: 1.0859 - val_accuracy: 0.7953\n",
      "Epoch 332/1000\n",
      "33/33 [==============================] - 1s 18ms/step - loss: 0.0063 - accuracy: 0.9981 - val_loss: 1.1282 - val_accuracy: 0.8031\n",
      "Epoch 333/1000\n",
      "33/33 [==============================] - 0s 14ms/step - loss: 0.0104 - accuracy: 0.9961 - val_loss: 1.1954 - val_accuracy: 0.7756\n",
      "Epoch 334/1000\n",
      "33/33 [==============================] - 0s 14ms/step - loss: 0.0103 - accuracy: 0.9981 - val_loss: 1.2810 - val_accuracy: 0.7756\n",
      "Epoch 335/1000\n",
      "33/33 [==============================] - 0s 11ms/step - loss: 0.0038 - accuracy: 1.0000 - val_loss: 1.2189 - val_accuracy: 0.7795\n",
      "Epoch 336/1000\n",
      "33/33 [==============================] - 0s 10ms/step - loss: 0.0052 - accuracy: 0.9981 - val_loss: 1.4363 - val_accuracy: 0.7677\n",
      "Epoch 337/1000\n",
      "33/33 [==============================] - 0s 10ms/step - loss: 0.0198 - accuracy: 0.9903 - val_loss: 1.1839 - val_accuracy: 0.7874\n",
      "Epoch 338/1000\n",
      "33/33 [==============================] - 0s 9ms/step - loss: 0.0115 - accuracy: 0.9961 - val_loss: 1.2345 - val_accuracy: 0.7835\n",
      "Epoch 339/1000\n",
      "33/33 [==============================] - 0s 8ms/step - loss: 0.0082 - accuracy: 0.9981 - val_loss: 1.1681 - val_accuracy: 0.7913\n",
      "Epoch 340/1000\n",
      "33/33 [==============================] - 0s 9ms/step - loss: 0.0158 - accuracy: 0.9961 - val_loss: 1.2013 - val_accuracy: 0.7835\n",
      "Epoch 341/1000\n",
      "33/33 [==============================] - 0s 9ms/step - loss: 0.0171 - accuracy: 0.9961 - val_loss: 1.3411 - val_accuracy: 0.7913\n",
      "Epoch 342/1000\n",
      "33/33 [==============================] - 0s 8ms/step - loss: 0.0076 - accuracy: 0.9981 - val_loss: 1.1953 - val_accuracy: 0.7913\n",
      "Epoch 343/1000\n",
      "33/33 [==============================] - 0s 9ms/step - loss: 0.0075 - accuracy: 0.9981 - val_loss: 1.1942 - val_accuracy: 0.7953\n",
      "Epoch 344/1000\n",
      "33/33 [==============================] - 0s 9ms/step - loss: 0.0131 - accuracy: 0.9942 - val_loss: 1.2854 - val_accuracy: 0.7835\n",
      "Epoch 345/1000\n",
      "33/33 [==============================] - 0s 9ms/step - loss: 0.0096 - accuracy: 0.9981 - val_loss: 1.2488 - val_accuracy: 0.7953\n",
      "Epoch 346/1000\n",
      "33/33 [==============================] - 0s 9ms/step - loss: 0.0069 - accuracy: 0.9981 - val_loss: 1.2240 - val_accuracy: 0.7992\n",
      "Epoch 347/1000\n",
      "33/33 [==============================] - 0s 9ms/step - loss: 0.0134 - accuracy: 0.9961 - val_loss: 1.1629 - val_accuracy: 0.7992\n",
      "Epoch 348/1000\n",
      "33/33 [==============================] - 0s 8ms/step - loss: 0.0052 - accuracy: 1.0000 - val_loss: 1.1553 - val_accuracy: 0.7874\n",
      "Epoch 349/1000\n",
      "33/33 [==============================] - 0s 7ms/step - loss: 0.0188 - accuracy: 0.9961 - val_loss: 1.2809 - val_accuracy: 0.7992\n",
      "Epoch 350/1000\n",
      "33/33 [==============================] - 0s 7ms/step - loss: 0.0098 - accuracy: 1.0000 - val_loss: 1.2448 - val_accuracy: 0.7795\n",
      "Epoch 351/1000\n",
      "33/33 [==============================] - 0s 7ms/step - loss: 0.0095 - accuracy: 0.9981 - val_loss: 1.2331 - val_accuracy: 0.7953\n",
      "Epoch 352/1000\n",
      "33/33 [==============================] - 0s 7ms/step - loss: 0.0093 - accuracy: 1.0000 - val_loss: 1.2562 - val_accuracy: 0.8071\n",
      "Epoch 353/1000\n",
      "33/33 [==============================] - 0s 7ms/step - loss: 0.0142 - accuracy: 0.9961 - val_loss: 1.2385 - val_accuracy: 0.7953\n",
      "Epoch 354/1000\n",
      "33/33 [==============================] - 0s 6ms/step - loss: 0.0149 - accuracy: 0.9942 - val_loss: 1.2000 - val_accuracy: 0.7992\n",
      "Epoch 355/1000\n",
      "33/33 [==============================] - 0s 7ms/step - loss: 0.0085 - accuracy: 0.9981 - val_loss: 1.3840 - val_accuracy: 0.7677\n",
      "Epoch 356/1000\n",
      "33/33 [==============================] - 0s 6ms/step - loss: 0.0074 - accuracy: 0.9981 - val_loss: 1.2057 - val_accuracy: 0.7874\n",
      "Epoch 357/1000\n",
      "33/33 [==============================] - 0s 6ms/step - loss: 0.0065 - accuracy: 0.9981 - val_loss: 1.2346 - val_accuracy: 0.7874\n",
      "Epoch 358/1000\n",
      "33/33 [==============================] - 0s 6ms/step - loss: 0.0052 - accuracy: 1.0000 - val_loss: 1.2185 - val_accuracy: 0.7874\n",
      "Epoch 359/1000\n",
      "33/33 [==============================] - 0s 6ms/step - loss: 0.0072 - accuracy: 1.0000 - val_loss: 1.4058 - val_accuracy: 0.7795\n",
      "Epoch 360/1000\n",
      "33/33 [==============================] - 0s 6ms/step - loss: 0.0033 - accuracy: 1.0000 - val_loss: 1.2247 - val_accuracy: 0.7795\n",
      "Epoch 361/1000\n",
      "33/33 [==============================] - 0s 6ms/step - loss: 0.0100 - accuracy: 0.9961 - val_loss: 1.2581 - val_accuracy: 0.7913\n",
      "Epoch 362/1000\n",
      "33/33 [==============================] - 0s 6ms/step - loss: 0.0104 - accuracy: 0.9961 - val_loss: 1.2213 - val_accuracy: 0.8031\n",
      "Epoch 363/1000\n",
      "33/33 [==============================] - 0s 6ms/step - loss: 0.0040 - accuracy: 0.9981 - val_loss: 1.3340 - val_accuracy: 0.7913\n",
      "Epoch 364/1000\n",
      "33/33 [==============================] - 0s 6ms/step - loss: 0.0068 - accuracy: 0.9981 - val_loss: 1.2786 - val_accuracy: 0.7953\n",
      "Epoch 365/1000\n",
      "33/33 [==============================] - 0s 6ms/step - loss: 0.0092 - accuracy: 0.9981 - val_loss: 1.2532 - val_accuracy: 0.7835\n",
      "Epoch 366/1000\n",
      "33/33 [==============================] - 0s 6ms/step - loss: 0.0069 - accuracy: 0.9981 - val_loss: 1.2890 - val_accuracy: 0.7756\n",
      "Epoch 367/1000\n",
      "33/33 [==============================] - 0s 6ms/step - loss: 0.0093 - accuracy: 0.9981 - val_loss: 1.3385 - val_accuracy: 0.7795\n",
      "Epoch 368/1000\n",
      "33/33 [==============================] - 0s 6ms/step - loss: 0.0104 - accuracy: 0.9942 - val_loss: 1.1719 - val_accuracy: 0.7756\n",
      "Epoch 369/1000\n",
      "33/33 [==============================] - 0s 6ms/step - loss: 0.0052 - accuracy: 1.0000 - val_loss: 1.2218 - val_accuracy: 0.7835\n",
      "Epoch 370/1000\n",
      "33/33 [==============================] - 0s 6ms/step - loss: 0.0119 - accuracy: 0.9942 - val_loss: 1.2188 - val_accuracy: 0.7835\n",
      "Epoch 371/1000\n",
      "33/33 [==============================] - 0s 7ms/step - loss: 0.0065 - accuracy: 0.9981 - val_loss: 1.3986 - val_accuracy: 0.7795\n",
      "Epoch 372/1000\n",
      "33/33 [==============================] - 0s 6ms/step - loss: 0.0073 - accuracy: 0.9981 - val_loss: 1.3048 - val_accuracy: 0.7913\n",
      "Epoch 373/1000\n",
      "33/33 [==============================] - 0s 6ms/step - loss: 0.0132 - accuracy: 0.9961 - val_loss: 1.2464 - val_accuracy: 0.7913\n",
      "Epoch 374/1000\n",
      "33/33 [==============================] - 0s 6ms/step - loss: 0.0048 - accuracy: 1.0000 - val_loss: 1.2768 - val_accuracy: 0.7795\n",
      "Epoch 375/1000\n",
      "33/33 [==============================] - 0s 6ms/step - loss: 0.0060 - accuracy: 0.9981 - val_loss: 1.3157 - val_accuracy: 0.7835\n",
      "Epoch 376/1000\n",
      "33/33 [==============================] - 0s 6ms/step - loss: 0.0068 - accuracy: 0.9981 - val_loss: 1.3342 - val_accuracy: 0.7835\n",
      "Epoch 377/1000\n",
      "33/33 [==============================] - 0s 6ms/step - loss: 0.0059 - accuracy: 0.9981 - val_loss: 1.2185 - val_accuracy: 0.7953\n",
      "Epoch 378/1000\n",
      "33/33 [==============================] - 0s 6ms/step - loss: 0.0108 - accuracy: 0.9961 - val_loss: 1.3361 - val_accuracy: 0.7795\n",
      "Epoch 379/1000\n",
      "33/33 [==============================] - 0s 6ms/step - loss: 0.0080 - accuracy: 0.9981 - val_loss: 1.3029 - val_accuracy: 0.8071\n",
      "Epoch 380/1000\n",
      "33/33 [==============================] - 0s 6ms/step - loss: 0.0060 - accuracy: 1.0000 - val_loss: 1.3449 - val_accuracy: 0.7913\n",
      "Epoch 381/1000\n",
      "33/33 [==============================] - 0s 6ms/step - loss: 0.0073 - accuracy: 0.9981 - val_loss: 1.2187 - val_accuracy: 0.7953\n",
      "Epoch 382/1000\n",
      "33/33 [==============================] - 0s 7ms/step - loss: 0.0117 - accuracy: 0.9981 - val_loss: 1.2767 - val_accuracy: 0.7598\n",
      "Epoch 383/1000\n",
      "33/33 [==============================] - 0s 7ms/step - loss: 0.0130 - accuracy: 0.9961 - val_loss: 1.2087 - val_accuracy: 0.8031\n",
      "Epoch 384/1000\n",
      "33/33 [==============================] - 0s 7ms/step - loss: 0.0149 - accuracy: 0.9942 - val_loss: 1.2268 - val_accuracy: 0.7717\n",
      "Epoch 385/1000\n",
      "33/33 [==============================] - 0s 7ms/step - loss: 0.0069 - accuracy: 1.0000 - val_loss: 1.3202 - val_accuracy: 0.7913\n",
      "Epoch 386/1000\n",
      "33/33 [==============================] - 0s 7ms/step - loss: 0.0063 - accuracy: 1.0000 - val_loss: 1.2295 - val_accuracy: 0.8071\n",
      "Epoch 387/1000\n",
      "33/33 [==============================] - 0s 7ms/step - loss: 0.0089 - accuracy: 0.9961 - val_loss: 1.3538 - val_accuracy: 0.7835\n",
      "Epoch 388/1000\n",
      "33/33 [==============================] - 0s 7ms/step - loss: 0.0067 - accuracy: 1.0000 - val_loss: 1.2197 - val_accuracy: 0.7913\n",
      "Epoch 389/1000\n",
      "33/33 [==============================] - 0s 7ms/step - loss: 0.0083 - accuracy: 0.9981 - val_loss: 1.1777 - val_accuracy: 0.7756\n",
      "Epoch 390/1000\n",
      "33/33 [==============================] - 0s 8ms/step - loss: 0.0134 - accuracy: 0.9981 - val_loss: 1.3186 - val_accuracy: 0.7795\n",
      "Epoch 391/1000\n",
      "33/33 [==============================] - 0s 8ms/step - loss: 0.0109 - accuracy: 0.9961 - val_loss: 1.2819 - val_accuracy: 0.7835\n",
      "Epoch 392/1000\n",
      "33/33 [==============================] - 0s 7ms/step - loss: 0.0060 - accuracy: 1.0000 - val_loss: 1.1862 - val_accuracy: 0.7913\n",
      "Epoch 393/1000\n",
      "33/33 [==============================] - 0s 7ms/step - loss: 0.0081 - accuracy: 0.9981 - val_loss: 1.2335 - val_accuracy: 0.7795\n",
      "Epoch 394/1000\n",
      "33/33 [==============================] - 0s 7ms/step - loss: 0.0064 - accuracy: 0.9981 - val_loss: 1.3213 - val_accuracy: 0.7835\n",
      "Epoch 395/1000\n",
      "33/33 [==============================] - 0s 7ms/step - loss: 0.0038 - accuracy: 1.0000 - val_loss: 1.2184 - val_accuracy: 0.7953\n",
      "Epoch 396/1000\n",
      "33/33 [==============================] - 0s 7ms/step - loss: 0.0056 - accuracy: 1.0000 - val_loss: 1.2433 - val_accuracy: 0.7992\n",
      "Epoch 397/1000\n",
      "33/33 [==============================] - 0s 7ms/step - loss: 0.0091 - accuracy: 0.9981 - val_loss: 1.2168 - val_accuracy: 0.8031\n",
      "Epoch 398/1000\n",
      "33/33 [==============================] - 0s 7ms/step - loss: 0.0122 - accuracy: 0.9942 - val_loss: 1.2067 - val_accuracy: 0.7835\n",
      "Epoch 399/1000\n",
      "33/33 [==============================] - 0s 7ms/step - loss: 0.0079 - accuracy: 1.0000 - val_loss: 1.2687 - val_accuracy: 0.7874\n",
      "Epoch 400/1000\n",
      "33/33 [==============================] - 0s 6ms/step - loss: 0.0062 - accuracy: 0.9981 - val_loss: 1.1731 - val_accuracy: 0.7835\n",
      "Epoch 401/1000\n",
      "33/33 [==============================] - 0s 7ms/step - loss: 0.0135 - accuracy: 0.9961 - val_loss: 1.1883 - val_accuracy: 0.8031\n",
      "Epoch 402/1000\n",
      "33/33 [==============================] - 0s 7ms/step - loss: 0.0051 - accuracy: 1.0000 - val_loss: 1.3244 - val_accuracy: 0.7795\n",
      "Epoch 403/1000\n",
      "33/33 [==============================] - 0s 7ms/step - loss: 0.0053 - accuracy: 1.0000 - val_loss: 1.2055 - val_accuracy: 0.7913\n",
      "Epoch 404/1000\n",
      "33/33 [==============================] - 0s 7ms/step - loss: 0.0091 - accuracy: 0.9961 - val_loss: 1.1945 - val_accuracy: 0.7874\n",
      "Epoch 405/1000\n",
      "33/33 [==============================] - 0s 7ms/step - loss: 0.0072 - accuracy: 0.9981 - val_loss: 1.1962 - val_accuracy: 0.7795\n",
      "Epoch 406/1000\n",
      "33/33 [==============================] - 0s 7ms/step - loss: 0.0194 - accuracy: 0.9961 - val_loss: 1.2012 - val_accuracy: 0.7756\n",
      "Epoch 407/1000\n",
      "33/33 [==============================] - 0s 7ms/step - loss: 0.0032 - accuracy: 1.0000 - val_loss: 1.2262 - val_accuracy: 0.7795\n",
      "Epoch 408/1000\n",
      "33/33 [==============================] - 0s 7ms/step - loss: 0.0066 - accuracy: 0.9981 - val_loss: 1.2466 - val_accuracy: 0.7717\n",
      "Epoch 409/1000\n",
      "33/33 [==============================] - 0s 7ms/step - loss: 0.0041 - accuracy: 1.0000 - val_loss: 1.2012 - val_accuracy: 0.8031\n",
      "Epoch 410/1000\n",
      "33/33 [==============================] - 0s 7ms/step - loss: 0.0096 - accuracy: 0.9981 - val_loss: 1.2342 - val_accuracy: 0.7913\n",
      "Epoch 411/1000\n",
      "33/33 [==============================] - 0s 7ms/step - loss: 0.0044 - accuracy: 1.0000 - val_loss: 1.2727 - val_accuracy: 0.7677\n",
      "Epoch 412/1000\n",
      "33/33 [==============================] - 0s 7ms/step - loss: 0.0100 - accuracy: 0.9961 - val_loss: 1.2196 - val_accuracy: 0.7874\n",
      "Epoch 413/1000\n",
      "33/33 [==============================] - 0s 6ms/step - loss: 0.0049 - accuracy: 1.0000 - val_loss: 1.2416 - val_accuracy: 0.7874\n",
      "Epoch 414/1000\n",
      "33/33 [==============================] - 0s 6ms/step - loss: 0.0123 - accuracy: 0.9942 - val_loss: 1.3675 - val_accuracy: 0.7638\n",
      "Epoch 415/1000\n",
      "33/33 [==============================] - 0s 6ms/step - loss: 0.0141 - accuracy: 0.9961 - val_loss: 1.3411 - val_accuracy: 0.7756\n",
      "Epoch 416/1000\n",
      "33/33 [==============================] - 0s 7ms/step - loss: 0.0110 - accuracy: 0.9981 - val_loss: 1.2999 - val_accuracy: 0.7913\n",
      "Epoch 417/1000\n",
      "33/33 [==============================] - 0s 7ms/step - loss: 0.0039 - accuracy: 1.0000 - val_loss: 1.2495 - val_accuracy: 0.7874\n",
      "Epoch 418/1000\n",
      "33/33 [==============================] - 0s 7ms/step - loss: 0.0058 - accuracy: 0.9981 - val_loss: 1.2620 - val_accuracy: 0.7756\n",
      "Epoch 419/1000\n",
      "33/33 [==============================] - 0s 6ms/step - loss: 0.0067 - accuracy: 0.9981 - val_loss: 1.2009 - val_accuracy: 0.7835\n",
      "Epoch 420/1000\n",
      "33/33 [==============================] - 0s 6ms/step - loss: 0.0133 - accuracy: 0.9961 - val_loss: 1.1143 - val_accuracy: 0.7913\n",
      "Epoch 421/1000\n",
      "33/33 [==============================] - 0s 6ms/step - loss: 0.0109 - accuracy: 0.9981 - val_loss: 1.2329 - val_accuracy: 0.7795\n",
      "Epoch 422/1000\n",
      "33/33 [==============================] - 0s 6ms/step - loss: 0.0052 - accuracy: 1.0000 - val_loss: 1.1795 - val_accuracy: 0.7795\n",
      "Epoch 423/1000\n",
      "33/33 [==============================] - 0s 6ms/step - loss: 0.0116 - accuracy: 0.9961 - val_loss: 1.2811 - val_accuracy: 0.7795\n",
      "Epoch 424/1000\n",
      "33/33 [==============================] - 0s 6ms/step - loss: 0.0078 - accuracy: 0.9981 - val_loss: 1.2344 - val_accuracy: 0.7953\n",
      "Epoch 425/1000\n",
      "33/33 [==============================] - 0s 7ms/step - loss: 0.0169 - accuracy: 0.9942 - val_loss: 1.2074 - val_accuracy: 0.7874\n",
      "Epoch 426/1000\n",
      "33/33 [==============================] - 0s 7ms/step - loss: 0.0117 - accuracy: 0.9942 - val_loss: 1.2661 - val_accuracy: 0.7835\n",
      "Epoch 427/1000\n",
      "33/33 [==============================] - 0s 6ms/step - loss: 0.0076 - accuracy: 0.9981 - val_loss: 1.1926 - val_accuracy: 0.7756\n",
      "Epoch 428/1000\n",
      "33/33 [==============================] - 0s 6ms/step - loss: 0.0053 - accuracy: 1.0000 - val_loss: 1.2224 - val_accuracy: 0.7756\n",
      "Epoch 429/1000\n",
      "33/33 [==============================] - 0s 6ms/step - loss: 0.0056 - accuracy: 0.9981 - val_loss: 1.2836 - val_accuracy: 0.7717\n",
      "Epoch 430/1000\n",
      "33/33 [==============================] - 0s 6ms/step - loss: 0.0120 - accuracy: 0.9981 - val_loss: 1.3630 - val_accuracy: 0.7795\n",
      "Epoch 431/1000\n",
      "33/33 [==============================] - 0s 6ms/step - loss: 0.0077 - accuracy: 0.9981 - val_loss: 1.2304 - val_accuracy: 0.7795\n",
      "Epoch 432/1000\n",
      "33/33 [==============================] - 0s 6ms/step - loss: 0.0064 - accuracy: 1.0000 - val_loss: 1.3231 - val_accuracy: 0.7638\n",
      "Epoch 433/1000\n",
      "33/33 [==============================] - 0s 6ms/step - loss: 0.0040 - accuracy: 1.0000 - val_loss: 1.3678 - val_accuracy: 0.7795\n",
      "Epoch 434/1000\n",
      "33/33 [==============================] - 0s 6ms/step - loss: 0.0080 - accuracy: 0.9961 - val_loss: 1.2337 - val_accuracy: 0.7913\n",
      "Epoch 435/1000\n",
      "33/33 [==============================] - 0s 6ms/step - loss: 0.0127 - accuracy: 0.9961 - val_loss: 1.3316 - val_accuracy: 0.7795\n",
      "Epoch 436/1000\n",
      "33/33 [==============================] - 0s 7ms/step - loss: 0.0055 - accuracy: 1.0000 - val_loss: 1.3225 - val_accuracy: 0.7835\n",
      "Epoch 437/1000\n",
      "33/33 [==============================] - 0s 6ms/step - loss: 0.0062 - accuracy: 0.9981 - val_loss: 1.3093 - val_accuracy: 0.7756\n",
      "Epoch 438/1000\n",
      "33/33 [==============================] - 0s 6ms/step - loss: 0.0042 - accuracy: 1.0000 - val_loss: 1.4044 - val_accuracy: 0.7835\n",
      "Epoch 439/1000\n",
      "33/33 [==============================] - 0s 6ms/step - loss: 0.0139 - accuracy: 0.9942 - val_loss: 1.2414 - val_accuracy: 0.7874\n",
      "Epoch 440/1000\n",
      "33/33 [==============================] - 0s 6ms/step - loss: 0.0079 - accuracy: 0.9981 - val_loss: 1.3796 - val_accuracy: 0.7756\n",
      "Epoch 441/1000\n",
      "33/33 [==============================] - 0s 6ms/step - loss: 0.0113 - accuracy: 0.9961 - val_loss: 1.2801 - val_accuracy: 0.7835\n",
      "Epoch 442/1000\n",
      "33/33 [==============================] - 0s 6ms/step - loss: 0.0047 - accuracy: 0.9981 - val_loss: 1.1936 - val_accuracy: 0.7913\n",
      "Epoch 443/1000\n",
      "33/33 [==============================] - 0s 6ms/step - loss: 0.0144 - accuracy: 0.9942 - val_loss: 1.3425 - val_accuracy: 0.7795\n",
      "Epoch 444/1000\n",
      "33/33 [==============================] - 0s 6ms/step - loss: 0.0045 - accuracy: 1.0000 - val_loss: 1.1566 - val_accuracy: 0.7756\n",
      "Epoch 445/1000\n",
      "33/33 [==============================] - 0s 6ms/step - loss: 0.0131 - accuracy: 0.9981 - val_loss: 1.1728 - val_accuracy: 0.7835\n",
      "Epoch 446/1000\n",
      "33/33 [==============================] - 0s 6ms/step - loss: 0.0094 - accuracy: 0.9981 - val_loss: 1.2099 - val_accuracy: 0.7953\n",
      "Epoch 447/1000\n",
      "33/33 [==============================] - 0s 6ms/step - loss: 0.0042 - accuracy: 0.9981 - val_loss: 1.2826 - val_accuracy: 0.7795\n",
      "Epoch 448/1000\n",
      "33/33 [==============================] - 0s 6ms/step - loss: 0.0115 - accuracy: 0.9942 - val_loss: 1.2719 - val_accuracy: 0.7874\n",
      "Epoch 449/1000\n",
      "33/33 [==============================] - 0s 6ms/step - loss: 0.0064 - accuracy: 0.9981 - val_loss: 1.2171 - val_accuracy: 0.7835\n",
      "Epoch 450/1000\n",
      "33/33 [==============================] - 0s 7ms/step - loss: 0.0106 - accuracy: 0.9981 - val_loss: 1.2954 - val_accuracy: 0.7795\n",
      "Epoch 451/1000\n",
      "33/33 [==============================] - 0s 7ms/step - loss: 0.0040 - accuracy: 1.0000 - val_loss: 1.2964 - val_accuracy: 0.7756\n",
      "Epoch 452/1000\n",
      "33/33 [==============================] - 0s 8ms/step - loss: 0.0157 - accuracy: 0.9942 - val_loss: 1.1820 - val_accuracy: 0.7835\n",
      "Epoch 453/1000\n",
      "33/33 [==============================] - 0s 7ms/step - loss: 0.0083 - accuracy: 0.9981 - val_loss: 1.1948 - val_accuracy: 0.7835\n",
      "Epoch 454/1000\n",
      "33/33 [==============================] - 0s 7ms/step - loss: 0.0040 - accuracy: 1.0000 - val_loss: 1.2849 - val_accuracy: 0.7756\n",
      "Epoch 455/1000\n",
      "33/33 [==============================] - 0s 7ms/step - loss: 0.0034 - accuracy: 1.0000 - val_loss: 1.2164 - val_accuracy: 0.7913\n",
      "Epoch 456/1000\n",
      "33/33 [==============================] - 0s 7ms/step - loss: 0.0060 - accuracy: 1.0000 - val_loss: 1.2906 - val_accuracy: 0.7756\n",
      "Epoch 457/1000\n",
      "33/33 [==============================] - 0s 8ms/step - loss: 0.0046 - accuracy: 1.0000 - val_loss: 1.2152 - val_accuracy: 0.7874\n",
      "Epoch 458/1000\n",
      "33/33 [==============================] - 0s 8ms/step - loss: 0.0066 - accuracy: 0.9981 - val_loss: 1.1240 - val_accuracy: 0.7953\n",
      "Epoch 459/1000\n",
      "33/33 [==============================] - 0s 7ms/step - loss: 0.0084 - accuracy: 0.9981 - val_loss: 1.2635 - val_accuracy: 0.7835\n",
      "Epoch 460/1000\n",
      "33/33 [==============================] - 0s 7ms/step - loss: 0.0084 - accuracy: 0.9981 - val_loss: 1.2467 - val_accuracy: 0.7835\n",
      "Epoch 461/1000\n",
      "33/33 [==============================] - 0s 7ms/step - loss: 0.0139 - accuracy: 0.9981 - val_loss: 1.2437 - val_accuracy: 0.7835\n",
      "Epoch 462/1000\n",
      "33/33 [==============================] - 0s 7ms/step - loss: 0.0111 - accuracy: 0.9961 - val_loss: 1.2636 - val_accuracy: 0.7835\n",
      "Epoch 463/1000\n",
      "33/33 [==============================] - 0s 7ms/step - loss: 0.0035 - accuracy: 1.0000 - val_loss: 1.3511 - val_accuracy: 0.7835\n",
      "Epoch 464/1000\n",
      "33/33 [==============================] - 0s 7ms/step - loss: 0.0031 - accuracy: 1.0000 - val_loss: 1.3425 - val_accuracy: 0.7795\n",
      "Epoch 465/1000\n",
      "33/33 [==============================] - 0s 7ms/step - loss: 0.0199 - accuracy: 0.9961 - val_loss: 1.2561 - val_accuracy: 0.7874\n",
      "Epoch 466/1000\n",
      "33/33 [==============================] - 0s 7ms/step - loss: 0.0028 - accuracy: 1.0000 - val_loss: 1.2558 - val_accuracy: 0.7874\n",
      "Epoch 467/1000\n",
      "33/33 [==============================] - 0s 7ms/step - loss: 0.0114 - accuracy: 0.9981 - val_loss: 1.2726 - val_accuracy: 0.8071\n",
      "Epoch 468/1000\n",
      "33/33 [==============================] - 0s 7ms/step - loss: 0.0077 - accuracy: 0.9981 - val_loss: 1.3182 - val_accuracy: 0.7992\n",
      "Epoch 469/1000\n",
      "33/33 [==============================] - 0s 7ms/step - loss: 0.0093 - accuracy: 0.9961 - val_loss: 1.2588 - val_accuracy: 0.7874\n",
      "Epoch 470/1000\n",
      "33/33 [==============================] - 0s 7ms/step - loss: 0.0092 - accuracy: 1.0000 - val_loss: 1.2508 - val_accuracy: 0.7835\n",
      "Epoch 471/1000\n",
      "33/33 [==============================] - 0s 7ms/step - loss: 0.0086 - accuracy: 0.9981 - val_loss: 1.1648 - val_accuracy: 0.8031\n",
      "Epoch 472/1000\n",
      "33/33 [==============================] - 0s 7ms/step - loss: 0.0077 - accuracy: 0.9981 - val_loss: 1.2716 - val_accuracy: 0.7953\n",
      "Epoch 473/1000\n",
      "33/33 [==============================] - 0s 7ms/step - loss: 0.0118 - accuracy: 0.9981 - val_loss: 1.2219 - val_accuracy: 0.7874\n",
      "Epoch 474/1000\n",
      "33/33 [==============================] - 0s 7ms/step - loss: 0.0110 - accuracy: 0.9961 - val_loss: 1.3848 - val_accuracy: 0.7677\n",
      "Epoch 475/1000\n",
      "33/33 [==============================] - 0s 6ms/step - loss: 0.0079 - accuracy: 0.9981 - val_loss: 1.2999 - val_accuracy: 0.7756\n",
      "Epoch 476/1000\n",
      "33/33 [==============================] - 0s 7ms/step - loss: 0.0131 - accuracy: 0.9981 - val_loss: 1.2084 - val_accuracy: 0.7992\n",
      "Epoch 477/1000\n",
      "33/33 [==============================] - 0s 7ms/step - loss: 0.0090 - accuracy: 0.9981 - val_loss: 1.2554 - val_accuracy: 0.7953\n",
      "Epoch 478/1000\n",
      "33/33 [==============================] - 0s 6ms/step - loss: 0.0070 - accuracy: 0.9981 - val_loss: 1.2715 - val_accuracy: 0.7913\n",
      "Epoch 479/1000\n",
      "33/33 [==============================] - 0s 7ms/step - loss: 0.0125 - accuracy: 0.9961 - val_loss: 1.2406 - val_accuracy: 0.7913\n",
      "Epoch 480/1000\n",
      "33/33 [==============================] - 0s 7ms/step - loss: 0.0109 - accuracy: 0.9961 - val_loss: 1.2541 - val_accuracy: 0.7795\n",
      "Epoch 481/1000\n",
      "33/33 [==============================] - 0s 7ms/step - loss: 0.0070 - accuracy: 1.0000 - val_loss: 1.3797 - val_accuracy: 0.7559\n",
      "Epoch 482/1000\n",
      "33/33 [==============================] - 0s 7ms/step - loss: 0.0270 - accuracy: 0.9942 - val_loss: 1.3315 - val_accuracy: 0.7953\n",
      "Epoch 483/1000\n",
      "33/33 [==============================] - 0s 6ms/step - loss: 0.0030 - accuracy: 1.0000 - val_loss: 1.2618 - val_accuracy: 0.7795\n",
      "Epoch 484/1000\n",
      "33/33 [==============================] - 0s 6ms/step - loss: 0.0042 - accuracy: 1.0000 - val_loss: 1.4414 - val_accuracy: 0.7874\n",
      "Epoch 485/1000\n",
      "33/33 [==============================] - 0s 6ms/step - loss: 0.0108 - accuracy: 0.9961 - val_loss: 1.2667 - val_accuracy: 0.7953\n",
      "Epoch 486/1000\n",
      "33/33 [==============================] - 0s 6ms/step - loss: 0.0043 - accuracy: 1.0000 - val_loss: 1.3198 - val_accuracy: 0.7835\n",
      "Epoch 487/1000\n",
      "33/33 [==============================] - 0s 6ms/step - loss: 0.0099 - accuracy: 0.9961 - val_loss: 1.2306 - val_accuracy: 0.7795\n",
      "Epoch 488/1000\n",
      "33/33 [==============================] - 0s 6ms/step - loss: 0.0070 - accuracy: 1.0000 - val_loss: 1.2742 - val_accuracy: 0.7913\n",
      "Epoch 489/1000\n",
      "33/33 [==============================] - 0s 6ms/step - loss: 0.0134 - accuracy: 0.9961 - val_loss: 1.2524 - val_accuracy: 0.7874\n",
      "Epoch 490/1000\n",
      "33/33 [==============================] - 0s 6ms/step - loss: 0.0088 - accuracy: 0.9981 - val_loss: 1.2613 - val_accuracy: 0.7953\n",
      "Epoch 491/1000\n",
      "33/33 [==============================] - 0s 6ms/step - loss: 0.0123 - accuracy: 0.9961 - val_loss: 1.3177 - val_accuracy: 0.7756\n",
      "Epoch 492/1000\n",
      "33/33 [==============================] - 0s 7ms/step - loss: 0.0183 - accuracy: 0.9942 - val_loss: 1.2782 - val_accuracy: 0.7992\n",
      "Epoch 493/1000\n",
      "33/33 [==============================] - 0s 6ms/step - loss: 0.0075 - accuracy: 0.9981 - val_loss: 1.3040 - val_accuracy: 0.7913\n",
      "Epoch 494/1000\n",
      "33/33 [==============================] - 0s 6ms/step - loss: 0.0046 - accuracy: 1.0000 - val_loss: 1.2873 - val_accuracy: 0.7795\n",
      "Epoch 495/1000\n",
      "33/33 [==============================] - 0s 6ms/step - loss: 0.0142 - accuracy: 0.9922 - val_loss: 1.2805 - val_accuracy: 0.7756\n",
      "Epoch 496/1000\n",
      "33/33 [==============================] - 0s 6ms/step - loss: 0.0043 - accuracy: 1.0000 - val_loss: 1.2817 - val_accuracy: 0.7835\n",
      "Epoch 497/1000\n",
      "33/33 [==============================] - 0s 6ms/step - loss: 0.0075 - accuracy: 0.9961 - val_loss: 1.3269 - val_accuracy: 0.7795\n",
      "Epoch 498/1000\n",
      "33/33 [==============================] - 0s 6ms/step - loss: 0.0055 - accuracy: 0.9981 - val_loss: 1.3961 - val_accuracy: 0.7874\n",
      "Epoch 499/1000\n",
      "33/33 [==============================] - 0s 6ms/step - loss: 0.0268 - accuracy: 0.9903 - val_loss: 1.3455 - val_accuracy: 0.7874\n",
      "Epoch 500/1000\n",
      "33/33 [==============================] - 0s 6ms/step - loss: 0.0055 - accuracy: 0.9981 - val_loss: 1.2500 - val_accuracy: 0.7874\n",
      "Epoch 501/1000\n",
      "33/33 [==============================] - 0s 6ms/step - loss: 0.0097 - accuracy: 0.9961 - val_loss: 1.3051 - val_accuracy: 0.7953\n",
      "Epoch 502/1000\n",
      "33/33 [==============================] - 0s 6ms/step - loss: 0.0053 - accuracy: 1.0000 - val_loss: 1.2373 - val_accuracy: 0.7953\n",
      "Epoch 503/1000\n",
      "33/33 [==============================] - 0s 7ms/step - loss: 0.0175 - accuracy: 0.9922 - val_loss: 1.2660 - val_accuracy: 0.7795\n",
      "Epoch 504/1000\n",
      "33/33 [==============================] - 0s 7ms/step - loss: 0.0024 - accuracy: 1.0000 - val_loss: 1.3234 - val_accuracy: 0.7953\n",
      "Epoch 505/1000\n",
      "33/33 [==============================] - 0s 7ms/step - loss: 0.0079 - accuracy: 0.9981 - val_loss: 1.3335 - val_accuracy: 0.7992\n",
      "Epoch 506/1000\n",
      "33/33 [==============================] - 0s 6ms/step - loss: 0.0113 - accuracy: 0.9961 - val_loss: 1.4238 - val_accuracy: 0.7913\n",
      "Epoch 507/1000\n",
      "33/33 [==============================] - 0s 6ms/step - loss: 0.0074 - accuracy: 0.9961 - val_loss: 1.2937 - val_accuracy: 0.7913\n",
      "Epoch 508/1000\n",
      "33/33 [==============================] - 0s 6ms/step - loss: 0.0077 - accuracy: 0.9981 - val_loss: 1.3507 - val_accuracy: 0.7717\n",
      "Epoch 509/1000\n",
      "33/33 [==============================] - 0s 6ms/step - loss: 0.0048 - accuracy: 1.0000 - val_loss: 1.1941 - val_accuracy: 0.7992\n",
      "Epoch 510/1000\n",
      "33/33 [==============================] - 0s 6ms/step - loss: 0.0162 - accuracy: 0.9922 - val_loss: 1.2995 - val_accuracy: 0.7717\n",
      "Epoch 511/1000\n",
      "33/33 [==============================] - 0s 6ms/step - loss: 0.0049 - accuracy: 1.0000 - val_loss: 1.3828 - val_accuracy: 0.7756\n",
      "Epoch 512/1000\n",
      "33/33 [==============================] - 0s 6ms/step - loss: 0.0270 - accuracy: 0.9961 - val_loss: 1.3080 - val_accuracy: 0.7953\n",
      "Epoch 513/1000\n",
      "33/33 [==============================] - 0s 6ms/step - loss: 0.0107 - accuracy: 0.9961 - val_loss: 1.2964 - val_accuracy: 0.7835\n",
      "Epoch 514/1000\n",
      "33/33 [==============================] - 0s 6ms/step - loss: 0.0042 - accuracy: 0.9981 - val_loss: 1.3212 - val_accuracy: 0.7913\n",
      "Epoch 515/1000\n",
      "33/33 [==============================] - 0s 6ms/step - loss: 0.0073 - accuracy: 0.9961 - val_loss: 1.3110 - val_accuracy: 0.7874\n",
      "Epoch 516/1000\n",
      "33/33 [==============================] - 0s 6ms/step - loss: 0.0081 - accuracy: 0.9961 - val_loss: 1.2854 - val_accuracy: 0.7874\n",
      "Epoch 517/1000\n",
      "33/33 [==============================] - 0s 6ms/step - loss: 0.0030 - accuracy: 1.0000 - val_loss: 1.3195 - val_accuracy: 0.7953\n",
      "Epoch 518/1000\n",
      "33/33 [==============================] - 0s 6ms/step - loss: 0.0161 - accuracy: 0.9961 - val_loss: 1.2831 - val_accuracy: 0.7913\n",
      "Epoch 519/1000\n",
      "33/33 [==============================] - 0s 7ms/step - loss: 0.0089 - accuracy: 0.9981 - val_loss: 1.2692 - val_accuracy: 0.7953\n",
      "Epoch 520/1000\n",
      "33/33 [==============================] - 0s 7ms/step - loss: 0.0283 - accuracy: 0.9942 - val_loss: 1.2247 - val_accuracy: 0.7953\n",
      "Epoch 521/1000\n",
      "33/33 [==============================] - 0s 7ms/step - loss: 0.0064 - accuracy: 1.0000 - val_loss: 1.2441 - val_accuracy: 0.8071\n",
      "Epoch 522/1000\n",
      "33/33 [==============================] - 0s 8ms/step - loss: 0.0027 - accuracy: 1.0000 - val_loss: 1.2257 - val_accuracy: 0.7913\n",
      "Epoch 523/1000\n",
      "33/33 [==============================] - 0s 8ms/step - loss: 0.0039 - accuracy: 1.0000 - val_loss: 1.3272 - val_accuracy: 0.7874\n",
      "Epoch 524/1000\n",
      "33/33 [==============================] - 0s 8ms/step - loss: 0.0096 - accuracy: 0.9981 - val_loss: 1.3496 - val_accuracy: 0.7756\n",
      "Epoch 525/1000\n",
      "33/33 [==============================] - 0s 8ms/step - loss: 0.0066 - accuracy: 0.9981 - val_loss: 1.3159 - val_accuracy: 0.7913\n",
      "Epoch 526/1000\n",
      "33/33 [==============================] - 0s 9ms/step - loss: 0.0069 - accuracy: 1.0000 - val_loss: 1.2741 - val_accuracy: 0.7835\n",
      "Epoch 527/1000\n",
      "33/33 [==============================] - 0s 9ms/step - loss: 0.0051 - accuracy: 1.0000 - val_loss: 1.2633 - val_accuracy: 0.8071\n",
      "Epoch 528/1000\n",
      "33/33 [==============================] - 0s 8ms/step - loss: 0.0063 - accuracy: 0.9981 - val_loss: 1.3866 - val_accuracy: 0.7795\n",
      "Epoch 529/1000\n",
      "33/33 [==============================] - 0s 7ms/step - loss: 0.0042 - accuracy: 1.0000 - val_loss: 1.4549 - val_accuracy: 0.7835\n",
      "Epoch 530/1000\n",
      "33/33 [==============================] - 0s 7ms/step - loss: 0.0150 - accuracy: 0.9981 - val_loss: 1.3292 - val_accuracy: 0.7874\n",
      "Epoch 531/1000\n",
      "33/33 [==============================] - 0s 7ms/step - loss: 0.0105 - accuracy: 0.9981 - val_loss: 1.3439 - val_accuracy: 0.7874\n",
      "Epoch 532/1000\n",
      "33/33 [==============================] - 0s 7ms/step - loss: 0.0062 - accuracy: 0.9961 - val_loss: 1.2723 - val_accuracy: 0.7795\n",
      "Epoch 533/1000\n",
      "33/33 [==============================] - 0s 7ms/step - loss: 0.0105 - accuracy: 0.9961 - val_loss: 1.2793 - val_accuracy: 0.7874\n",
      "Epoch 534/1000\n",
      "33/33 [==============================] - 0s 7ms/step - loss: 0.0088 - accuracy: 0.9981 - val_loss: 1.3812 - val_accuracy: 0.7835\n",
      "Epoch 535/1000\n",
      "33/33 [==============================] - 0s 7ms/step - loss: 0.0072 - accuracy: 0.9981 - val_loss: 1.3124 - val_accuracy: 0.7835\n",
      "Epoch 536/1000\n",
      "33/33 [==============================] - 0s 7ms/step - loss: 0.0092 - accuracy: 0.9981 - val_loss: 1.4073 - val_accuracy: 0.7913\n",
      "Epoch 537/1000\n",
      "33/33 [==============================] - 0s 7ms/step - loss: 0.0062 - accuracy: 0.9981 - val_loss: 1.3076 - val_accuracy: 0.7795\n",
      "Epoch 538/1000\n",
      "33/33 [==============================] - 0s 7ms/step - loss: 0.0069 - accuracy: 0.9981 - val_loss: 1.4551 - val_accuracy: 0.7835\n",
      "Epoch 539/1000\n",
      "33/33 [==============================] - 0s 7ms/step - loss: 0.0112 - accuracy: 0.9961 - val_loss: 1.3106 - val_accuracy: 0.7953\n",
      "Epoch 540/1000\n",
      "33/33 [==============================] - 0s 7ms/step - loss: 0.0029 - accuracy: 1.0000 - val_loss: 1.3176 - val_accuracy: 0.7874\n",
      "Epoch 541/1000\n",
      "33/33 [==============================] - 0s 7ms/step - loss: 0.0115 - accuracy: 0.9961 - val_loss: 1.3420 - val_accuracy: 0.7913\n",
      "Epoch 542/1000\n",
      "33/33 [==============================] - 0s 7ms/step - loss: 0.0099 - accuracy: 0.9961 - val_loss: 1.2419 - val_accuracy: 0.7953\n",
      "Epoch 543/1000\n",
      "33/33 [==============================] - 0s 7ms/step - loss: 0.0027 - accuracy: 1.0000 - val_loss: 1.3144 - val_accuracy: 0.7953\n",
      "Epoch 544/1000\n",
      "33/33 [==============================] - 0s 6ms/step - loss: 0.0053 - accuracy: 1.0000 - val_loss: 1.2501 - val_accuracy: 0.7874\n",
      "Epoch 545/1000\n",
      "33/33 [==============================] - 0s 7ms/step - loss: 0.0039 - accuracy: 0.9981 - val_loss: 1.2413 - val_accuracy: 0.8031\n",
      "Epoch 546/1000\n",
      "33/33 [==============================] - 0s 7ms/step - loss: 0.0018 - accuracy: 1.0000 - val_loss: 1.2762 - val_accuracy: 0.8031\n",
      "Epoch 547/1000\n",
      "33/33 [==============================] - 0s 7ms/step - loss: 0.0048 - accuracy: 1.0000 - val_loss: 1.3518 - val_accuracy: 0.7835\n",
      "Epoch 548/1000\n",
      "33/33 [==============================] - 0s 6ms/step - loss: 0.0163 - accuracy: 0.9922 - val_loss: 1.3556 - val_accuracy: 0.7953\n",
      "Epoch 549/1000\n",
      "33/33 [==============================] - 0s 7ms/step - loss: 0.0059 - accuracy: 1.0000 - val_loss: 1.2568 - val_accuracy: 0.7835\n",
      "Epoch 550/1000\n",
      "33/33 [==============================] - 0s 6ms/step - loss: 0.0169 - accuracy: 0.9961 - val_loss: 1.2776 - val_accuracy: 0.7953\n",
      "Epoch 551/1000\n",
      "33/33 [==============================] - 0s 6ms/step - loss: 0.0060 - accuracy: 1.0000 - val_loss: 1.2334 - val_accuracy: 0.7874\n",
      "Epoch 552/1000\n",
      "33/33 [==============================] - 0s 6ms/step - loss: 0.0032 - accuracy: 1.0000 - val_loss: 1.1727 - val_accuracy: 0.7795\n",
      "Epoch 553/1000\n",
      "33/33 [==============================] - ETA: 0s - loss: 0.0056 - accuracy: 1.00 - 0s 6ms/step - loss: 0.0052 - accuracy: 1.0000 - val_loss: 1.2756 - val_accuracy: 0.7953\n",
      "Epoch 554/1000\n",
      "33/33 [==============================] - 0s 6ms/step - loss: 0.0038 - accuracy: 1.0000 - val_loss: 1.2446 - val_accuracy: 0.7953\n",
      "Epoch 555/1000\n",
      "33/33 [==============================] - 0s 6ms/step - loss: 0.0037 - accuracy: 1.0000 - val_loss: 1.2746 - val_accuracy: 0.7677\n",
      "Epoch 556/1000\n",
      "33/33 [==============================] - 0s 7ms/step - loss: 0.0061 - accuracy: 1.0000 - val_loss: 1.4359 - val_accuracy: 0.7756\n",
      "Epoch 557/1000\n",
      "33/33 [==============================] - 0s 6ms/step - loss: 0.0228 - accuracy: 0.9903 - val_loss: 1.2671 - val_accuracy: 0.7638\n",
      "Epoch 558/1000\n",
      "33/33 [==============================] - 0s 6ms/step - loss: 0.0122 - accuracy: 0.9961 - val_loss: 1.4560 - val_accuracy: 0.7835\n",
      "Epoch 559/1000\n",
      "33/33 [==============================] - 0s 6ms/step - loss: 0.0095 - accuracy: 0.9961 - val_loss: 1.3355 - val_accuracy: 0.7874\n",
      "Epoch 560/1000\n",
      "33/33 [==============================] - 0s 6ms/step - loss: 0.0134 - accuracy: 0.9981 - val_loss: 1.3452 - val_accuracy: 0.7795\n",
      "Epoch 561/1000\n",
      "33/33 [==============================] - 0s 6ms/step - loss: 0.0053 - accuracy: 0.9981 - val_loss: 1.3579 - val_accuracy: 0.7874\n",
      "Epoch 562/1000\n",
      "33/33 [==============================] - 0s 6ms/step - loss: 0.0036 - accuracy: 1.0000 - val_loss: 1.3525 - val_accuracy: 0.7913\n",
      "Epoch 563/1000\n",
      "33/33 [==============================] - 0s 6ms/step - loss: 0.0056 - accuracy: 1.0000 - val_loss: 1.3351 - val_accuracy: 0.7756\n",
      "Epoch 564/1000\n",
      "33/33 [==============================] - 0s 6ms/step - loss: 0.0038 - accuracy: 1.0000 - val_loss: 1.2036 - val_accuracy: 0.7756\n",
      "Epoch 565/1000\n",
      "33/33 [==============================] - 0s 6ms/step - loss: 0.0037 - accuracy: 1.0000 - val_loss: 1.2860 - val_accuracy: 0.7913\n",
      "Epoch 566/1000\n",
      "33/33 [==============================] - 0s 7ms/step - loss: 0.0075 - accuracy: 0.9981 - val_loss: 1.2216 - val_accuracy: 0.7913\n",
      "Epoch 567/1000\n",
      "33/33 [==============================] - 0s 7ms/step - loss: 0.0053 - accuracy: 1.0000 - val_loss: 1.3137 - val_accuracy: 0.7992\n",
      "Epoch 568/1000\n",
      "33/33 [==============================] - 0s 8ms/step - loss: 0.0057 - accuracy: 1.0000 - val_loss: 1.3181 - val_accuracy: 0.7953\n",
      "Epoch 569/1000\n",
      "33/33 [==============================] - 0s 9ms/step - loss: 0.0095 - accuracy: 0.9981 - val_loss: 1.3314 - val_accuracy: 0.7835\n",
      "Epoch 570/1000\n",
      "33/33 [==============================] - 0s 9ms/step - loss: 0.0047 - accuracy: 1.0000 - val_loss: 1.2971 - val_accuracy: 0.7677\n",
      "Epoch 571/1000\n",
      "33/33 [==============================] - 0s 9ms/step - loss: 0.0070 - accuracy: 1.0000 - val_loss: 1.2880 - val_accuracy: 0.7874\n",
      "Epoch 572/1000\n",
      "33/33 [==============================] - 0s 9ms/step - loss: 0.0064 - accuracy: 0.9981 - val_loss: 1.3610 - val_accuracy: 0.7913\n",
      "Epoch 573/1000\n",
      "33/33 [==============================] - 0s 8ms/step - loss: 0.0154 - accuracy: 0.9922 - val_loss: 1.2577 - val_accuracy: 0.7835\n",
      "Epoch 574/1000\n",
      "33/33 [==============================] - 0s 8ms/step - loss: 0.0017 - accuracy: 1.0000 - val_loss: 1.2845 - val_accuracy: 0.7835\n",
      "Epoch 575/1000\n",
      "33/33 [==============================] - 0s 9ms/step - loss: 0.0082 - accuracy: 0.9981 - val_loss: 1.3331 - val_accuracy: 0.7756\n",
      "Epoch 576/1000\n",
      "33/33 [==============================] - 0s 9ms/step - loss: 0.0170 - accuracy: 0.9942 - val_loss: 1.2279 - val_accuracy: 0.7717\n",
      "Epoch 577/1000\n",
      "33/33 [==============================] - 0s 9ms/step - loss: 0.0049 - accuracy: 1.0000 - val_loss: 1.3077 - val_accuracy: 0.7874\n",
      "Epoch 578/1000\n",
      "33/33 [==============================] - 0s 8ms/step - loss: 0.0016 - accuracy: 1.0000 - val_loss: 1.3125 - val_accuracy: 0.7795\n",
      "Epoch 579/1000\n",
      "33/33 [==============================] - 0s 9ms/step - loss: 0.0068 - accuracy: 0.9981 - val_loss: 1.2442 - val_accuracy: 0.7756\n",
      "Epoch 580/1000\n",
      "33/33 [==============================] - 0s 8ms/step - loss: 0.0101 - accuracy: 0.9961 - val_loss: 1.4945 - val_accuracy: 0.7756\n",
      "Epoch 581/1000\n",
      "33/33 [==============================] - 0s 9ms/step - loss: 0.0044 - accuracy: 1.0000 - val_loss: 1.4175 - val_accuracy: 0.7756\n",
      "Epoch 582/1000\n",
      "33/33 [==============================] - 0s 9ms/step - loss: 0.0150 - accuracy: 0.9961 - val_loss: 1.3476 - val_accuracy: 0.7795\n",
      "Epoch 583/1000\n",
      "33/33 [==============================] - 0s 9ms/step - loss: 0.0117 - accuracy: 0.9961 - val_loss: 1.3156 - val_accuracy: 0.7953\n",
      "Epoch 584/1000\n",
      "33/33 [==============================] - 0s 8ms/step - loss: 0.0220 - accuracy: 0.9961 - val_loss: 1.2537 - val_accuracy: 0.7874\n",
      "Epoch 585/1000\n",
      "33/33 [==============================] - 0s 8ms/step - loss: 0.0142 - accuracy: 0.9942 - val_loss: 1.2979 - val_accuracy: 0.7756\n",
      "Epoch 586/1000\n",
      "33/33 [==============================] - 0s 8ms/step - loss: 0.0154 - accuracy: 0.9942 - val_loss: 1.2037 - val_accuracy: 0.7874\n",
      "Epoch 587/1000\n",
      "33/33 [==============================] - 0s 8ms/step - loss: 0.0110 - accuracy: 0.9961 - val_loss: 1.2361 - val_accuracy: 0.7992\n",
      "Epoch 588/1000\n",
      "33/33 [==============================] - 0s 8ms/step - loss: 0.0085 - accuracy: 0.9981 - val_loss: 1.3093 - val_accuracy: 0.7992\n",
      "Epoch 589/1000\n",
      "33/33 [==============================] - 0s 8ms/step - loss: 0.0067 - accuracy: 1.0000 - val_loss: 1.3077 - val_accuracy: 0.7874\n",
      "Epoch 590/1000\n",
      "33/33 [==============================] - 0s 8ms/step - loss: 0.0125 - accuracy: 0.9942 - val_loss: 1.2175 - val_accuracy: 0.7992\n",
      "Epoch 591/1000\n",
      "33/33 [==============================] - 0s 8ms/step - loss: 0.0068 - accuracy: 0.9981 - val_loss: 1.3049 - val_accuracy: 0.7874\n",
      "Epoch 592/1000\n",
      "33/33 [==============================] - 0s 7ms/step - loss: 0.0072 - accuracy: 0.9981 - val_loss: 1.3439 - val_accuracy: 0.7953\n",
      "Epoch 593/1000\n",
      "33/33 [==============================] - 0s 7ms/step - loss: 0.0173 - accuracy: 0.9942 - val_loss: 1.3512 - val_accuracy: 0.7874\n",
      "Epoch 594/1000\n",
      "33/33 [==============================] - 0s 7ms/step - loss: 0.0100 - accuracy: 0.9981 - val_loss: 1.3608 - val_accuracy: 0.7953\n",
      "Epoch 595/1000\n",
      "33/33 [==============================] - 0s 8ms/step - loss: 0.0269 - accuracy: 0.9942 - val_loss: 1.1988 - val_accuracy: 0.7795\n",
      "Epoch 596/1000\n",
      "33/33 [==============================] - 0s 7ms/step - loss: 0.0075 - accuracy: 0.9981 - val_loss: 1.2726 - val_accuracy: 0.7913\n",
      "Epoch 597/1000\n",
      "33/33 [==============================] - 0s 7ms/step - loss: 0.0031 - accuracy: 1.0000 - val_loss: 1.3095 - val_accuracy: 0.7835\n",
      "Epoch 598/1000\n",
      "33/33 [==============================] - 0s 7ms/step - loss: 0.0057 - accuracy: 0.9981 - val_loss: 1.2433 - val_accuracy: 0.7992\n",
      "Epoch 599/1000\n",
      "33/33 [==============================] - 0s 7ms/step - loss: 0.0087 - accuracy: 0.9961 - val_loss: 1.2777 - val_accuracy: 0.7913\n",
      "Epoch 600/1000\n",
      "33/33 [==============================] - 0s 7ms/step - loss: 0.0047 - accuracy: 1.0000 - val_loss: 1.2145 - val_accuracy: 0.7913\n",
      "Epoch 601/1000\n",
      "33/33 [==============================] - 0s 7ms/step - loss: 0.0078 - accuracy: 0.9981 - val_loss: 1.4627 - val_accuracy: 0.7638\n",
      "Epoch 602/1000\n",
      "33/33 [==============================] - 0s 7ms/step - loss: 0.0058 - accuracy: 0.9981 - val_loss: 1.2943 - val_accuracy: 0.7874\n",
      "Epoch 603/1000\n",
      "33/33 [==============================] - 0s 7ms/step - loss: 0.0089 - accuracy: 0.9981 - val_loss: 1.2184 - val_accuracy: 0.7677\n",
      "Epoch 604/1000\n",
      "33/33 [==============================] - 0s 7ms/step - loss: 0.0072 - accuracy: 1.0000 - val_loss: 1.3318 - val_accuracy: 0.7874\n",
      "Epoch 605/1000\n",
      "33/33 [==============================] - 0s 6ms/step - loss: 0.0074 - accuracy: 0.9981 - val_loss: 1.3076 - val_accuracy: 0.7874\n",
      "Epoch 606/1000\n",
      "33/33 [==============================] - 0s 7ms/step - loss: 0.0098 - accuracy: 0.9961 - val_loss: 1.3625 - val_accuracy: 0.7874\n",
      "Epoch 607/1000\n",
      "33/33 [==============================] - 0s 7ms/step - loss: 0.0054 - accuracy: 0.9981 - val_loss: 1.3270 - val_accuracy: 0.7874\n",
      "Epoch 608/1000\n",
      "33/33 [==============================] - 0s 7ms/step - loss: 0.0101 - accuracy: 0.9961 - val_loss: 1.2842 - val_accuracy: 0.7913\n",
      "Epoch 609/1000\n",
      "33/33 [==============================] - 0s 7ms/step - loss: 0.0034 - accuracy: 1.0000 - val_loss: 1.2974 - val_accuracy: 0.7874\n",
      "Epoch 610/1000\n",
      "33/33 [==============================] - 0s 6ms/step - loss: 0.0080 - accuracy: 0.9981 - val_loss: 1.3207 - val_accuracy: 0.7795\n",
      "Epoch 611/1000\n",
      "33/33 [==============================] - 0s 7ms/step - loss: 0.0071 - accuracy: 0.9981 - val_loss: 1.2825 - val_accuracy: 0.7913\n",
      "Epoch 612/1000\n",
      "33/33 [==============================] - 0s 6ms/step - loss: 0.0078 - accuracy: 0.9981 - val_loss: 1.4506 - val_accuracy: 0.7756\n",
      "Epoch 613/1000\n",
      "33/33 [==============================] - 0s 6ms/step - loss: 0.0041 - accuracy: 1.0000 - val_loss: 1.2232 - val_accuracy: 0.7795\n",
      "Epoch 614/1000\n",
      "33/33 [==============================] - 0s 7ms/step - loss: 0.0066 - accuracy: 0.9981 - val_loss: 1.2132 - val_accuracy: 0.7795\n",
      "Epoch 615/1000\n",
      "33/33 [==============================] - 0s 8ms/step - loss: 0.0170 - accuracy: 0.9961 - val_loss: 1.3390 - val_accuracy: 0.7795\n",
      "Epoch 616/1000\n",
      "33/33 [==============================] - 0s 7ms/step - loss: 0.0081 - accuracy: 0.9981 - val_loss: 1.3045 - val_accuracy: 0.7835\n",
      "Epoch 617/1000\n",
      "33/33 [==============================] - 0s 7ms/step - loss: 0.0033 - accuracy: 1.0000 - val_loss: 1.2461 - val_accuracy: 0.7795\n",
      "Epoch 618/1000\n",
      "33/33 [==============================] - 0s 6ms/step - loss: 0.0056 - accuracy: 0.9981 - val_loss: 1.2591 - val_accuracy: 0.7756\n",
      "Epoch 619/1000\n",
      "33/33 [==============================] - 0s 6ms/step - loss: 0.0041 - accuracy: 1.0000 - val_loss: 1.2036 - val_accuracy: 0.7795\n",
      "Epoch 620/1000\n",
      "33/33 [==============================] - 0s 6ms/step - loss: 0.0114 - accuracy: 0.9981 - val_loss: 1.2033 - val_accuracy: 0.7913\n",
      "Epoch 621/1000\n",
      "33/33 [==============================] - 0s 6ms/step - loss: 0.0122 - accuracy: 0.9961 - val_loss: 1.2961 - val_accuracy: 0.7835\n",
      "Epoch 622/1000\n",
      "33/33 [==============================] - 0s 6ms/step - loss: 0.0074 - accuracy: 0.9981 - val_loss: 1.2670 - val_accuracy: 0.7717\n",
      "Epoch 623/1000\n",
      "33/33 [==============================] - 0s 6ms/step - loss: 0.0127 - accuracy: 0.9961 - val_loss: 1.2321 - val_accuracy: 0.7835\n",
      "Epoch 624/1000\n",
      "33/33 [==============================] - 0s 6ms/step - loss: 0.0098 - accuracy: 0.9961 - val_loss: 1.2881 - val_accuracy: 0.7835\n",
      "Epoch 625/1000\n",
      "33/33 [==============================] - 0s 6ms/step - loss: 0.0041 - accuracy: 0.9981 - val_loss: 1.4012 - val_accuracy: 0.7795\n",
      "Epoch 626/1000\n",
      "33/33 [==============================] - 0s 6ms/step - loss: 0.0152 - accuracy: 0.9942 - val_loss: 1.3469 - val_accuracy: 0.7953\n",
      "Epoch 627/1000\n",
      "33/33 [==============================] - 0s 6ms/step - loss: 0.0033 - accuracy: 1.0000 - val_loss: 1.3248 - val_accuracy: 0.7874\n",
      "Epoch 628/1000\n",
      "33/33 [==============================] - 0s 7ms/step - loss: 0.0076 - accuracy: 0.9981 - val_loss: 1.4311 - val_accuracy: 0.7795\n",
      "Epoch 629/1000\n",
      "33/33 [==============================] - 0s 7ms/step - loss: 0.0060 - accuracy: 0.9981 - val_loss: 1.3017 - val_accuracy: 0.7992\n",
      "Epoch 630/1000\n",
      "33/33 [==============================] - 0s 6ms/step - loss: 0.0053 - accuracy: 1.0000 - val_loss: 1.3589 - val_accuracy: 0.7953\n",
      "Epoch 631/1000\n",
      "33/33 [==============================] - 0s 7ms/step - loss: 0.0043 - accuracy: 1.0000 - val_loss: 1.3207 - val_accuracy: 0.7992\n",
      "Epoch 632/1000\n",
      "33/33 [==============================] - 0s 7ms/step - loss: 0.0031 - accuracy: 1.0000 - val_loss: 1.2859 - val_accuracy: 0.7874\n",
      "Epoch 633/1000\n",
      "33/33 [==============================] - 0s 7ms/step - loss: 0.0026 - accuracy: 1.0000 - val_loss: 1.4321 - val_accuracy: 0.7795\n",
      "Epoch 634/1000\n",
      "33/33 [==============================] - 0s 8ms/step - loss: 0.0135 - accuracy: 0.9961 - val_loss: 1.3295 - val_accuracy: 0.7835\n",
      "Epoch 635/1000\n",
      "33/33 [==============================] - 0s 7ms/step - loss: 0.0113 - accuracy: 0.9961 - val_loss: 1.3743 - val_accuracy: 0.7913\n",
      "Epoch 636/1000\n",
      "33/33 [==============================] - 0s 8ms/step - loss: 0.0055 - accuracy: 0.9981 - val_loss: 1.3675 - val_accuracy: 0.7953\n",
      "Epoch 637/1000\n",
      "33/33 [==============================] - 0s 7ms/step - loss: 0.0054 - accuracy: 0.9981 - val_loss: 1.3303 - val_accuracy: 0.7913\n",
      "Epoch 638/1000\n",
      "33/33 [==============================] - 0s 7ms/step - loss: 0.0052 - accuracy: 0.9981 - val_loss: 1.3180 - val_accuracy: 0.7717\n",
      "Epoch 639/1000\n",
      "33/33 [==============================] - 0s 7ms/step - loss: 0.0069 - accuracy: 1.0000 - val_loss: 1.2701 - val_accuracy: 0.7953\n",
      "Epoch 640/1000\n",
      "33/33 [==============================] - 0s 7ms/step - loss: 0.0070 - accuracy: 0.9981 - val_loss: 1.3714 - val_accuracy: 0.7677\n",
      "Epoch 641/1000\n",
      "33/33 [==============================] - 0s 7ms/step - loss: 0.0134 - accuracy: 0.9961 - val_loss: 1.3322 - val_accuracy: 0.7953\n",
      "Epoch 642/1000\n",
      "33/33 [==============================] - 0s 6ms/step - loss: 0.0065 - accuracy: 0.9981 - val_loss: 1.3085 - val_accuracy: 0.7953\n",
      "Epoch 643/1000\n",
      "33/33 [==============================] - 0s 6ms/step - loss: 0.0085 - accuracy: 0.9981 - val_loss: 1.4921 - val_accuracy: 0.7717\n",
      "Epoch 644/1000\n",
      "33/33 [==============================] - 0s 6ms/step - loss: 0.0091 - accuracy: 0.9981 - val_loss: 1.3623 - val_accuracy: 0.7795\n",
      "Epoch 645/1000\n",
      "33/33 [==============================] - 0s 7ms/step - loss: 0.0070 - accuracy: 0.9981 - val_loss: 1.3625 - val_accuracy: 0.7756\n",
      "Epoch 646/1000\n",
      "33/33 [==============================] - 0s 8ms/step - loss: 0.0094 - accuracy: 0.9981 - val_loss: 1.3437 - val_accuracy: 0.7756\n",
      "Epoch 647/1000\n",
      "33/33 [==============================] - 0s 7ms/step - loss: 0.0074 - accuracy: 0.9981 - val_loss: 1.3228 - val_accuracy: 0.7795\n",
      "Epoch 648/1000\n",
      "33/33 [==============================] - 0s 7ms/step - loss: 0.0104 - accuracy: 0.9981 - val_loss: 1.1976 - val_accuracy: 0.7835\n",
      "Epoch 649/1000\n",
      "33/33 [==============================] - 0s 7ms/step - loss: 0.0054 - accuracy: 0.9981 - val_loss: 1.3287 - val_accuracy: 0.7953\n",
      "Epoch 650/1000\n",
      "33/33 [==============================] - 0s 7ms/step - loss: 0.0086 - accuracy: 0.9981 - val_loss: 1.3616 - val_accuracy: 0.7913\n",
      "Epoch 651/1000\n",
      "33/33 [==============================] - 0s 8ms/step - loss: 0.0031 - accuracy: 1.0000 - val_loss: 1.2439 - val_accuracy: 0.7835\n",
      "Epoch 652/1000\n",
      "33/33 [==============================] - 0s 7ms/step - loss: 0.0047 - accuracy: 0.9981 - val_loss: 1.2032 - val_accuracy: 0.7795\n",
      "Epoch 653/1000\n",
      "33/33 [==============================] - 0s 7ms/step - loss: 0.0047 - accuracy: 0.9981 - val_loss: 1.4398 - val_accuracy: 0.7756\n",
      "Epoch 654/1000\n",
      "33/33 [==============================] - 0s 6ms/step - loss: 0.0036 - accuracy: 1.0000 - val_loss: 1.2255 - val_accuracy: 0.8031\n",
      "Epoch 655/1000\n",
      "33/33 [==============================] - 0s 7ms/step - loss: 0.0019 - accuracy: 1.0000 - val_loss: 1.3508 - val_accuracy: 0.7913\n",
      "Epoch 656/1000\n",
      "33/33 [==============================] - 0s 7ms/step - loss: 0.0059 - accuracy: 0.9981 - val_loss: 1.2808 - val_accuracy: 0.7874\n",
      "Epoch 657/1000\n",
      "33/33 [==============================] - 0s 7ms/step - loss: 0.0043 - accuracy: 0.9981 - val_loss: 1.3445 - val_accuracy: 0.7835\n",
      "Epoch 658/1000\n",
      "33/33 [==============================] - 0s 7ms/step - loss: 0.0069 - accuracy: 0.9961 - val_loss: 1.4308 - val_accuracy: 0.7992\n",
      "Epoch 659/1000\n",
      "33/33 [==============================] - 0s 7ms/step - loss: 0.0028 - accuracy: 1.0000 - val_loss: 1.3424 - val_accuracy: 0.7953\n",
      "Epoch 660/1000\n",
      "33/33 [==============================] - 0s 7ms/step - loss: 0.0119 - accuracy: 0.9942 - val_loss: 1.3291 - val_accuracy: 0.7992\n",
      "Epoch 661/1000\n",
      "33/33 [==============================] - 0s 7ms/step - loss: 0.0038 - accuracy: 1.0000 - val_loss: 1.2894 - val_accuracy: 0.7953\n",
      "Epoch 662/1000\n",
      "33/33 [==============================] - 0s 7ms/step - loss: 0.0126 - accuracy: 0.9961 - val_loss: 1.3131 - val_accuracy: 0.7795\n",
      "Epoch 663/1000\n",
      "33/33 [==============================] - 0s 6ms/step - loss: 0.0045 - accuracy: 1.0000 - val_loss: 1.2666 - val_accuracy: 0.7913\n",
      "Epoch 664/1000\n",
      "33/33 [==============================] - 0s 6ms/step - loss: 0.0062 - accuracy: 0.9981 - val_loss: 1.3174 - val_accuracy: 0.7953\n",
      "Epoch 665/1000\n",
      "33/33 [==============================] - 0s 7ms/step - loss: 0.0152 - accuracy: 0.9981 - val_loss: 1.3073 - val_accuracy: 0.7874\n",
      "Epoch 666/1000\n",
      "33/33 [==============================] - 0s 7ms/step - loss: 0.0186 - accuracy: 0.9942 - val_loss: 1.2711 - val_accuracy: 0.7598\n",
      "Epoch 667/1000\n",
      "33/33 [==============================] - 0s 7ms/step - loss: 0.0085 - accuracy: 0.9981 - val_loss: 1.3624 - val_accuracy: 0.7638\n",
      "Epoch 668/1000\n",
      "33/33 [==============================] - 0s 7ms/step - loss: 0.0057 - accuracy: 0.9981 - val_loss: 1.2723 - val_accuracy: 0.7795\n",
      "Epoch 669/1000\n",
      "33/33 [==============================] - 0s 7ms/step - loss: 0.0085 - accuracy: 0.9961 - val_loss: 1.2667 - val_accuracy: 0.7874\n",
      "Epoch 670/1000\n",
      "33/33 [==============================] - 0s 8ms/step - loss: 0.0143 - accuracy: 0.9942 - val_loss: 1.2592 - val_accuracy: 0.7874\n",
      "Epoch 671/1000\n",
      "33/33 [==============================] - 0s 8ms/step - loss: 0.0049 - accuracy: 1.0000 - val_loss: 1.3077 - val_accuracy: 0.7913\n",
      "Epoch 672/1000\n",
      "33/33 [==============================] - 0s 7ms/step - loss: 0.0050 - accuracy: 0.9981 - val_loss: 1.2853 - val_accuracy: 0.7795\n",
      "Epoch 673/1000\n",
      "33/33 [==============================] - 0s 8ms/step - loss: 0.0055 - accuracy: 1.0000 - val_loss: 1.3203 - val_accuracy: 0.7953\n",
      "Epoch 674/1000\n",
      "33/33 [==============================] - 0s 7ms/step - loss: 0.0020 - accuracy: 1.0000 - val_loss: 1.3500 - val_accuracy: 0.7992\n",
      "Epoch 675/1000\n",
      "33/33 [==============================] - 0s 7ms/step - loss: 0.0226 - accuracy: 0.9942 - val_loss: 1.2919 - val_accuracy: 0.7953\n",
      "Epoch 676/1000\n",
      "33/33 [==============================] - 0s 7ms/step - loss: 0.0018 - accuracy: 1.0000 - val_loss: 1.3402 - val_accuracy: 0.7874\n",
      "Epoch 677/1000\n",
      "33/33 [==============================] - 0s 6ms/step - loss: 0.0033 - accuracy: 1.0000 - val_loss: 1.2757 - val_accuracy: 0.7874\n",
      "Epoch 678/1000\n",
      "33/33 [==============================] - 0s 6ms/step - loss: 0.0076 - accuracy: 0.9981 - val_loss: 1.2761 - val_accuracy: 0.7795\n",
      "Epoch 679/1000\n",
      "33/33 [==============================] - 0s 6ms/step - loss: 0.0029 - accuracy: 1.0000 - val_loss: 1.3322 - val_accuracy: 0.7953\n",
      "Epoch 680/1000\n",
      "33/33 [==============================] - 0s 7ms/step - loss: 0.0059 - accuracy: 0.9981 - val_loss: 1.2831 - val_accuracy: 0.7913\n",
      "Epoch 681/1000\n",
      "33/33 [==============================] - 0s 6ms/step - loss: 0.0140 - accuracy: 0.9922 - val_loss: 1.3323 - val_accuracy: 0.7717\n",
      "Epoch 682/1000\n",
      "33/33 [==============================] - 0s 6ms/step - loss: 0.0053 - accuracy: 0.9981 - val_loss: 1.3273 - val_accuracy: 0.7874\n",
      "Epoch 683/1000\n",
      "33/33 [==============================] - 0s 6ms/step - loss: 0.0051 - accuracy: 1.0000 - val_loss: 1.2991 - val_accuracy: 0.7953\n",
      "Epoch 684/1000\n",
      "33/33 [==============================] - 0s 6ms/step - loss: 0.0053 - accuracy: 1.0000 - val_loss: 1.2765 - val_accuracy: 0.7756\n",
      "Epoch 685/1000\n",
      "33/33 [==============================] - 0s 7ms/step - loss: 0.0026 - accuracy: 1.0000 - val_loss: 1.4266 - val_accuracy: 0.7717\n",
      "Epoch 686/1000\n",
      "33/33 [==============================] - 0s 7ms/step - loss: 0.0034 - accuracy: 1.0000 - val_loss: 1.3955 - val_accuracy: 0.7874\n",
      "Epoch 687/1000\n",
      "33/33 [==============================] - 0s 6ms/step - loss: 0.0092 - accuracy: 0.9981 - val_loss: 1.3407 - val_accuracy: 0.7677\n",
      "Epoch 688/1000\n",
      "33/33 [==============================] - 0s 6ms/step - loss: 0.0082 - accuracy: 1.0000 - val_loss: 1.3020 - val_accuracy: 0.7874\n",
      "Epoch 689/1000\n",
      "33/33 [==============================] - 0s 6ms/step - loss: 0.0125 - accuracy: 0.9922 - val_loss: 1.3705 - val_accuracy: 0.7835\n",
      "Epoch 690/1000\n",
      "33/33 [==============================] - 0s 6ms/step - loss: 0.0092 - accuracy: 0.9942 - val_loss: 1.3785 - val_accuracy: 0.7795\n",
      "Epoch 691/1000\n",
      "33/33 [==============================] - 0s 6ms/step - loss: 0.0048 - accuracy: 1.0000 - val_loss: 1.2450 - val_accuracy: 0.8031\n",
      "Epoch 692/1000\n",
      "33/33 [==============================] - 0s 6ms/step - loss: 0.0076 - accuracy: 0.9981 - val_loss: 1.2979 - val_accuracy: 0.7913\n",
      "Epoch 693/1000\n",
      "33/33 [==============================] - 0s 6ms/step - loss: 0.0070 - accuracy: 0.9981 - val_loss: 1.4243 - val_accuracy: 0.7756\n",
      "Epoch 694/1000\n",
      "33/33 [==============================] - 0s 6ms/step - loss: 0.0099 - accuracy: 0.9961 - val_loss: 1.1880 - val_accuracy: 0.7992\n",
      "Epoch 695/1000\n",
      "33/33 [==============================] - 0s 6ms/step - loss: 0.0094 - accuracy: 0.9961 - val_loss: 1.2044 - val_accuracy: 0.7913\n",
      "Epoch 696/1000\n",
      "33/33 [==============================] - 0s 6ms/step - loss: 0.0062 - accuracy: 0.9981 - val_loss: 1.2389 - val_accuracy: 0.7992\n",
      "Epoch 697/1000\n",
      "33/33 [==============================] - 0s 6ms/step - loss: 0.0085 - accuracy: 0.9961 - val_loss: 1.3162 - val_accuracy: 0.7677\n",
      "Epoch 698/1000\n",
      "33/33 [==============================] - 0s 6ms/step - loss: 0.0065 - accuracy: 0.9981 - val_loss: 1.3542 - val_accuracy: 0.7756\n",
      "Epoch 699/1000\n",
      "33/33 [==============================] - 0s 6ms/step - loss: 0.0075 - accuracy: 0.9981 - val_loss: 1.3684 - val_accuracy: 0.7677\n",
      "Epoch 700/1000\n",
      "33/33 [==============================] - 0s 6ms/step - loss: 0.0184 - accuracy: 0.9961 - val_loss: 1.2545 - val_accuracy: 0.7874\n",
      "Epoch 701/1000\n",
      "33/33 [==============================] - 0s 6ms/step - loss: 0.0032 - accuracy: 1.0000 - val_loss: 1.4567 - val_accuracy: 0.7756\n",
      "Epoch 702/1000\n",
      "33/33 [==============================] - 0s 6ms/step - loss: 0.0135 - accuracy: 0.9981 - val_loss: 1.2900 - val_accuracy: 0.8071\n",
      "Epoch 703/1000\n",
      "33/33 [==============================] - 0s 6ms/step - loss: 0.0063 - accuracy: 0.9981 - val_loss: 1.2818 - val_accuracy: 0.8031\n",
      "Epoch 704/1000\n",
      "33/33 [==============================] - 0s 6ms/step - loss: 0.0166 - accuracy: 0.9961 - val_loss: 1.4158 - val_accuracy: 0.7913\n",
      "Epoch 705/1000\n",
      "33/33 [==============================] - 0s 6ms/step - loss: 0.0057 - accuracy: 1.0000 - val_loss: 1.2888 - val_accuracy: 0.7953\n",
      "Epoch 706/1000\n",
      "33/33 [==============================] - 0s 6ms/step - loss: 0.0029 - accuracy: 1.0000 - val_loss: 1.3914 - val_accuracy: 0.7913\n",
      "Epoch 707/1000\n",
      "33/33 [==============================] - 0s 6ms/step - loss: 0.0060 - accuracy: 1.0000 - val_loss: 1.2851 - val_accuracy: 0.8031\n",
      "Epoch 708/1000\n",
      "33/33 [==============================] - 0s 6ms/step - loss: 0.0040 - accuracy: 1.0000 - val_loss: 1.2941 - val_accuracy: 0.7874\n",
      "Epoch 709/1000\n",
      "33/33 [==============================] - 0s 6ms/step - loss: 0.0034 - accuracy: 1.0000 - val_loss: 1.3894 - val_accuracy: 0.7874\n",
      "Epoch 710/1000\n",
      "33/33 [==============================] - 0s 6ms/step - loss: 0.0074 - accuracy: 0.9961 - val_loss: 1.3737 - val_accuracy: 0.7835\n",
      "Epoch 711/1000\n",
      "33/33 [==============================] - 0s 6ms/step - loss: 0.0054 - accuracy: 0.9981 - val_loss: 1.2401 - val_accuracy: 0.7795\n",
      "Epoch 712/1000\n",
      "33/33 [==============================] - 0s 7ms/step - loss: 0.0084 - accuracy: 0.9961 - val_loss: 1.2795 - val_accuracy: 0.7874\n",
      "Epoch 713/1000\n",
      "33/33 [==============================] - 0s 7ms/step - loss: 0.0153 - accuracy: 0.9942 - val_loss: 1.2352 - val_accuracy: 0.8031\n",
      "Epoch 714/1000\n",
      "33/33 [==============================] - 0s 8ms/step - loss: 0.0071 - accuracy: 0.9961 - val_loss: 1.3866 - val_accuracy: 0.7913\n",
      "Epoch 715/1000\n",
      "33/33 [==============================] - 0s 7ms/step - loss: 0.0034 - accuracy: 1.0000 - val_loss: 1.2218 - val_accuracy: 0.7992\n",
      "Epoch 716/1000\n",
      "33/33 [==============================] - 0s 8ms/step - loss: 0.0032 - accuracy: 1.0000 - val_loss: 1.2882 - val_accuracy: 0.7874\n",
      "Epoch 717/1000\n",
      "33/33 [==============================] - 0s 9ms/step - loss: 0.0105 - accuracy: 0.9961 - val_loss: 1.3312 - val_accuracy: 0.7677\n",
      "Epoch 718/1000\n",
      "33/33 [==============================] - 0s 9ms/step - loss: 0.0035 - accuracy: 1.0000 - val_loss: 1.2850 - val_accuracy: 0.7874\n",
      "Epoch 719/1000\n",
      "33/33 [==============================] - 0s 8ms/step - loss: 0.0062 - accuracy: 1.0000 - val_loss: 1.3871 - val_accuracy: 0.7874\n",
      "Epoch 720/1000\n",
      "33/33 [==============================] - 0s 7ms/step - loss: 0.0047 - accuracy: 0.9981 - val_loss: 1.3604 - val_accuracy: 0.7677\n",
      "Epoch 721/1000\n",
      "33/33 [==============================] - ETA: 0s - loss: 0.0142 - accuracy: 0.99 - 0s 8ms/step - loss: 0.0129 - accuracy: 0.9922 - val_loss: 1.4002 - val_accuracy: 0.8031\n",
      "Epoch 722/1000\n",
      "33/33 [==============================] - 0s 7ms/step - loss: 0.0028 - accuracy: 1.0000 - val_loss: 1.4727 - val_accuracy: 0.7756\n",
      "Epoch 723/1000\n",
      "33/33 [==============================] - 0s 7ms/step - loss: 0.0081 - accuracy: 0.9981 - val_loss: 1.3442 - val_accuracy: 0.7874\n",
      "Epoch 724/1000\n",
      "33/33 [==============================] - 0s 7ms/step - loss: 0.0137 - accuracy: 0.9961 - val_loss: 1.3795 - val_accuracy: 0.7835\n",
      "Epoch 725/1000\n",
      "33/33 [==============================] - 0s 7ms/step - loss: 0.0036 - accuracy: 1.0000 - val_loss: 1.2972 - val_accuracy: 0.7953\n",
      "Epoch 726/1000\n",
      "33/33 [==============================] - 0s 7ms/step - loss: 0.0071 - accuracy: 0.9981 - val_loss: 1.4224 - val_accuracy: 0.7992\n",
      "Epoch 727/1000\n",
      "33/33 [==============================] - 0s 7ms/step - loss: 0.0035 - accuracy: 1.0000 - val_loss: 1.2608 - val_accuracy: 0.7913\n",
      "Epoch 728/1000\n",
      "33/33 [==============================] - 0s 7ms/step - loss: 0.0047 - accuracy: 1.0000 - val_loss: 1.3602 - val_accuracy: 0.7953\n",
      "Epoch 729/1000\n",
      "33/33 [==============================] - 0s 7ms/step - loss: 0.0077 - accuracy: 0.9981 - val_loss: 1.3289 - val_accuracy: 0.7953\n",
      "Epoch 730/1000\n",
      "33/33 [==============================] - 0s 7ms/step - loss: 0.0036 - accuracy: 1.0000 - val_loss: 1.3567 - val_accuracy: 0.7913\n",
      "Epoch 731/1000\n",
      "33/33 [==============================] - 0s 7ms/step - loss: 0.0066 - accuracy: 0.9981 - val_loss: 1.3123 - val_accuracy: 0.7913\n",
      "Epoch 732/1000\n",
      "33/33 [==============================] - 0s 7ms/step - loss: 0.0021 - accuracy: 1.0000 - val_loss: 1.2477 - val_accuracy: 0.8071\n",
      "Epoch 733/1000\n",
      "33/33 [==============================] - 0s 7ms/step - loss: 0.0026 - accuracy: 1.0000 - val_loss: 1.4843 - val_accuracy: 0.7717\n",
      "Epoch 734/1000\n",
      "33/33 [==============================] - 0s 6ms/step - loss: 0.0036 - accuracy: 0.9981 - val_loss: 1.2946 - val_accuracy: 0.7953\n",
      "Epoch 735/1000\n",
      "33/33 [==============================] - 0s 7ms/step - loss: 0.0061 - accuracy: 0.9981 - val_loss: 1.3470 - val_accuracy: 0.7835\n",
      "Epoch 736/1000\n",
      "33/33 [==============================] - 0s 7ms/step - loss: 0.0066 - accuracy: 0.9981 - val_loss: 1.3286 - val_accuracy: 0.7874\n",
      "Epoch 737/1000\n",
      "33/33 [==============================] - 0s 7ms/step - loss: 0.0183 - accuracy: 0.9961 - val_loss: 1.4492 - val_accuracy: 0.7953\n",
      "Epoch 738/1000\n",
      "33/33 [==============================] - 0s 7ms/step - loss: 0.0038 - accuracy: 1.0000 - val_loss: 1.3261 - val_accuracy: 0.7874\n",
      "Epoch 739/1000\n",
      "33/33 [==============================] - 0s 6ms/step - loss: 0.0062 - accuracy: 0.9981 - val_loss: 1.3005 - val_accuracy: 0.7913\n",
      "Epoch 740/1000\n",
      "33/33 [==============================] - 0s 7ms/step - loss: 0.0089 - accuracy: 0.9961 - val_loss: 1.2683 - val_accuracy: 0.8031\n",
      "Epoch 741/1000\n",
      "33/33 [==============================] - 0s 7ms/step - loss: 0.0023 - accuracy: 1.0000 - val_loss: 1.2695 - val_accuracy: 0.8031\n",
      "Epoch 742/1000\n",
      "33/33 [==============================] - 0s 6ms/step - loss: 0.0035 - accuracy: 1.0000 - val_loss: 1.4603 - val_accuracy: 0.7795\n",
      "Epoch 743/1000\n",
      "33/33 [==============================] - 0s 6ms/step - loss: 0.0054 - accuracy: 1.0000 - val_loss: 1.3349 - val_accuracy: 0.8071\n",
      "Epoch 744/1000\n",
      "33/33 [==============================] - 0s 7ms/step - loss: 0.0043 - accuracy: 1.0000 - val_loss: 1.4124 - val_accuracy: 0.7953\n",
      "Epoch 745/1000\n",
      "33/33 [==============================] - 0s 7ms/step - loss: 0.0089 - accuracy: 0.9981 - val_loss: 1.3453 - val_accuracy: 0.7874\n",
      "Epoch 746/1000\n",
      "33/33 [==============================] - 0s 7ms/step - loss: 0.0069 - accuracy: 0.9981 - val_loss: 1.3496 - val_accuracy: 0.7953\n",
      "Epoch 747/1000\n",
      "33/33 [==============================] - 0s 6ms/step - loss: 0.0047 - accuracy: 0.9981 - val_loss: 1.3572 - val_accuracy: 0.7874\n",
      "Epoch 748/1000\n",
      "33/33 [==============================] - 0s 6ms/step - loss: 0.0081 - accuracy: 0.9942 - val_loss: 1.3391 - val_accuracy: 0.7795\n",
      "Epoch 749/1000\n",
      "33/33 [==============================] - 0s 6ms/step - loss: 0.0049 - accuracy: 0.9981 - val_loss: 1.1903 - val_accuracy: 0.7795\n",
      "Epoch 750/1000\n",
      "33/33 [==============================] - 0s 7ms/step - loss: 0.0054 - accuracy: 0.9981 - val_loss: 1.2631 - val_accuracy: 0.7992\n",
      "Epoch 751/1000\n",
      "33/33 [==============================] - 0s 7ms/step - loss: 0.0025 - accuracy: 1.0000 - val_loss: 1.2386 - val_accuracy: 0.7795\n",
      "Epoch 752/1000\n",
      "33/33 [==============================] - 0s 7ms/step - loss: 0.0053 - accuracy: 1.0000 - val_loss: 1.4114 - val_accuracy: 0.7717\n",
      "Epoch 753/1000\n",
      "33/33 [==============================] - 0s 7ms/step - loss: 0.0042 - accuracy: 1.0000 - val_loss: 1.2890 - val_accuracy: 0.7835\n",
      "Epoch 754/1000\n",
      "33/33 [==============================] - 0s 7ms/step - loss: 0.0059 - accuracy: 1.0000 - val_loss: 1.2968 - val_accuracy: 0.7835\n",
      "Epoch 755/1000\n",
      "33/33 [==============================] - 0s 7ms/step - loss: 0.0034 - accuracy: 1.0000 - val_loss: 1.3430 - val_accuracy: 0.7795\n",
      "Epoch 756/1000\n",
      "33/33 [==============================] - 0s 7ms/step - loss: 0.0024 - accuracy: 1.0000 - val_loss: 1.3214 - val_accuracy: 0.7795\n",
      "Epoch 757/1000\n",
      "33/33 [==============================] - 0s 7ms/step - loss: 0.0060 - accuracy: 0.9981 - val_loss: 1.4180 - val_accuracy: 0.8031\n",
      "Epoch 758/1000\n",
      "33/33 [==============================] - 0s 7ms/step - loss: 0.0159 - accuracy: 0.9981 - val_loss: 1.3456 - val_accuracy: 0.7835\n",
      "Epoch 759/1000\n",
      "33/33 [==============================] - 0s 8ms/step - loss: 0.0072 - accuracy: 0.9961 - val_loss: 1.2660 - val_accuracy: 0.7835\n",
      "Epoch 760/1000\n",
      "33/33 [==============================] - 0s 8ms/step - loss: 0.0019 - accuracy: 1.0000 - val_loss: 1.3083 - val_accuracy: 0.7874\n",
      "Epoch 761/1000\n",
      "33/33 [==============================] - 0s 7ms/step - loss: 0.0046 - accuracy: 1.0000 - val_loss: 1.2383 - val_accuracy: 0.7953\n",
      "Epoch 762/1000\n",
      "33/33 [==============================] - 0s 7ms/step - loss: 0.0032 - accuracy: 0.9981 - val_loss: 1.3822 - val_accuracy: 0.7717\n",
      "Epoch 763/1000\n",
      "33/33 [==============================] - 0s 6ms/step - loss: 0.0111 - accuracy: 0.9961 - val_loss: 1.4218 - val_accuracy: 0.7874\n",
      "Epoch 764/1000\n",
      "33/33 [==============================] - 0s 6ms/step - loss: 0.0047 - accuracy: 0.9981 - val_loss: 1.3917 - val_accuracy: 0.7953\n",
      "Epoch 765/1000\n",
      "33/33 [==============================] - 0s 6ms/step - loss: 0.0067 - accuracy: 1.0000 - val_loss: 1.3657 - val_accuracy: 0.7874\n",
      "Epoch 766/1000\n",
      "33/33 [==============================] - 0s 6ms/step - loss: 0.0045 - accuracy: 1.0000 - val_loss: 1.2908 - val_accuracy: 0.8031\n",
      "Epoch 767/1000\n",
      "33/33 [==============================] - 0s 7ms/step - loss: 0.0144 - accuracy: 0.9961 - val_loss: 1.3928 - val_accuracy: 0.7913\n",
      "Epoch 768/1000\n",
      "33/33 [==============================] - 0s 8ms/step - loss: 0.0073 - accuracy: 0.9981 - val_loss: 1.3092 - val_accuracy: 0.7835\n",
      "Epoch 769/1000\n",
      "33/33 [==============================] - 0s 7ms/step - loss: 0.0058 - accuracy: 1.0000 - val_loss: 1.3340 - val_accuracy: 0.7992\n",
      "Epoch 770/1000\n",
      "33/33 [==============================] - 0s 7ms/step - loss: 0.0136 - accuracy: 0.9922 - val_loss: 1.4193 - val_accuracy: 0.7795\n",
      "Epoch 771/1000\n",
      "33/33 [==============================] - 0s 7ms/step - loss: 0.0051 - accuracy: 0.9981 - val_loss: 1.3184 - val_accuracy: 0.7677\n",
      "Epoch 772/1000\n",
      "33/33 [==============================] - 0s 6ms/step - loss: 0.0036 - accuracy: 1.0000 - val_loss: 1.2886 - val_accuracy: 0.7874\n",
      "Epoch 773/1000\n",
      "33/33 [==============================] - 0s 6ms/step - loss: 0.0131 - accuracy: 0.9961 - val_loss: 1.4678 - val_accuracy: 0.7756\n",
      "Epoch 774/1000\n",
      "33/33 [==============================] - 0s 6ms/step - loss: 0.0044 - accuracy: 1.0000 - val_loss: 1.3098 - val_accuracy: 0.7953\n",
      "Epoch 775/1000\n",
      "33/33 [==============================] - 0s 6ms/step - loss: 0.0020 - accuracy: 1.0000 - val_loss: 1.3666 - val_accuracy: 0.7756\n",
      "Epoch 776/1000\n",
      "33/33 [==============================] - 0s 6ms/step - loss: 0.0040 - accuracy: 0.9981 - val_loss: 1.3114 - val_accuracy: 0.7992\n",
      "Epoch 777/1000\n",
      "33/33 [==============================] - 0s 6ms/step - loss: 0.0062 - accuracy: 1.0000 - val_loss: 1.2668 - val_accuracy: 0.7953\n",
      "Epoch 778/1000\n",
      "33/33 [==============================] - 0s 7ms/step - loss: 0.0041 - accuracy: 1.0000 - val_loss: 1.4543 - val_accuracy: 0.7795\n",
      "Epoch 779/1000\n",
      "33/33 [==============================] - 0s 7ms/step - loss: 0.0134 - accuracy: 0.9961 - val_loss: 1.2889 - val_accuracy: 0.7835\n",
      "Epoch 780/1000\n",
      "33/33 [==============================] - 0s 7ms/step - loss: 0.0030 - accuracy: 0.9981 - val_loss: 1.2052 - val_accuracy: 0.8031\n",
      "Epoch 781/1000\n",
      "33/33 [==============================] - 0s 7ms/step - loss: 0.0044 - accuracy: 1.0000 - val_loss: 1.3252 - val_accuracy: 0.7795\n",
      "Epoch 782/1000\n",
      "33/33 [==============================] - 0s 7ms/step - loss: 0.0096 - accuracy: 0.9981 - val_loss: 1.2822 - val_accuracy: 0.7835\n",
      "Epoch 783/1000\n",
      "33/33 [==============================] - 0s 7ms/step - loss: 0.0064 - accuracy: 0.9981 - val_loss: 1.3023 - val_accuracy: 0.7835\n",
      "Epoch 784/1000\n",
      "33/33 [==============================] - 0s 7ms/step - loss: 0.0031 - accuracy: 0.9981 - val_loss: 1.3048 - val_accuracy: 0.7835\n",
      "Epoch 785/1000\n",
      "33/33 [==============================] - 0s 7ms/step - loss: 0.0212 - accuracy: 0.9942 - val_loss: 1.2831 - val_accuracy: 0.7953\n",
      "Epoch 786/1000\n",
      "33/33 [==============================] - 0s 7ms/step - loss: 0.0041 - accuracy: 1.0000 - val_loss: 1.2435 - val_accuracy: 0.7874\n",
      "Epoch 787/1000\n",
      "33/33 [==============================] - 0s 7ms/step - loss: 0.0032 - accuracy: 0.9981 - val_loss: 1.3069 - val_accuracy: 0.7992\n",
      "Epoch 788/1000\n",
      "33/33 [==============================] - 0s 6ms/step - loss: 0.0082 - accuracy: 0.9981 - val_loss: 1.3609 - val_accuracy: 0.7874\n",
      "Epoch 789/1000\n",
      "33/33 [==============================] - 0s 7ms/step - loss: 0.0087 - accuracy: 0.9981 - val_loss: 1.3014 - val_accuracy: 0.7953\n",
      "Epoch 790/1000\n",
      "33/33 [==============================] - 0s 7ms/step - loss: 0.0058 - accuracy: 0.9981 - val_loss: 1.2747 - val_accuracy: 0.7835\n",
      "Epoch 791/1000\n",
      "33/33 [==============================] - 0s 6ms/step - loss: 0.0096 - accuracy: 0.9961 - val_loss: 1.4458 - val_accuracy: 0.7835\n",
      "Epoch 792/1000\n",
      "33/33 [==============================] - 0s 6ms/step - loss: 0.0051 - accuracy: 1.0000 - val_loss: 1.3111 - val_accuracy: 0.7913\n",
      "Epoch 793/1000\n",
      "33/33 [==============================] - 0s 6ms/step - loss: 0.0080 - accuracy: 0.9981 - val_loss: 1.3761 - val_accuracy: 0.7717\n",
      "Epoch 794/1000\n",
      "33/33 [==============================] - 0s 6ms/step - loss: 0.0069 - accuracy: 0.9981 - val_loss: 1.3286 - val_accuracy: 0.7874\n",
      "Epoch 795/1000\n",
      "33/33 [==============================] - 0s 7ms/step - loss: 0.0048 - accuracy: 0.9981 - val_loss: 1.2542 - val_accuracy: 0.7874\n",
      "Epoch 796/1000\n",
      "33/33 [==============================] - 0s 7ms/step - loss: 0.0064 - accuracy: 0.9961 - val_loss: 1.3038 - val_accuracy: 0.7835\n",
      "Epoch 797/1000\n",
      "33/33 [==============================] - 0s 6ms/step - loss: 0.0042 - accuracy: 1.0000 - val_loss: 1.2748 - val_accuracy: 0.7795\n",
      "Epoch 798/1000\n",
      "33/33 [==============================] - 0s 6ms/step - loss: 0.0062 - accuracy: 0.9981 - val_loss: 1.3821 - val_accuracy: 0.7835\n",
      "Epoch 799/1000\n",
      "33/33 [==============================] - 0s 6ms/step - loss: 0.0058 - accuracy: 0.9981 - val_loss: 1.3177 - val_accuracy: 0.7913\n",
      "Epoch 800/1000\n",
      "33/33 [==============================] - 0s 7ms/step - loss: 0.0056 - accuracy: 0.9981 - val_loss: 1.3131 - val_accuracy: 0.7835\n",
      "Epoch 801/1000\n",
      "33/33 [==============================] - 0s 7ms/step - loss: 0.0106 - accuracy: 0.9961 - val_loss: 1.2908 - val_accuracy: 0.7913\n",
      "Epoch 802/1000\n",
      "33/33 [==============================] - 0s 6ms/step - loss: 0.0104 - accuracy: 0.9961 - val_loss: 1.2881 - val_accuracy: 0.7913\n",
      "Epoch 803/1000\n",
      "33/33 [==============================] - 0s 6ms/step - loss: 0.0070 - accuracy: 0.9981 - val_loss: 1.3466 - val_accuracy: 0.7953\n",
      "Epoch 804/1000\n",
      "33/33 [==============================] - 0s 6ms/step - loss: 0.0057 - accuracy: 0.9981 - val_loss: 1.3688 - val_accuracy: 0.7953\n",
      "Epoch 805/1000\n",
      "33/33 [==============================] - 0s 6ms/step - loss: 0.0063 - accuracy: 0.9961 - val_loss: 1.2718 - val_accuracy: 0.7953\n",
      "Epoch 806/1000\n",
      "33/33 [==============================] - 0s 6ms/step - loss: 0.0077 - accuracy: 0.9981 - val_loss: 1.3534 - val_accuracy: 0.7874\n",
      "Epoch 807/1000\n",
      "33/33 [==============================] - 0s 6ms/step - loss: 0.0144 - accuracy: 0.9942 - val_loss: 1.3521 - val_accuracy: 0.7953\n",
      "Epoch 808/1000\n",
      "33/33 [==============================] - 0s 6ms/step - loss: 0.0054 - accuracy: 0.9981 - val_loss: 1.2661 - val_accuracy: 0.8071\n",
      "Epoch 809/1000\n",
      "33/33 [==============================] - 0s 6ms/step - loss: 0.0026 - accuracy: 1.0000 - val_loss: 1.2983 - val_accuracy: 0.7992\n",
      "Epoch 810/1000\n",
      "33/33 [==============================] - 0s 6ms/step - loss: 0.0071 - accuracy: 1.0000 - val_loss: 1.2773 - val_accuracy: 0.7874\n",
      "Epoch 811/1000\n",
      "33/33 [==============================] - 0s 6ms/step - loss: 0.0062 - accuracy: 0.9981 - val_loss: 1.2476 - val_accuracy: 0.7874\n",
      "Epoch 812/1000\n",
      "33/33 [==============================] - 0s 6ms/step - loss: 0.0108 - accuracy: 0.9942 - val_loss: 1.3185 - val_accuracy: 0.7835\n",
      "Epoch 813/1000\n",
      "33/33 [==============================] - 0s 6ms/step - loss: 0.0070 - accuracy: 0.9981 - val_loss: 1.3750 - val_accuracy: 0.7795\n",
      "Epoch 814/1000\n",
      "33/33 [==============================] - 0s 6ms/step - loss: 0.0203 - accuracy: 0.9903 - val_loss: 1.5007 - val_accuracy: 0.7323\n",
      "Epoch 815/1000\n",
      "33/33 [==============================] - 0s 6ms/step - loss: 0.0075 - accuracy: 0.9981 - val_loss: 1.2281 - val_accuracy: 0.7717\n",
      "Epoch 816/1000\n",
      "33/33 [==============================] - 0s 6ms/step - loss: 0.0020 - accuracy: 1.0000 - val_loss: 1.3384 - val_accuracy: 0.7874\n",
      "Epoch 817/1000\n",
      "33/33 [==============================] - 0s 6ms/step - loss: 0.0170 - accuracy: 0.9922 - val_loss: 1.3043 - val_accuracy: 0.7677\n",
      "Epoch 818/1000\n",
      "33/33 [==============================] - 0s 6ms/step - loss: 0.0026 - accuracy: 1.0000 - val_loss: 1.2327 - val_accuracy: 0.7992\n",
      "Epoch 819/1000\n",
      "33/33 [==============================] - 0s 6ms/step - loss: 0.0025 - accuracy: 1.0000 - val_loss: 1.2546 - val_accuracy: 0.7874\n",
      "Epoch 820/1000\n",
      "33/33 [==============================] - 0s 6ms/step - loss: 0.0048 - accuracy: 1.0000 - val_loss: 1.2594 - val_accuracy: 0.7874\n",
      "Epoch 821/1000\n",
      "33/33 [==============================] - 0s 6ms/step - loss: 0.0133 - accuracy: 0.9981 - val_loss: 1.3257 - val_accuracy: 0.7953\n",
      "Epoch 822/1000\n",
      "33/33 [==============================] - 0s 6ms/step - loss: 0.0128 - accuracy: 0.9961 - val_loss: 1.3703 - val_accuracy: 0.7953\n",
      "Epoch 823/1000\n",
      "33/33 [==============================] - 0s 6ms/step - loss: 0.0018 - accuracy: 1.0000 - val_loss: 1.3255 - val_accuracy: 0.7913\n",
      "Epoch 824/1000\n",
      "33/33 [==============================] - 0s 6ms/step - loss: 0.0048 - accuracy: 0.9981 - val_loss: 1.2457 - val_accuracy: 0.8031\n",
      "Epoch 825/1000\n",
      "33/33 [==============================] - 0s 6ms/step - loss: 0.0096 - accuracy: 0.9942 - val_loss: 1.4184 - val_accuracy: 0.7756\n",
      "Epoch 826/1000\n",
      "33/33 [==============================] - 0s 6ms/step - loss: 0.0072 - accuracy: 0.9981 - val_loss: 1.3634 - val_accuracy: 0.7835\n",
      "Epoch 827/1000\n",
      "33/33 [==============================] - 0s 6ms/step - loss: 0.0145 - accuracy: 0.9961 - val_loss: 1.3487 - val_accuracy: 0.7756\n",
      "Epoch 828/1000\n",
      "33/33 [==============================] - 0s 6ms/step - loss: 0.0024 - accuracy: 1.0000 - val_loss: 1.3417 - val_accuracy: 0.7874\n",
      "Epoch 829/1000\n",
      "33/33 [==============================] - 0s 6ms/step - loss: 0.0033 - accuracy: 1.0000 - val_loss: 1.3156 - val_accuracy: 0.7992\n",
      "Epoch 830/1000\n",
      "33/33 [==============================] - 0s 6ms/step - loss: 0.0055 - accuracy: 0.9981 - val_loss: 1.3238 - val_accuracy: 0.7953\n",
      "Epoch 831/1000\n",
      "33/33 [==============================] - 0s 6ms/step - loss: 0.0098 - accuracy: 0.9942 - val_loss: 1.3415 - val_accuracy: 0.7953\n",
      "Epoch 832/1000\n",
      "33/33 [==============================] - 0s 6ms/step - loss: 0.0100 - accuracy: 0.9981 - val_loss: 1.3279 - val_accuracy: 0.8031\n",
      "Epoch 833/1000\n",
      "33/33 [==============================] - 0s 6ms/step - loss: 0.0027 - accuracy: 1.0000 - val_loss: 1.3280 - val_accuracy: 0.7835\n",
      "Epoch 834/1000\n",
      "33/33 [==============================] - 0s 6ms/step - loss: 0.0062 - accuracy: 1.0000 - val_loss: 1.2754 - val_accuracy: 0.7913\n",
      "Epoch 835/1000\n",
      "33/33 [==============================] - 0s 6ms/step - loss: 0.0055 - accuracy: 0.9981 - val_loss: 1.2356 - val_accuracy: 0.7992\n",
      "Epoch 836/1000\n",
      "33/33 [==============================] - 0s 6ms/step - loss: 0.0063 - accuracy: 0.9981 - val_loss: 1.3646 - val_accuracy: 0.7953\n",
      "Epoch 837/1000\n",
      "33/33 [==============================] - 0s 6ms/step - loss: 0.0114 - accuracy: 0.9981 - val_loss: 1.3425 - val_accuracy: 0.8071\n",
      "Epoch 838/1000\n",
      "33/33 [==============================] - 0s 6ms/step - loss: 0.0042 - accuracy: 1.0000 - val_loss: 1.3373 - val_accuracy: 0.7992\n",
      "Epoch 839/1000\n",
      "33/33 [==============================] - 0s 6ms/step - loss: 0.0027 - accuracy: 1.0000 - val_loss: 1.2608 - val_accuracy: 0.8031\n",
      "Epoch 840/1000\n",
      "33/33 [==============================] - 0s 6ms/step - loss: 0.0021 - accuracy: 1.0000 - val_loss: 1.6380 - val_accuracy: 0.7638\n",
      "Epoch 841/1000\n",
      "33/33 [==============================] - 0s 6ms/step - loss: 0.0094 - accuracy: 0.9961 - val_loss: 1.2987 - val_accuracy: 0.7913\n",
      "Epoch 842/1000\n",
      "33/33 [==============================] - 0s 6ms/step - loss: 0.0024 - accuracy: 1.0000 - val_loss: 1.3664 - val_accuracy: 0.7913\n",
      "Epoch 843/1000\n",
      "33/33 [==============================] - 0s 6ms/step - loss: 0.0075 - accuracy: 0.9981 - val_loss: 1.3207 - val_accuracy: 0.7795\n",
      "Epoch 844/1000\n",
      "33/33 [==============================] - 0s 6ms/step - loss: 0.0038 - accuracy: 1.0000 - val_loss: 1.3653 - val_accuracy: 0.7874\n",
      "Epoch 845/1000\n",
      "33/33 [==============================] - 0s 6ms/step - loss: 0.0071 - accuracy: 0.9961 - val_loss: 1.6404 - val_accuracy: 0.7756\n",
      "Epoch 846/1000\n",
      "33/33 [==============================] - 0s 6ms/step - loss: 0.0041 - accuracy: 1.0000 - val_loss: 1.3966 - val_accuracy: 0.7913\n",
      "Epoch 847/1000\n",
      "33/33 [==============================] - 0s 6ms/step - loss: 0.0075 - accuracy: 0.9981 - val_loss: 1.4099 - val_accuracy: 0.7992\n",
      "Epoch 848/1000\n",
      "33/33 [==============================] - 0s 6ms/step - loss: 0.0026 - accuracy: 1.0000 - val_loss: 1.3177 - val_accuracy: 0.7992\n",
      "Epoch 849/1000\n",
      "33/33 [==============================] - 0s 7ms/step - loss: 0.0073 - accuracy: 0.9961 - val_loss: 1.2839 - val_accuracy: 0.8071\n",
      "Epoch 850/1000\n",
      "33/33 [==============================] - 0s 7ms/step - loss: 0.0036 - accuracy: 1.0000 - val_loss: 1.3571 - val_accuracy: 0.7913\n",
      "Epoch 851/1000\n",
      "33/33 [==============================] - 0s 7ms/step - loss: 0.0023 - accuracy: 1.0000 - val_loss: 1.3772 - val_accuracy: 0.7913\n",
      "Epoch 852/1000\n",
      "33/33 [==============================] - 0s 7ms/step - loss: 0.0082 - accuracy: 0.9981 - val_loss: 1.2564 - val_accuracy: 0.7953\n",
      "Epoch 853/1000\n",
      "33/33 [==============================] - 0s 7ms/step - loss: 0.0053 - accuracy: 1.0000 - val_loss: 1.2888 - val_accuracy: 0.7913\n",
      "Epoch 854/1000\n",
      "33/33 [==============================] - 0s 7ms/step - loss: 0.0065 - accuracy: 0.9981 - val_loss: 1.3481 - val_accuracy: 0.7598\n",
      "Epoch 855/1000\n",
      "33/33 [==============================] - 0s 7ms/step - loss: 0.0024 - accuracy: 1.0000 - val_loss: 1.4096 - val_accuracy: 0.7953\n",
      "Epoch 856/1000\n",
      "33/33 [==============================] - 0s 7ms/step - loss: 0.0038 - accuracy: 0.9981 - val_loss: 1.2539 - val_accuracy: 0.7992\n",
      "Epoch 857/1000\n",
      "33/33 [==============================] - 0s 7ms/step - loss: 0.0137 - accuracy: 0.9961 - val_loss: 1.2792 - val_accuracy: 0.8110\n",
      "Epoch 858/1000\n",
      "33/33 [==============================] - 0s 7ms/step - loss: 0.0072 - accuracy: 0.9981 - val_loss: 1.3377 - val_accuracy: 0.7835\n",
      "Epoch 859/1000\n",
      "33/33 [==============================] - 0s 6ms/step - loss: 0.0016 - accuracy: 1.0000 - val_loss: 1.3611 - val_accuracy: 0.7835\n",
      "Epoch 860/1000\n",
      "33/33 [==============================] - 0s 6ms/step - loss: 0.0038 - accuracy: 0.9981 - val_loss: 1.3394 - val_accuracy: 0.7913\n",
      "Epoch 861/1000\n",
      "33/33 [==============================] - 0s 6ms/step - loss: 0.0067 - accuracy: 0.9981 - val_loss: 1.3823 - val_accuracy: 0.7835\n",
      "Epoch 862/1000\n",
      "33/33 [==============================] - 0s 6ms/step - loss: 0.0075 - accuracy: 0.9981 - val_loss: 1.3319 - val_accuracy: 0.7953\n",
      "Epoch 863/1000\n",
      "33/33 [==============================] - 0s 7ms/step - loss: 0.0020 - accuracy: 1.0000 - val_loss: 1.2858 - val_accuracy: 0.7992\n",
      "Epoch 864/1000\n",
      "33/33 [==============================] - 0s 6ms/step - loss: 0.0015 - accuracy: 1.0000 - val_loss: 1.2353 - val_accuracy: 0.7913\n",
      "Epoch 865/1000\n",
      "33/33 [==============================] - 0s 6ms/step - loss: 0.0032 - accuracy: 1.0000 - val_loss: 1.3689 - val_accuracy: 0.7953\n",
      "Epoch 866/1000\n",
      "33/33 [==============================] - 0s 6ms/step - loss: 0.0047 - accuracy: 1.0000 - val_loss: 1.3662 - val_accuracy: 0.7795\n",
      "Epoch 867/1000\n",
      "33/33 [==============================] - 0s 7ms/step - loss: 0.0045 - accuracy: 0.9981 - val_loss: 1.3772 - val_accuracy: 0.7992\n",
      "Epoch 868/1000\n",
      "33/33 [==============================] - 0s 6ms/step - loss: 0.0048 - accuracy: 1.0000 - val_loss: 1.3842 - val_accuracy: 0.7953\n",
      "Epoch 869/1000\n",
      "33/33 [==============================] - 0s 7ms/step - loss: 0.0128 - accuracy: 0.9922 - val_loss: 1.2728 - val_accuracy: 0.8031\n",
      "Epoch 870/1000\n",
      "33/33 [==============================] - 0s 7ms/step - loss: 0.0020 - accuracy: 1.0000 - val_loss: 1.2637 - val_accuracy: 0.7835\n",
      "Epoch 871/1000\n",
      "33/33 [==============================] - 0s 6ms/step - loss: 0.0034 - accuracy: 1.0000 - val_loss: 1.3642 - val_accuracy: 0.8071\n",
      "Epoch 872/1000\n",
      "33/33 [==============================] - 0s 7ms/step - loss: 0.0106 - accuracy: 0.9961 - val_loss: 1.4122 - val_accuracy: 0.8031\n",
      "Epoch 873/1000\n",
      "33/33 [==============================] - 0s 7ms/step - loss: 0.0031 - accuracy: 1.0000 - val_loss: 1.4838 - val_accuracy: 0.7795\n",
      "Epoch 874/1000\n",
      "33/33 [==============================] - 0s 7ms/step - loss: 0.0033 - accuracy: 1.0000 - val_loss: 1.3532 - val_accuracy: 0.8071\n",
      "Epoch 875/1000\n",
      "33/33 [==============================] - 0s 8ms/step - loss: 0.0058 - accuracy: 1.0000 - val_loss: 1.5255 - val_accuracy: 0.7795\n",
      "Epoch 876/1000\n",
      "33/33 [==============================] - 0s 8ms/step - loss: 0.0021 - accuracy: 1.0000 - val_loss: 1.4417 - val_accuracy: 0.7756\n",
      "Epoch 877/1000\n",
      "33/33 [==============================] - 0s 8ms/step - loss: 0.0060 - accuracy: 0.9981 - val_loss: 1.3010 - val_accuracy: 0.7795\n",
      "Epoch 878/1000\n",
      "33/33 [==============================] - 0s 8ms/step - loss: 0.0026 - accuracy: 1.0000 - val_loss: 1.2959 - val_accuracy: 0.7953\n",
      "Epoch 879/1000\n",
      "33/33 [==============================] - 0s 7ms/step - loss: 0.0046 - accuracy: 1.0000 - val_loss: 1.3949 - val_accuracy: 0.7913\n",
      "Epoch 880/1000\n",
      "33/33 [==============================] - 0s 6ms/step - loss: 0.0018 - accuracy: 1.0000 - val_loss: 1.3872 - val_accuracy: 0.7717\n",
      "Epoch 881/1000\n",
      "33/33 [==============================] - 0s 6ms/step - loss: 0.0019 - accuracy: 1.0000 - val_loss: 1.3147 - val_accuracy: 0.7835\n",
      "Epoch 882/1000\n",
      "33/33 [==============================] - 0s 6ms/step - loss: 0.0032 - accuracy: 1.0000 - val_loss: 1.4256 - val_accuracy: 0.7756\n",
      "Epoch 883/1000\n",
      "33/33 [==============================] - 0s 6ms/step - loss: 0.0024 - accuracy: 1.0000 - val_loss: 1.3820 - val_accuracy: 0.7913\n",
      "Epoch 884/1000\n",
      "33/33 [==============================] - 0s 6ms/step - loss: 0.0042 - accuracy: 0.9981 - val_loss: 1.4984 - val_accuracy: 0.7992\n",
      "Epoch 885/1000\n",
      "33/33 [==============================] - 0s 6ms/step - loss: 0.0030 - accuracy: 1.0000 - val_loss: 1.5072 - val_accuracy: 0.7953\n",
      "Epoch 886/1000\n",
      "33/33 [==============================] - 0s 6ms/step - loss: 0.0036 - accuracy: 1.0000 - val_loss: 1.4473 - val_accuracy: 0.7756\n",
      "Epoch 887/1000\n",
      "33/33 [==============================] - 0s 7ms/step - loss: 0.0052 - accuracy: 0.9981 - val_loss: 1.3601 - val_accuracy: 0.7874\n",
      "Epoch 888/1000\n",
      "33/33 [==============================] - 0s 7ms/step - loss: 0.0058 - accuracy: 0.9981 - val_loss: 1.2948 - val_accuracy: 0.7835\n",
      "Epoch 889/1000\n",
      "33/33 [==============================] - 0s 7ms/step - loss: 0.0014 - accuracy: 1.0000 - val_loss: 1.3033 - val_accuracy: 0.7913\n",
      "Epoch 890/1000\n",
      "33/33 [==============================] - 0s 8ms/step - loss: 0.0069 - accuracy: 0.9981 - val_loss: 1.3774 - val_accuracy: 0.7874\n",
      "Epoch 891/1000\n",
      "33/33 [==============================] - 0s 8ms/step - loss: 0.0016 - accuracy: 1.0000 - val_loss: 1.3801 - val_accuracy: 0.7913\n",
      "Epoch 892/1000\n",
      "33/33 [==============================] - 0s 8ms/step - loss: 0.0076 - accuracy: 0.9981 - val_loss: 1.3777 - val_accuracy: 0.8031\n",
      "Epoch 893/1000\n",
      "33/33 [==============================] - 0s 8ms/step - loss: 0.0125 - accuracy: 0.9961 - val_loss: 1.4258 - val_accuracy: 0.7677\n",
      "Epoch 894/1000\n",
      "33/33 [==============================] - 0s 8ms/step - loss: 0.0039 - accuracy: 0.9981 - val_loss: 1.3366 - val_accuracy: 0.7913\n",
      "Epoch 895/1000\n",
      "33/33 [==============================] - 0s 8ms/step - loss: 0.0112 - accuracy: 0.9942 - val_loss: 1.3674 - val_accuracy: 0.7835\n",
      "Epoch 896/1000\n",
      "33/33 [==============================] - 0s 8ms/step - loss: 0.0043 - accuracy: 0.9981 - val_loss: 1.2044 - val_accuracy: 0.7795\n",
      "Epoch 897/1000\n",
      "33/33 [==============================] - 0s 8ms/step - loss: 0.0023 - accuracy: 1.0000 - val_loss: 1.3013 - val_accuracy: 0.7717\n",
      "Epoch 898/1000\n",
      "33/33 [==============================] - 0s 8ms/step - loss: 0.0042 - accuracy: 1.0000 - val_loss: 1.2731 - val_accuracy: 0.7835\n",
      "Epoch 899/1000\n",
      "33/33 [==============================] - 0s 8ms/step - loss: 0.0040 - accuracy: 1.0000 - val_loss: 1.2766 - val_accuracy: 0.7913\n",
      "Epoch 900/1000\n",
      "33/33 [==============================] - 0s 8ms/step - loss: 0.0043 - accuracy: 0.9981 - val_loss: 1.3271 - val_accuracy: 0.7835\n",
      "Epoch 901/1000\n",
      "33/33 [==============================] - ETA: 0s - loss: 9.4936e-04 - accuracy: 1.00 - 0s 8ms/step - loss: 0.0012 - accuracy: 1.0000 - val_loss: 1.3487 - val_accuracy: 0.7874\n",
      "Epoch 902/1000\n",
      "33/33 [==============================] - 0s 8ms/step - loss: 0.0021 - accuracy: 1.0000 - val_loss: 1.5144 - val_accuracy: 0.8031\n",
      "Epoch 903/1000\n",
      "33/33 [==============================] - 0s 8ms/step - loss: 0.0036 - accuracy: 1.0000 - val_loss: 1.4086 - val_accuracy: 0.7835\n",
      "Epoch 904/1000\n",
      "33/33 [==============================] - 0s 8ms/step - loss: 0.0053 - accuracy: 0.9981 - val_loss: 1.4825 - val_accuracy: 0.7874\n",
      "Epoch 905/1000\n",
      "33/33 [==============================] - 0s 8ms/step - loss: 0.0069 - accuracy: 0.9981 - val_loss: 1.4075 - val_accuracy: 0.7953\n",
      "Epoch 906/1000\n",
      "33/33 [==============================] - 0s 8ms/step - loss: 0.0049 - accuracy: 0.9981 - val_loss: 1.3368 - val_accuracy: 0.7756\n",
      "Epoch 907/1000\n",
      "33/33 [==============================] - 0s 9ms/step - loss: 0.0132 - accuracy: 0.9981 - val_loss: 1.2818 - val_accuracy: 0.8150\n",
      "Epoch 908/1000\n",
      "33/33 [==============================] - 0s 8ms/step - loss: 0.0036 - accuracy: 1.0000 - val_loss: 1.4517 - val_accuracy: 0.7795\n",
      "Epoch 909/1000\n",
      "33/33 [==============================] - 0s 8ms/step - loss: 0.0041 - accuracy: 0.9981 - val_loss: 1.3892 - val_accuracy: 0.7795\n",
      "Epoch 910/1000\n",
      "33/33 [==============================] - 0s 8ms/step - loss: 0.0032 - accuracy: 1.0000 - val_loss: 1.3339 - val_accuracy: 0.7913\n",
      "Epoch 911/1000\n",
      "33/33 [==============================] - 0s 9ms/step - loss: 0.0018 - accuracy: 1.0000 - val_loss: 1.4493 - val_accuracy: 0.7953\n",
      "Epoch 912/1000\n",
      "33/33 [==============================] - 0s 9ms/step - loss: 0.0018 - accuracy: 1.0000 - val_loss: 1.3188 - val_accuracy: 0.7756\n",
      "Epoch 913/1000\n",
      "33/33 [==============================] - 0s 8ms/step - loss: 0.0016 - accuracy: 1.0000 - val_loss: 1.3493 - val_accuracy: 0.8031\n",
      "Epoch 914/1000\n",
      "33/33 [==============================] - 0s 9ms/step - loss: 0.0072 - accuracy: 0.9981 - val_loss: 1.4630 - val_accuracy: 0.7953\n",
      "Epoch 915/1000\n",
      "33/33 [==============================] - 0s 7ms/step - loss: 0.0083 - accuracy: 0.9981 - val_loss: 1.4158 - val_accuracy: 0.8031\n",
      "Epoch 916/1000\n",
      "33/33 [==============================] - 0s 8ms/step - loss: 0.0087 - accuracy: 0.9961 - val_loss: 1.3390 - val_accuracy: 0.7913\n",
      "Epoch 917/1000\n",
      "33/33 [==============================] - 0s 7ms/step - loss: 0.0042 - accuracy: 1.0000 - val_loss: 1.3728 - val_accuracy: 0.8071\n",
      "Epoch 918/1000\n",
      "33/33 [==============================] - 0s 8ms/step - loss: 0.0034 - accuracy: 0.9981 - val_loss: 1.3744 - val_accuracy: 0.7953\n",
      "Epoch 919/1000\n",
      "33/33 [==============================] - 0s 8ms/step - loss: 0.0026 - accuracy: 1.0000 - val_loss: 1.3401 - val_accuracy: 0.7913\n",
      "Epoch 920/1000\n",
      "33/33 [==============================] - 0s 7ms/step - loss: 0.0078 - accuracy: 0.9981 - val_loss: 1.3892 - val_accuracy: 0.7953\n",
      "Epoch 921/1000\n",
      "33/33 [==============================] - 0s 7ms/step - loss: 0.0254 - accuracy: 0.9961 - val_loss: 1.3851 - val_accuracy: 0.7953\n",
      "Epoch 922/1000\n",
      "33/33 [==============================] - 0s 7ms/step - loss: 0.0066 - accuracy: 0.9981 - val_loss: 1.3764 - val_accuracy: 0.7835\n",
      "Epoch 923/1000\n",
      "33/33 [==============================] - 0s 8ms/step - loss: 0.0085 - accuracy: 0.9961 - val_loss: 1.3806 - val_accuracy: 0.7874\n",
      "Epoch 924/1000\n",
      "33/33 [==============================] - 0s 7ms/step - loss: 0.0151 - accuracy: 0.9903 - val_loss: 1.3615 - val_accuracy: 0.7795\n",
      "Epoch 925/1000\n",
      "33/33 [==============================] - 0s 7ms/step - loss: 0.0040 - accuracy: 1.0000 - val_loss: 1.3196 - val_accuracy: 0.8031\n",
      "Epoch 926/1000\n",
      "33/33 [==============================] - 0s 7ms/step - loss: 0.0042 - accuracy: 0.9981 - val_loss: 1.3479 - val_accuracy: 0.7992\n",
      "Epoch 927/1000\n",
      "33/33 [==============================] - 0s 7ms/step - loss: 0.0024 - accuracy: 1.0000 - val_loss: 1.5484 - val_accuracy: 0.7874\n",
      "Epoch 928/1000\n",
      "33/33 [==============================] - 0s 7ms/step - loss: 0.0046 - accuracy: 0.9981 - val_loss: 1.3316 - val_accuracy: 0.7992\n",
      "Epoch 929/1000\n",
      "33/33 [==============================] - 0s 7ms/step - loss: 0.0036 - accuracy: 0.9981 - val_loss: 1.5012 - val_accuracy: 0.7756\n",
      "Epoch 930/1000\n",
      "33/33 [==============================] - 0s 7ms/step - loss: 0.0037 - accuracy: 1.0000 - val_loss: 1.4460 - val_accuracy: 0.7835\n",
      "Epoch 931/1000\n",
      "33/33 [==============================] - 0s 7ms/step - loss: 0.0027 - accuracy: 1.0000 - val_loss: 1.3082 - val_accuracy: 0.7835\n",
      "Epoch 932/1000\n",
      "33/33 [==============================] - 0s 6ms/step - loss: 0.0028 - accuracy: 1.0000 - val_loss: 1.3491 - val_accuracy: 0.7756\n",
      "Epoch 933/1000\n",
      "33/33 [==============================] - 0s 7ms/step - loss: 0.0048 - accuracy: 1.0000 - val_loss: 1.3075 - val_accuracy: 0.7953\n",
      "Epoch 934/1000\n",
      "33/33 [==============================] - 0s 7ms/step - loss: 0.0017 - accuracy: 1.0000 - val_loss: 1.4816 - val_accuracy: 0.7913\n",
      "Epoch 935/1000\n",
      "33/33 [==============================] - 0s 6ms/step - loss: 0.0025 - accuracy: 1.0000 - val_loss: 1.3252 - val_accuracy: 0.7874\n",
      "Epoch 936/1000\n",
      "33/33 [==============================] - 0s 6ms/step - loss: 0.0065 - accuracy: 0.9981 - val_loss: 1.3341 - val_accuracy: 0.7874\n",
      "Epoch 937/1000\n",
      "33/33 [==============================] - 0s 6ms/step - loss: 0.0117 - accuracy: 0.9942 - val_loss: 1.4026 - val_accuracy: 0.8031\n",
      "Epoch 938/1000\n",
      "33/33 [==============================] - 0s 7ms/step - loss: 0.0051 - accuracy: 0.9981 - val_loss: 1.3861 - val_accuracy: 0.7953\n",
      "Epoch 939/1000\n",
      "33/33 [==============================] - 0s 6ms/step - loss: 0.0054 - accuracy: 1.0000 - val_loss: 1.4204 - val_accuracy: 0.7835\n",
      "Epoch 940/1000\n",
      "33/33 [==============================] - 0s 7ms/step - loss: 0.0100 - accuracy: 0.9961 - val_loss: 1.5360 - val_accuracy: 0.7795\n",
      "Epoch 941/1000\n",
      "33/33 [==============================] - 0s 6ms/step - loss: 0.0040 - accuracy: 1.0000 - val_loss: 1.3585 - val_accuracy: 0.7717\n",
      "Epoch 942/1000\n",
      "33/33 [==============================] - 0s 6ms/step - loss: 0.0071 - accuracy: 1.0000 - val_loss: 1.3721 - val_accuracy: 0.7756\n",
      "Epoch 943/1000\n",
      "33/33 [==============================] - 0s 6ms/step - loss: 0.0057 - accuracy: 0.9981 - val_loss: 1.3926 - val_accuracy: 0.7874\n",
      "Epoch 944/1000\n",
      "33/33 [==============================] - 0s 6ms/step - loss: 0.0027 - accuracy: 1.0000 - val_loss: 1.5818 - val_accuracy: 0.7756\n",
      "Epoch 945/1000\n",
      "33/33 [==============================] - 0s 6ms/step - loss: 0.0128 - accuracy: 0.9942 - val_loss: 1.4161 - val_accuracy: 0.7835\n",
      "Epoch 946/1000\n",
      "33/33 [==============================] - 0s 6ms/step - loss: 0.0030 - accuracy: 1.0000 - val_loss: 1.3886 - val_accuracy: 0.8031\n",
      "Epoch 947/1000\n",
      "33/33 [==============================] - 0s 6ms/step - loss: 0.0094 - accuracy: 0.9961 - val_loss: 1.3359 - val_accuracy: 0.7795\n",
      "Epoch 948/1000\n",
      "33/33 [==============================] - 0s 6ms/step - loss: 0.0097 - accuracy: 0.9961 - val_loss: 1.3228 - val_accuracy: 0.7795\n",
      "Epoch 949/1000\n",
      "33/33 [==============================] - 0s 6ms/step - loss: 0.0041 - accuracy: 1.0000 - val_loss: 1.3832 - val_accuracy: 0.8031\n",
      "Epoch 950/1000\n",
      "33/33 [==============================] - 0s 6ms/step - loss: 0.0062 - accuracy: 0.9981 - val_loss: 1.4038 - val_accuracy: 0.7874\n",
      "Epoch 951/1000\n",
      "33/33 [==============================] - 0s 6ms/step - loss: 0.0098 - accuracy: 0.9961 - val_loss: 1.3537 - val_accuracy: 0.7874\n",
      "Epoch 952/1000\n",
      "33/33 [==============================] - 0s 6ms/step - loss: 0.0019 - accuracy: 1.0000 - val_loss: 1.3443 - val_accuracy: 0.7953\n",
      "Epoch 953/1000\n",
      "33/33 [==============================] - 0s 6ms/step - loss: 0.0096 - accuracy: 0.9942 - val_loss: 1.3805 - val_accuracy: 0.7874\n",
      "Epoch 954/1000\n",
      "33/33 [==============================] - 0s 6ms/step - loss: 0.0045 - accuracy: 0.9981 - val_loss: 1.3628 - val_accuracy: 0.7874\n",
      "Epoch 955/1000\n",
      "33/33 [==============================] - 0s 6ms/step - loss: 0.0166 - accuracy: 0.9942 - val_loss: 1.3475 - val_accuracy: 0.7717\n",
      "Epoch 956/1000\n",
      "33/33 [==============================] - 0s 6ms/step - loss: 0.0034 - accuracy: 0.9981 - val_loss: 1.3269 - val_accuracy: 0.7953\n",
      "Epoch 957/1000\n",
      "33/33 [==============================] - 0s 6ms/step - loss: 0.0046 - accuracy: 0.9981 - val_loss: 1.4299 - val_accuracy: 0.7874\n",
      "Epoch 958/1000\n",
      "33/33 [==============================] - 0s 6ms/step - loss: 0.0036 - accuracy: 1.0000 - val_loss: 1.3426 - val_accuracy: 0.7756\n",
      "Epoch 959/1000\n",
      "33/33 [==============================] - 0s 6ms/step - loss: 0.0063 - accuracy: 1.0000 - val_loss: 1.3845 - val_accuracy: 0.8071\n",
      "Epoch 960/1000\n",
      "33/33 [==============================] - 0s 7ms/step - loss: 0.0094 - accuracy: 0.9981 - val_loss: 1.2602 - val_accuracy: 0.7717\n",
      "Epoch 961/1000\n",
      "33/33 [==============================] - 0s 7ms/step - loss: 0.0034 - accuracy: 0.9981 - val_loss: 1.3025 - val_accuracy: 0.7756\n",
      "Epoch 962/1000\n",
      "33/33 [==============================] - 0s 7ms/step - loss: 0.0149 - accuracy: 0.9961 - val_loss: 1.5335 - val_accuracy: 0.7598\n",
      "Epoch 963/1000\n",
      "33/33 [==============================] - 0s 6ms/step - loss: 0.0147 - accuracy: 0.9961 - val_loss: 1.4793 - val_accuracy: 0.7677\n",
      "Epoch 964/1000\n",
      "33/33 [==============================] - 0s 7ms/step - loss: 0.0033 - accuracy: 1.0000 - val_loss: 1.5310 - val_accuracy: 0.7835\n",
      "Epoch 965/1000\n",
      "33/33 [==============================] - 0s 6ms/step - loss: 0.0027 - accuracy: 0.9981 - val_loss: 1.5197 - val_accuracy: 0.7913\n",
      "Epoch 966/1000\n",
      "33/33 [==============================] - 0s 6ms/step - loss: 0.0072 - accuracy: 0.9981 - val_loss: 1.4480 - val_accuracy: 0.7874\n",
      "Epoch 967/1000\n",
      "33/33 [==============================] - 0s 6ms/step - loss: 0.0060 - accuracy: 0.9981 - val_loss: 1.4324 - val_accuracy: 0.7835\n",
      "Epoch 968/1000\n",
      "33/33 [==============================] - 0s 6ms/step - loss: 0.0038 - accuracy: 1.0000 - val_loss: 1.3070 - val_accuracy: 0.7953\n",
      "Epoch 969/1000\n",
      "33/33 [==============================] - 0s 7ms/step - loss: 0.0055 - accuracy: 0.9981 - val_loss: 1.4013 - val_accuracy: 0.7913\n",
      "Epoch 970/1000\n",
      "33/33 [==============================] - 0s 6ms/step - loss: 0.0020 - accuracy: 1.0000 - val_loss: 1.5440 - val_accuracy: 0.7835\n",
      "Epoch 971/1000\n",
      "33/33 [==============================] - 0s 6ms/step - loss: 0.0070 - accuracy: 0.9981 - val_loss: 1.3510 - val_accuracy: 0.7795\n",
      "Epoch 972/1000\n",
      "33/33 [==============================] - 0s 6ms/step - loss: 0.0048 - accuracy: 0.9981 - val_loss: 1.3226 - val_accuracy: 0.7953\n",
      "Epoch 973/1000\n",
      "33/33 [==============================] - 0s 7ms/step - loss: 0.0071 - accuracy: 1.0000 - val_loss: 1.3630 - val_accuracy: 0.7874\n",
      "Epoch 974/1000\n",
      "33/33 [==============================] - 0s 6ms/step - loss: 0.0024 - accuracy: 1.0000 - val_loss: 1.3412 - val_accuracy: 0.7835\n",
      "Epoch 975/1000\n",
      "33/33 [==============================] - 0s 6ms/step - loss: 0.0111 - accuracy: 0.9961 - val_loss: 1.3140 - val_accuracy: 0.7835\n",
      "Epoch 976/1000\n",
      "33/33 [==============================] - 0s 6ms/step - loss: 0.0044 - accuracy: 0.9981 - val_loss: 1.5225 - val_accuracy: 0.7795\n",
      "Epoch 977/1000\n",
      "33/33 [==============================] - 0s 6ms/step - loss: 0.0091 - accuracy: 0.9961 - val_loss: 1.3469 - val_accuracy: 0.7874\n",
      "Epoch 978/1000\n",
      "33/33 [==============================] - 0s 7ms/step - loss: 0.0026 - accuracy: 1.0000 - val_loss: 1.4373 - val_accuracy: 0.7874\n",
      "Epoch 979/1000\n",
      "33/33 [==============================] - 0s 7ms/step - loss: 0.0091 - accuracy: 0.9981 - val_loss: 1.3889 - val_accuracy: 0.7835\n",
      "Epoch 980/1000\n",
      "33/33 [==============================] - 0s 7ms/step - loss: 0.0027 - accuracy: 1.0000 - val_loss: 1.4676 - val_accuracy: 0.7835\n",
      "Epoch 981/1000\n",
      "33/33 [==============================] - 0s 7ms/step - loss: 0.0024 - accuracy: 1.0000 - val_loss: 1.3728 - val_accuracy: 0.7874\n",
      "Epoch 982/1000\n",
      "33/33 [==============================] - 0s 7ms/step - loss: 0.0051 - accuracy: 0.9981 - val_loss: 1.3665 - val_accuracy: 0.7874\n",
      "Epoch 983/1000\n",
      "33/33 [==============================] - 0s 7ms/step - loss: 0.0067 - accuracy: 0.9981 - val_loss: 1.4472 - val_accuracy: 0.7795\n",
      "Epoch 984/1000\n",
      "33/33 [==============================] - 0s 7ms/step - loss: 0.0018 - accuracy: 1.0000 - val_loss: 1.3352 - val_accuracy: 0.7795\n",
      "Epoch 985/1000\n",
      "33/33 [==============================] - 0s 7ms/step - loss: 0.0077 - accuracy: 0.9961 - val_loss: 1.2965 - val_accuracy: 0.7874\n",
      "Epoch 986/1000\n",
      "33/33 [==============================] - 0s 7ms/step - loss: 0.0040 - accuracy: 1.0000 - val_loss: 1.3689 - val_accuracy: 0.7953\n",
      "Epoch 987/1000\n",
      "33/33 [==============================] - 0s 7ms/step - loss: 0.0074 - accuracy: 0.9961 - val_loss: 1.3359 - val_accuracy: 0.7756\n",
      "Epoch 988/1000\n",
      "33/33 [==============================] - 0s 6ms/step - loss: 0.0031 - accuracy: 1.0000 - val_loss: 1.3300 - val_accuracy: 0.7913\n",
      "Epoch 989/1000\n",
      "33/33 [==============================] - 0s 6ms/step - loss: 0.0044 - accuracy: 1.0000 - val_loss: 1.4198 - val_accuracy: 0.7835\n",
      "Epoch 990/1000\n",
      "33/33 [==============================] - 0s 7ms/step - loss: 0.0063 - accuracy: 1.0000 - val_loss: 1.3265 - val_accuracy: 0.7874\n",
      "Epoch 991/1000\n",
      "33/33 [==============================] - 0s 6ms/step - loss: 0.0044 - accuracy: 0.9981 - val_loss: 1.4268 - val_accuracy: 0.7913\n",
      "Epoch 992/1000\n",
      "33/33 [==============================] - 0s 7ms/step - loss: 0.0026 - accuracy: 1.0000 - val_loss: 1.3410 - val_accuracy: 0.7795\n",
      "Epoch 993/1000\n",
      "33/33 [==============================] - 0s 6ms/step - loss: 0.0018 - accuracy: 1.0000 - val_loss: 1.4408 - val_accuracy: 0.7756\n",
      "Epoch 994/1000\n",
      "33/33 [==============================] - 0s 7ms/step - loss: 0.0096 - accuracy: 0.9981 - val_loss: 1.4183 - val_accuracy: 0.7835\n",
      "Epoch 995/1000\n",
      "33/33 [==============================] - 0s 7ms/step - loss: 0.0204 - accuracy: 0.9922 - val_loss: 1.4219 - val_accuracy: 0.7953\n",
      "Epoch 996/1000\n",
      "33/33 [==============================] - 0s 6ms/step - loss: 0.0059 - accuracy: 0.9981 - val_loss: 1.3530 - val_accuracy: 0.7756\n",
      "Epoch 997/1000\n",
      "33/33 [==============================] - 0s 7ms/step - loss: 0.0139 - accuracy: 0.9981 - val_loss: 1.3275 - val_accuracy: 0.7835\n",
      "Epoch 998/1000\n",
      "33/33 [==============================] - 0s 7ms/step - loss: 0.0048 - accuracy: 0.9981 - val_loss: 1.4245 - val_accuracy: 0.7756\n",
      "Epoch 999/1000\n",
      "33/33 [==============================] - 0s 7ms/step - loss: 0.0115 - accuracy: 0.9961 - val_loss: 1.4018 - val_accuracy: 0.7913\n",
      "Epoch 1000/1000\n",
      "33/33 [==============================] - 0s 7ms/step - loss: 0.0025 - accuracy: 1.0000 - val_loss: 1.4381 - val_accuracy: 0.7913\n"
     ]
    }
   ],
   "source": [
    "cnnhistory=model.fit(x_traincnn, y_train, batch_size=16, epochs=1000, validation_data=(x_testcnn, y_test),callbacks=[tensorboard_callback])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "id": "endangered-intelligence",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "\n",
       "      <iframe id=\"tensorboard-frame-8b8318387ad92f1f\" width=\"100%\" height=\"800\" frameborder=\"0\">\n",
       "      </iframe>\n",
       "      <script>\n",
       "        (function() {\n",
       "          const frame = document.getElementById(\"tensorboard-frame-8b8318387ad92f1f\");\n",
       "          const url = new URL(\"/\", window.location);\n",
       "          const port = 6006;\n",
       "          if (port) {\n",
       "            url.port = port;\n",
       "          }\n",
       "          frame.src = url;\n",
       "        })();\n",
       "      </script>\n",
       "    "
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "%tensorboard --logdir model_board_1\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "id": "located-stream",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<AxesSubplot:>"
      ]
     },
     "execution_count": 42,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "pd.DataFrame(cnnhistory.history)[[\"loss\",\"val_loss\"]].plot()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "id": "covered-kennedy",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<AxesSubplot:>"
      ]
     },
     "execution_count": 43,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "pd.DataFrame(cnnhistory.history)[[\"accuracy\",\"val_accuracy\"]].plot()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "id": "loving-feature",
   "metadata": {},
   "outputs": [],
   "source": [
    "predictions=model.predict_classes(x_testcnn)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "id": "compliant-phenomenon",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Confusion matrix, without normalization\n"
     ]
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 576x576 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "cm = confusion_matrix( y_test,predictions)\n",
    "plot_confusion_matrix(cm, classes = Le.classes_, title='Confusion Matrix', normalize=False, figname = 'Confusion_matrix_concrete2.jpg')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "id": "danish-copper",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "       angry       0.79      0.88      0.83        56\n",
      "        calm       0.74      0.87      0.80        68\n",
      "       happy       0.83      0.75      0.79        67\n",
      "         sad       0.77      0.63      0.70        63\n",
      "\n",
      "    accuracy                           0.78       254\n",
      "   macro avg       0.78      0.78      0.78       254\n",
      "weighted avg       0.78      0.78      0.78       254\n",
      "\n"
     ]
    }
   ],
   "source": [
    "print(classification_report(y_test,predictions,target_names=Le.classes_))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ahead-japan",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
